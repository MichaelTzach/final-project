{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Text Generation\n",
    "You can find the full code in the \"TextGen.py\" file.\n",
    "Here we will review the most significet parts of the code\n",
    "\n",
    "## Data preperetion\n",
    "In the \"preprocess\" function we first read the sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    x = pd.read_csv(path).as_matrix()\n",
    "    data = ''.join(x[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we are creating the dictionary to index the chars to numeric and vise versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    unique_chars = sorted(list(set(data)))\n",
    "    dict_size = len(unique_chars)+1\n",
    "    char_indices = dict((c, i) for i, c in enumerate(unique_chars))\n",
    "    indices_char = dict((i, c) for i, c in enumerate(unique_chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we prepering the data, the data will be a sequences of 10 chars and the output should be those 10 chars shipted by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "   for i in range(0, len(data)-10, 10):\n",
    "        temp = data[i:i+10]\n",
    "        tempy = data[i+1:i+11]\n",
    "        sequences.append([char_indices[a] for a in temp])\n",
    "        y_sequences.append([char_indices[a] for a in tempy])\n",
    "    y_sequences = np.array([to_categorical(a, num_classes=dict_size) for a in np.array(y_sequences)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we split the data to 80%-20% (train-test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model\n",
    "For the model we used Embedding layer as the first layer to convert the input array to a dense vectors.\n",
    "Then we use an LSTM (Long-Short-Term-Memory) layer, it's a variant of RNN with an addition of 'memory cell'.\n",
    "Afterwards a dropout layer to be more generalized.\n",
    "And finally an output layer with the size of the vocabulary.\n",
    "The models were trained with batch size of 1000 and with 100 epochs.\n",
    "Our optimizer is 'ADAM' an improvment of the gradient descent by using a changing learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    model = Sequential()\n",
    "    model.add(Embedding(dict_size, 42, input_length=10))\n",
    "    model.add(LSTM(int(dict_size*2), return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(TimeDistributed(Dense(dict_size, activation='softmax')))\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried a deeper network but probably because of our litle resources we couldn't train it enough and our accuracy was very low, arround 35% with lot of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    model = Sequential()\n",
    "    model.add(Embedding(dict_size, 42, input_length=10))\n",
    "    model.add(LSTM(75, return_sequences=True))\n",
    "    model.add(Dense(40, activation='relu'))\n",
    "    model.add(Dense(75, activation='relu'))\n",
    "    model.add(TimeDistributed(Dense(dict_size, activation='softmax')))\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model evaluetion\n",
    "We used the test set from that we preperd earlier to check the model accuracy.\n",
    "It is easy to see that we got much higher accuracy with the bigger datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|          | Wiki  | BBC   | TripAdvisor |   \n",
    "|----------|-------|-------|-------------|\n",
    "| Accuracy | 0.543 | 0.357 | 0.450       |   \n",
    "| Loss     | 1.594 | 2.22  | 1.939       |   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Text\n",
    "For the text generation we first give the sequance 'When mecha' as the initial input, from testing with a random seed we got bad results. Then added the first char predicted to the text, afterwards we took the last 10 chars of the constructed sequance and used them as the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are giving the seed and translating it to input form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = 'When mecha'\n",
    "idxs = [char_indices[c] for c in inp]\n",
    "arr = np.array(idxs)[np.newaxis, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gathering the prediction output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = model.predict(arr)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a non-monotonic generation we are randomly choosing one of the most probable indx from the output and adding that char to the total output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char = chars[np.where(p[-1] == random.choice(p_sorted[-3:]))[0][0]]\n",
    "out += char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally write each sequance to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open('{}_gen.csv'.format(path), 'aw')\n",
    "file.write('{}, {}\\n'.format(i, ''.join(out)))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "We trained a model for each type using sequances of 10 chars.\n",
    "Our results weren't meaningfull but surprisingly mostly combined from a real words.\n",
    "The results are satisfying for the amount of training time (100 epochs) and for the thin model we used.\n",
    "Of course a more deeper and more training time will generate better results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
