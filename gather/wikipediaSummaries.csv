""	"x"
"1"	"Swift is a general-purpose, multi-paradigm, compiled programming language developed by Apple Inc. for iOS, macOS, watchOS, tvOS, and Linux. Swift is designed to work with Apple's Cocoa and Cocoa Touch frameworks and the large body of existing Objective-C (ObjC) code written for Apple products. It is built with the open source LLVM compiler framework and has been included in Xcode since version 6. On platforms other than Linux, it uses the Objective-C runtime library which allows C, Objective-C, C++ and Swift code to run within one program.Apple intended Swift to support many core concepts associated with Objective-C, notably dynamic dispatch, widespread late binding, extensible programming and similar features, but safer (easier to catch software bugs); Swift has features addressing some common programming errors like null pointers and provides syntactic sugar to help avoid the pyramid of doom. Swift supports the concept of protocol extensibility, an extensibility system that can be applied to types, structs and classes, which Apple promotes as a real change in programming paradigms they term protocol-oriented programming (similar to traits).Swift was introduced at Apple's 2014 Worldwide Developers Conference (WWDC). It underwent an upgrade to version 1.2 during 2014 and a more major upgrade to Swift 2 at WWDC 2015. Initially a proprietary language, version 2.2 was made open-source software under the Apache License 2.0 on December 3, 2015, for Apple's platforms and Linux.In March 2017, Swift made the top 10 in the monthly TIOBE index ranking of popular programming languages, and was ranked 11th at the end of 2017.Development of Swift started in July 2010 by Chris Lattner, with the eventual collaboration of many other programmers at Apple. Swift took language ideas from Objective-C, Rust, Haskell, Ruby, Python, C#, CLU, and far too many others to list. On June 2, 2014, the Apple Worldwide Developers Conference (WWDC) application became the first publicly released app written in Swift. A beta version of the programming language was released to registered Apple developers at the conference, but the company did not promise that the final version of Swift would be source code compatible with the test version. Apple planned to make source code converters available if needed for the full release.The Swift Programming Language, a free 500-page manual, was also released at WWDC, and is available on the iBooks Store and the official website.Swift reached the 1.0 milestone on September 9, 2014, with the Gold Master of Xcode 6.0 for iOS. Swift 1.1 was released on October 22, 2014, alongside the launch of Xcode 6.1. Swift 1.2 was released on April 8, 2015, along with Xcode 6.3. Swift 2.0 was announced at WWDC 2015, and was made available for publishing apps in the App Store in September 21, 2015. Swift 3.0 was released on September 13, 2016.Swift won first place for Most Loved Programming Language in the Stack Overflow Developer Survey 2015 and second place in 2016.In December 2015, IBM announced its Swift Sandbox website, which allows developers to write Swift code in one pane and display output in another.During the WWDC 2016, Apple announced an iPad exclusive app, named Swift Playgrounds, intended to teach people how to code in Swift. The app is presented in a 3D video game-like interface which provides feedback when lines of code are placed in a certain order and executed.In January 2017, Chris Lattner announced his departure from Apple for a new position with Tesla Motors, with the Swift project lead role going to team veteran Ted Kremenek.Swift is an alternative to the Objective-C language that employs modern programming-language theory concepts and strives to present a simpler syntax. During its introduction, it was described simply as Objective-C without the C.By default, Swift does not expose pointers and other unsafe accessors, in contrast to Objective-C, which uses pointers pervasively to refer to object instances. Also, Objective-C's use of a Smalltalk-like syntax for making method calls has been replaced with a dot-notation style and namespace system more familiar to programmers from other common object-oriented (OO) languages like Java or C#. Swift introduces true named parameters and retains key Objective-C concepts, including protocols, closures and categories, often replacing former syntax with cleaner versions and allowing these concepts to be applied to other language structures, like enumerated types (enums)Under the Cocoa and Cocoa Touch environments, many common classes were part of the Foundation Kit library. This included the NSString string library (using Unicode), the NSArray and NSDictionary collection classes, and others. Objective-C provided various bits of syntactic sugar to allow some of these objects to be created on-the-fly within the language, but once created, the objects were manipulated with object calls. For instance, in Objective-C concatenating two NSStrings required method calls similar to this:  In Swift, many of these basic types have been promoted to the language's core, and can be manipulated directly. For instance, strings are invisibly bridged to NSString (when Foundation is imported) and can now be concatenated with the + operator, allowing greatly simplified syntax; the prior example becoming:Swift supports five access control levels for symbols: open, public, internal, fileprivate, and private. Unlike many object-oriented languages, these access controls ignore inheritance hierarchies: private indicates that a symbol is accessible only in the immediate scope, fileprivate indicates it is accessible only from within the file, internal indicates it is accessible within the containing module, public indicates it is accessible from any module, and open (only for classes and their methods) indicates that the class may be subclassed outside of the module.An important new feature in Swift is option types, which allow references or values to operate in a manner similar to the common pattern in C, where a pointer may refer to a value or may be null. This implies that non-optional types cannot result in a null-pointer error; the compiler can ensure this is not possible.Optional types are created with the Optional mechanism—to make an Integer that is nullable, one would use a declaration similar to var optionalInteger: Optional<Int>. As in C#, Swift also includes syntactic sugar for this, allowing one to indicate a variable is optional by placing a question mark after the type name, var optionalInteger: Int?. Variables or constants that are marked optional either have a value of the underlying type or are nil. Optional types wrap the base type, resulting in a different instance. String and String? are fundamentally different types, the latter has more in common with Int? than String.To access the value inside, assuming it is not nil, it must be unwrapped to expose the instance inside. This is performed with the ! operator:In this case, the ! operator unwraps anOptionalInstance to expose the instance inside, allowing the method call to be made on it. If anOptionalInstance is nil, a null-pointer error occurs. This can be annoying in practice, so Swift also includes the concept of optional chaining to test whether the instance is nil and then unwrap it if it is non-null:In this case the runtime only calls someMethod if anOptionalInstance is not nil, suppressing the error. Normally this requires the programmer to test whether myValue is nil before proceeding. The origin of the term chaining comes from the more common case where several method calls/getters are chained together. For instance:can be reduced to:The ? syntax circumvents the pyramid of doom.Swift 2 introduced the new keyword guard for cases in which code should stop executing if some condition is unmet:Using guard has three benefits. While the syntax can act as an if statement, its primary benefit is inferring non-nullability. Where an if statement requires a case, guard assumes the case based on the condition provided. Also, since guard contains no scope, with exception of the else closure, leaseStart is presented as an unwrapped optional to the guard's super-scope. Lastly, if the guard statement's test fails, Swift requires the else to exit the current method or loop, ensuring leaseStart never is accessed when nil.  This is performed with the keywords return, continue, break, or throw.ObjC was weakly typed, and allowed any method to be called on any object at any time. If the method call failed, there was a default handler in the runtime that returned nil. That meant that no unwrapping or testing was needed, the equivalent statement in ObjC:would return nil and this could be tested. However, this also demanded that all method calls be dynamic, which introduces significant overhead. Swift's use of optionals provides a similar mechanism for testing and dealing with nils, but does so in a way that allows the compiler to use static dispatch because the unwrapping action is called on a defined instance (the wrapper), versus occurring in the runtime dispatch system.In many object-oriented languages, objects are represented internally in two parts. The object is stored as a block of data placed on the heap, while the name (or handle) to that object is represented by a pointer. Objects are passed between methods by copying the value of the pointer, allowing the same underlying data on the heap to be accessed by anyone with a copy. In contrast, basic types like integers and floating point values are represented directly; the handle contains the data, not a pointer to it, and that data is passed directly to methods by copying. These styles of access are termed pass-by-reference in the case of objects, and pass-by-value for basic types.Both concepts have their advantages and disadvantages. Objects are useful when the data is large, like the description of a window or the contents of a document. In these cases, access to that data is provided by copying a 32- or 64-bit value, versus copying an entire data structure. However, smaller values like integers are the same size as pointers (typically both are one word), so there is no advantage to passing a pointer, versus passing the value. Also, pass-by-reference inherently requires a dereferencing operation, which can produce noticeable overhead in some operations, typically those used with these basic value types, like mathematics.Similarly to C# and in contrast to most other OO languages,[citation needed] Swift offers built-in support for objects using either pass-by-reference or pass-by-value semantics, the former using the class declaration and the latter using struct. Structs in Swift have almost all the same features as classes: methods, implementing protocols, and using the extension mechanisms. For this reason, Apple terms all data generically as instances, versus objects or values. Structs do not support inheritance, however.The programmer is free to choose which semantics are more appropriate for each data structure in the application. Larger structures like windows would be defined as classes, allowing them to be passed around as pointers. Smaller structures, like a 2D point, can be defined as structs, which will be pass-by-value and allow direct access to their internal data with no dereference. The performance improvement inherent to the pass-by-value concept is such that Swift uses these types for almost all common data types, including Int and Double, and types normally represented by objects, like String and Array. Using value types can result in significant performance improvements in user applications also.To ensure that even the largest structs do not cause a performance penalty when they are handed off, Swift uses copy on write so that the objects are copied only if and when the program attempts to change a value in them. This means that the various accessors have what is in effect a pointer to the same data storage, but this takes place far below the level of the language, in the computer's memory management unit (MMU). So while the data is physically stored as one instance in memory, at the level of the application, these values are separate, and physical separation is enforced by copy on write only if needed.A key feature of ObjC is its support for categories, methods that can be added to extend classes at runtime. Categories allow extending classes in-place to add new functions with no need to subclass or even have access to the original source code. An example might be to add spell checker support to the base NSString class, which means all instances of NSString in the application gain spell checking. The system is also widely used as an organizational technique, allowing related code to be gathered into library-like extensions. Swift continues to support this concept, although they are now termed extensions, and declared with the keyword extension. Unlike ObjC, Swift can also add new properties accessors, types and enums to extant instances.Another key feature of ObjC is its use of protocols, known in most modern languages as interfaces. Protocols promise that a particular class implements a set of methods, meaning that other objects in the system can call those methods on any object supporting that protocol. This is often used in modern OO languages as a substitute for multiple inheritance, although the feature sets are not entirely similar. A common example of a protocol in Cocoa is the NSCopying protocol, which defines one method, copyWithZone, that implements deep copying on objects.In ObjC, and most other languages implementing the protocol concept, it is up to the programmer to ensure that the required methods are implemented in each class. Swift adds the ability to add these methods using extensions, and to use generic programming (generics) to implement them. Combined, these allow protocols to be written once and support a wide variety of instances. Also, the extension mechanism can be used to add protocol conformance to an object that does not list that protocol in its definition.For example, a protocol might be declared called SupportsToString, which ensures that instances that conform to the protocol implement a toString method that returns a String. In Swift, this can be declared with code like this:This protocol can now be added to String, with no access to the base class's source:In Swift, like many modern languages supporting interfaces, protocols can be used as types, which means variables and methods can be defined by protocol instead of their specific type:It does not matter what sort of instance someSortOfPrintableObject is, the compiler will ensure that it conforms to the protocol and thus this code is safe. This syntax also means that collections can be based on protocols also, like let printableArray = [SupportsToString].As Swift treats structs and classes as similar concepts, both extensions and protocols are extensively used in Swift's runtime to provide a rich API based on structs. For instance, Swift uses an extension to add the Equatable protocol to many of their basic types, like Strings and Arrays, allowing them to be compared with the == operator. A concrete example of how all of these features interact can be seen in the concept of default protocol implementations:This function defines a method that works on any instance conforming to Equatable, providing a not equals function. Any instance, class or struct, automatically gains this implementation simply by conforming to Equatable. As many instances gain Equatable through their base implementations or other generic extensions, most basic objects in the runtime gain equals and not equals with no code.This combination of protocols, defaults, protocol inheritance, and extensions allows many of the functions normally associated with classes and inheritance to be implemented on value types. Properly used, this can lead to dramatic performance improvements with no significant limits in API. This concept is so widely used within Swift, that Apple has begun calling it a protocol-oriented programming language. They suggest addressing many of the problem domains normally solved though classes and inheritance using protocols and structs instead.Swift uses the same runtime as the extant Objective-C system, but requires iOS 7 or macOS 10.9 or higher. Swift and Objective-C code can be used in one program, and by extension, C and C++ also. In contrast to C, C++ code cannot be used directly from Swift. An Objective-C or C wrapper must be created between Swift and C++. In the case of Objective-C, Swift has considerable access to the object model, and can be used to subclass, extend and use Objective-C code to provide protocol support. The converse is not true: a Swift class cannot be subclassed in Objective-C.To aid development of such programs, and the re-use of extant code, Xcode 6 offers a semi-automated system that builds and maintains a bridging header to expose Objective-C code to Swift. This takes the form of an additional header file that simply defines or imports all of the Objective-C symbols that are needed by the project's Swift code. At that point, Swift can refer to the types, functions, and variables declared in those imports as though they were written in Swift. Objective-C code can also use Swift code directly, by importing an automatically maintained header file with Objective-C declarations of the project's Swift symbols. For instance, an Objective-C file in a mixed project called MyApp could access Swift classes or functions with the code #import MyApp-Swift.h. Not all symbols are available through this mechanism, however—use of Swift-specific features like generic types, non-object optional types, sophisticated enums, or even Unicode identifiers may render a symbol inaccessible from Objective-C.Swift also has limited support for attributes, metadata that is read by the development environment, and is not necessarily part of the compiled code. Like Objective-C, attributes use the @ syntax, but the currently available set is small. One example is the @IBOutlet attribute, which marks a given value in the code as an outlet, available for use within Interface Builder (IB). An outlet is a device that binds the value of the on-screen display to an object in code.Swift uses Automatic Reference Counting (ARC) to manage memory. Apple used to require manual memory management in Objective-C, but introduced ARC in 2011 to allow for easier memory allocation and deallocation. One problem with ARC is the possibility of creating a strong reference cycle, where objects reference each other in a way that you can reach the object you started from by following references (e.g. A references B, B references A). This causes them to become leaked into memory as they are never released.  Swift provides the keywords weak and unowned to prevent strong reference cycles. Typically a parent-child relationship would use a strong reference while a child-parent would use either weak reference, where parents and children can be unrelated, or unowned where a child always has a parent, but parent may not have a child. Weak references must be optional variables, since they can change and become nil.A closure within a class can also create a strong reference cycle by capturing self references. Self references to be treated as weak or unowned can be indicated using a capture list.A key element of the Swift system is its ability to be cleanly debugged and run within the development environment, using a read–eval–print loop (REPL), giving it interactive properties more in common with the scripting abilities of Python than traditional system programming languages. The REPL is further enhanced with the new concept playgrounds. These are interactive views running within the Xcode environment that respond to code or debugger changes on-the-fly. Playgrounds allow programmers to add in Swift code along with markdown documentation. If some code changes over time or with regard to some other ranged input value, the view can be used with the Timeline Assistant to demonstrate the output in an animated way. In addition, Xcode has debugging features for Swift development including breakpoints, step through and step over statements, as well as UI element placement breakdowns for app developers. Apple says that Swift is the first industrial-quality systems programming language that is as expressive and enjoyable as a scripting language.Many of the features introduced with Swift also have well-known performance and safety trade-offs. Apple has implemented optimizations that reduce this overhead.Swift is similar to C in various ways:It also has similarities to Objective-C:Differences from Objective-C include:Since the language is open-source, there are prospects of it being ported to the web. Some web frameworks have already been developed, such as IBM's Kitura, Perfect and Vapor.An official Server APIs work group has also been started by Apple, with members of the Swift developer community playing a central role.A second free implementation of Swift that targets Cocoa, Microsoft's Common Language Infrastructure (.NET), and the Java and Android platform exists as part of the Elements Compiler from RemObjects Software."
"2"	"Cocoa is Apple's native object-oriented application programming interface (API) for their operating system macOS.For iOS, tvOS, and watchOS, a similar API exists, named Cocoa Touch, which includes gesture recognition, animation, and a different set of graphical control elements. It is used in applications for Apple devices such as iPhone, iPad, iPod Touch, Apple TV, and Apple Watch.Cocoa consists of the Foundation Kit, Application Kit, and Core Data frameworks, as included by the Cocoa.h header file, and the libraries and frameworks included by those, such as the C standard library and the Objective-C runtime.Cocoa applications are typically developed using the development tools provided by Apple, specifically Xcode (formerly Project Builder) and Interface Builder, using the languages Objective-C or Swift. However, the Cocoa programming environment can be accessed using other tools, such as Clozure CL, LispWorks, Object Pascal, Python, Perl, Ruby, and AppleScript with the aid of bridge mechanisms such as PasCocoa, PyObjC, CamelBones, RubyCocoa, and a D/Objective-C Bridge. A Ruby language implementation named MacRuby, which removes the need for a bridge mechanism, was formerly developed by Apple, while Nu is a Lisp-like language that can be used with Cocoa with no bridge.  It is also possible to write Objective-C Cocoa programs in a simple text editor and build it manually with GNU Compiler Collection (GCC) or clang from the command line or from a makefile.For end-users, Cocoa applications are those written using the Cocoa programming environment. Such applications usually have a distinctive feel, since the Cocoa programming environment automates many aspects of an application to comply with Apple's human interface guidelines.Cocoa continues the lineage of several software frameworks (mainly the App Kit and Foundation Kit)  from the NeXTSTEP and OpenStep programming environments developed by NeXT in the 1980s and 1990s. Apple acquired NeXT in December 1996, and subsequently went to work on the Rhapsody operating system that was to be the direct successor of OpenStep. It was to have had an emulation base for classic Mac OS applications, named Blue Box. The OpenStep base of libraries and binary support was termed Yellow Box. Rhapsody evolved into Mac OS X, and the Yellow Box became Cocoa. Thus, Cocoa classes begin with the letters NS, such as NSString or NSArray.  These stand for either the NeXT-Sun creation of OpenStep, or for the original proprietary term for the OpenStep framework, NeXTSTEP.Much of the work that went into developing OpenStep was applied to developing Mac OS X, Cocoa being the most visible part. However, differences exist. For example, NeXTSTEP and OpenStep used Display PostScript for on-screen display of text and graphics, while Cocoa depends on Apple's Quartz (which uses the Portable Document Format (PDF) imaging model, but not its underlying technology). Cocoa also has a level of Internet support, including the NSURL and WebKit HTML classes, and others, while OpenStep had only rudimentary support for managed network connections via NSFileHandle classes and Berkeley sockets.The resulting software framework received the name Cocoa for the sake of expediency, because the name had already been trademarked by Apple. For many years before this present use of the name, Apple's Cocoa trademark had originated as the name of a multimedia project design application for children. The application was originally developed at the Apple Advanced Technology Group under the name KidSim, and was then renamed and trademarked as Cocoa. The name, coined by Peter Jensen who was hired to develop Cocoa for Apple, was intended to evoke Java for kids, as it ran embedded in web pages.  The trademark, and thus the name Cocoa, was re-used to avoid the delay which would have occurred while registering a new trademark for this software framework.  The original Cocoa program was discontinued at Apple in one of the rationalizations that followed Steve Jobs's return to Apple.  It was then licensed to a third party and marketed as Stagecast Creator as of  2011[update].One feature of the Cocoa environment is its facility for managing dynamically allocated memory. Cocoa's NSObject class, from which most classes, both vendor and user, are derived, implements a reference counting scheme for memory management. Objects that derive from the NSObject root class respond to a retain and a release message, and keep a retain count. A method titled retainCount exists, but contrary to its name, will usually not return the exact retain count of an object. It is mainly used for system-level purposes. Invoking it manually is not recommended by Apple.A newly allocated object created with alloc or copy has a retain count of one. Sending that object a retain message increments the retain count, while sending it a release message decrements the retain count. When an object's retain count reaches zero, it is deallocated by a procedure similar to a C++ destructor. dealloc is not guaranteed to be invoked.Starting with Objective-C 2.0, the Objective-C runtime implemented an optional garbage collector, which is now obsolete and deprecated in favor of Automatic Reference Counting (ARC). In this model, the runtime turned Cocoa reference counting operations such as retain and release into no-ops.  The garbage collector does not exist on the iOS implementation of Objective-C 2.0. Garbage collection in Objective-C ran on a low-priority background thread, and can halt on Cocoa's user events, with the intention of keeping the user experience responsive.  The legacy garbage collector is still available on Mac OS X version 10.13, but no Apple-provided applications use it.In 2011, the LLVM compiler introduced Automatic Reference Counting (ARC), which replaces the conventional garbage collector by performing static analysis of Objective-C source code and inserting retain and release messages as necessary.Cocoa consists of three Objective-C object libraries called frameworks. Frameworks are functionally similar to shared libraries, a compiled object that can be dynamically loaded into a program's address space at runtime, but frameworks add associated resources, header files, and documentation.  The Cocoa frameworks are implemented as a type of bundle, containing the aforementioned items in standard locations.A key part of the Cocoa architecture is its comprehensive views model. This is organized along conventional lines for an application framework, but is based on the Portable Document Format (PDF) drawing model provided by Quartz. This allows creating custom drawing content using PostScript-like drawing commands, which also allows automatic printer support and so forth. Since the Cocoa framework manages all the clipping, scrolling, scaling and other chores of drawing graphics, the programmer is freed from implementing basic infrastructure and can concentrate on the unique aspects of an application's content.The Smalltalk teams at Xerox PARC eventually settled on a design philosophy that led to easy development and high code reuse. Named model-view-controller (MVC), the concept breaks an application into three sets of interacting object classes.Cocoa's design is a fairly, but not absolutely strict application of MVC principles. Under OpenStep, most of the classes provided were either high-level View classes (in AppKit) or one of a number of relatively low-level model classes like NSString. Compared to similar MVC systems, OpenStep lacked a strong model layer. No stock class represented a document, for instance. During the transition to Cocoa, the model layer was expanded greatly, introducing a number of pre-rolled classes to provide functionality common to desktop applications.In Mac OS X 10.3, Apple introduced the NSController family of classes, which provide predefined behavior for the controller layer. These classes are considered part of the Cocoa Bindings system, which also makes extensive use of protocols such as Key-Value Observing and Key-Value Binding. The term 'binding' refers to a relationship between two objects, often between a view and a controller. Bindings allow the developer to focus more on declarative relationships rather than orchestrating fine-grained behavior.With the arrival of Mac OS X 10.4, Apple extended this foundation further by introducing the Core Data framework, which standardizes change tracking and persistence in the model layer. In effect, the framework greatly simplifies the process of making changes to application data, undoing changes (if necessary), saving data to disk, and reading it back in.By providing framework support for all three MVC layers, Apple's goal is to reduce the amount of boilerplate or glue code that developers have to write, freeing up resources to spend time on application-specific features.In most object-oriented languages, calls to methods are represented physically by a pointer to the code in memory. This restricts the design of an application since specific command handling classes are needed, usually organized according to the chain-of-responsibility pattern. While Cocoa retains this approach for the most part, Objective-C's late binding opens up more flexibility.Under Objective-C, methods are represented by a selector, a string describing the method to call. When a message is sent, the selector is sent into the Objective-C runtime, matched against a list of available methods, and the method's implementation is called. Since the selector is text data, this lets it be saved to a file, transmitted over a network or between processes, or manipulated in other ways. The implementation of the method is looked up at runtime, not compile time. There is a small performance penalty for this, but late binding allows the same selector to reference different implementations.By a similar token, Cocoa provides a pervasive data manipulation method called key-value coding (KVC). This allows a piece of data or property of an object to be looked up or changed at runtime by name. The property name acts as a key to the value. In traditional languages, this late binding is impossible. KVC leads to great design flexibility. An object's type need not be known, yet any property of that object can be discovered using KVC. Also, by extending this system using something Cocoa terms key-value observing (KVO), automatic support for undo-redo is provided.Late static binding is a variant of binding somewhere between static and dynamic binding. The binding of names before the program is run is called static (early); bindings performed as the program runs are dynamic (late or virtual).One of the most useful features of Cocoa is the powerful base objects the system supplies. As an example, consider the Foundation classes NSString and NSAttributedString, which provide Unicode strings, and the NSText system in AppKit, which allows the programmer to place string objects in the GUI.NSText and its related classes are used to display and edit strings. The collection of objects involved permit an application to implement anything from a simple single-line text entry field to a complete multi-page, multi-column text layout schema, with full professional typography features such as kerning, ligatures, running text around arbitrary shapes, rotation, full Unicode support and anti-aliased glyph rendering. Paragraph layout can be controlled automatically or by the user, using a built-in ruler object that can be attached to any text view. Spell checking is automatic, using a single dictionary used by all applications that uses the squiggly underlining convention introduced by Microsoft (actually a dashed red underline in Cocoa). Unlimited undo-redo support is built in. Using only the built-in features, one can write a text editor application in as few as 10 lines of code. With new controller objects, this may fall to zero[clarification needed]. This is in contrast to the TextEdit APIs found in the earlier Mac OS.When extensions are needed, Cocoa's use of Objective-C makes this a straightforward task. Objective-C includes the concept of categories, which allows modifying existing class in-place. Functionality can be accomplished in a category without any changes to the original classes in the framework, or even access to its source. Under more common frameworks, this same task requires making a new subclass supporting the added features, and then changing all instances of the classes to this new class.The Cocoa frameworks are written in Objective-C, and hence that is the preferred language for developing Cocoa applications.[citation needed] Java bindings for the Cocoa frameworks (termed the Java bridge) were also made available with the aim of replacing Objective-C with a more popular language but these bindings were unpopular among Cocoa developers and Cocoa's message passing semantics did not translate well to a statically-typed language such as Java. Cocoa's need for runtime binding means many of Cocoa's key features are not available with Java. In 2005, Apple announced that the Java bridge was to be deprecated, meaning that features added to Cocoa in macOS versions later than 10.4 would not be added to the Cocoa-Java programming interface.At Apple Worldwide Developers Conference (WWDC) 2014, Apple introduced a new programming language named Swift, which is intended to replace Objective-C.Originally, AppleScript Studio could be used to develop simpler Cocoa applications.  However, as of Snow Leopard, it has been deprecated. It was replaced with AppleScriptObjC, which allows programming in AppleScript, while using Cocoa frameworks.Third-party bindings available for other languages include Clozure CL, Monobjc and NObjective (C#), Cocoa# (CLI), Cocodao and D/Objective-C Bridge,LispWorks, CamelBones (Perl), PyObjC (Python), FPC PasCocoa (Lazarus and Free Pascal), RubyCocoa (Ruby).Nu uses the Objective-C object model directly, and thus can use the Cocoa frameworks without needing a binding.There are also open source implementations of major parts of the Cocoa framework, such as GNUstep and Cocotron, which allow cross-platform Cocoa application development to target other operating systems, such as Microsoft Windows and Linux."
"3"	"In object-oriented computer programming, a null object is an object with no referenced value or with defined neutral (null) behavior. The null object design pattern describes the uses of such objects and their behavior (or lack thereof). It was first published in the Pattern Languages of Program Design book series.In most object-oriented languages, such as Java or C#, references may be null. These references need to be checked to ensure they are not null before invoking any methods, because methods typically cannot be invoked on null references.The Objective-C language takes another approach to this problem and does nothing when sending a message to nil; if a return value is expected, nil (for objects), 0 (for numeric values), NO (for BOOL values), or a struct (for struct types) with all its members initialised to null/0/NO/zero-initialised struct is returned.Instead of using a null reference to convey absence of an object (for instance, a non-existent customer), one uses an object which implements the expected interface, but whose method body is empty. The advantage of this approach over a working default implementation is that a null object is very predictable and has no side effects: it does nothing.For example, a function may retrieve a list of files in a folder and perform some action on each. In the case of an empty folder, one response may be to throw an exception or return a null reference rather than a list. Thus, the code which expects a list must verify that it in fact has one before continuing, which can complicate the design.By returning a null object (i.e. an empty list) instead, there is no need to verify that the return value is in fact a list. The calling function may simply iterate the list as normal, effectively doing nothing. It is, however, still possible to check whether the return value is a null object (an empty list) and react differently if desired.The null object pattern can also be used to act as a stub for testing, if a certain feature such as a database is not available for testing.Given a binary tree, with this node structure:One may implement a tree size procedure recursively:Since the child nodes may not exist, one must modify the procedure by adding non-existence or null checks:This however makes the procedure more complicated by mixing boundary checks with normal logic, and it becomes harder to read. Using the null object pattern, one can create a special version of the procedure but only for null nodes:This separates normal logic from special case handling, and makes the code easier to understand.It can be regarded as a special case of the State pattern and the Strategy pattern.It is not a pattern from Design Patterns, but is mentioned in Martin Fowler's Refactoring and Joshua Kerievsky's Refactoring To Patterns as the Insert Null Object refactoring.Chapter 17 of Robert Cecil Martin's Agile Software Development: Principles, Patterns and Practices is dedicated to the pattern.From C# 6.0 it is possible to use the ?. operator (aka null-conditional operator), which will simply evaluate to null if its left operand is null.In some Microsoft .NET languages, Extension methods can be used to perform what is called 'null coalescing'. This is because extension methods can be called on null values as if it concerns an 'instance method invocation' while in fact extension methods are static. Extension methods can be made to check for null values, thereby freeing code that uses them from ever having to do so. Note that the example below uses the C# Null coalescing operator to guarantee error free invocation, where it could also have used a more mundane if...then...else.A language with statically typed references to objects illustrates how the null object becomes a more complicated pattern:Here, the idea is that there are situations where a pointer or reference to an animal object is required, but there is no appropriate object available. A null reference is impossible in standard-conforming C++. A null animal * pointer is possible, and could be useful as a place-holder, but may not be used for direct dispatch: a->make_sound() is undefined behavior if a is a null pointer.The null object pattern solves this problem by providing a special null_animal class which can be instantiated bound to an animal pointer or reference.The special null class must be created for each class hierarchy that is to have a null object, since a null_animal is of no use when what is needed is a null object with regard to some widget base class that is not related to the animal hierarchy.Note, that NOT having a null class at all is an important feature, in contrast to languages where anything is a reference (e.g. Java and C#). In C++, the design of a function or method may explicitly state whether null is allowed or not.C# is a language in which the null object pattern can be properly implemented. This example shows animal objects that display sounds and a NullAnimal instance used in place of the C# null keyword. The null object provides consistent behaviour and prevents a runtime null reference exception that would occur if the C# null keyword were used instead.Following the Smalltalk principle, everything is an object, the absence of an object is itself modeled by an object, called nil. In the GNU Smalltalk for example, the class of  nil is UndefinedObject, a direct descendant of Object.Any operation that fails to return a sensible object for its purpose may return nil instead, thus avoiding the special case of returning no object. This method has the advantage of simplicity (no need for a special case) over the classical null or no object or null reference approach. Especially useful messages to be used with nil are isNil or ifNil:, which make it practical and safe to deal with possible references to nil in Smalltalk programs.In Lisp, functions can gracefully accept the special object nil, which reduces the amount of special case testing in application code. For instance, although nil is an atom and does not have any fields, the functions car and cdr accept nil and just return it, which is very useful and results in shorter code.Since nil is the empty list in Lisp, the situation described in the introduction above doesn't exist. Code which returns nil is returning what is in fact the empty list (and not anything resembling a  null reference to a list type), so the caller does not need to test the value to see whether or not it has a list.The null object pattern is also supported in multiple value processing. If the program attempts to extract a value from an expression which returns no values, the behavior is that the null object nil is substituted. Thus (list (values)) returns (nil) (a one-element list containing nil). The (values) expression returns no values at all, but since the function call to list needs to reduce its argument expression to a value, the null object is automatically substituted.In Common Lisp, the object nil is the one and only instance of the special class null. What this means is that a method can be specialized to the null class, thereby implementing the null design pattern. Which is to say, it is essentially built into the object system:The class null is a subclass of the symbol class, because nil is a symbol. Since nil also represents the empty list, null is a subclass of the list class, too. Methods parameters specialized to symbol or list will thus take a nil argument. Of course, a null specialization can still be defined which is a more specific match for nil.Unlike Common Lisp, and many dialects of Lisp, the Scheme dialect does not have a nil value which works this way; the functions car and cdr may not be applied to an empty list; Scheme application code therefore has to use the empty? or pair? predicate functions to sidestep this situation, even in situations where very similar Lisp would not need to distinguish the empty and non-empty cases thanks to the behavior of nil.In duck-typed languages like Ruby, language inheritance is not necessary to provide expected behavior. Attempts to directly monkey-patch NilClass instead of providing explicit implementations give more unexpected side effects than benefits.In duck-typed languages like JavaScript, language inheritance is not necessary to provide expected behavior.This code illustrates a variation of the C++ example, above, using the Java language. As with C++, a null class can be instantiated in situations where a reference to an Animal object is required, but there is no appropriate object available. A null Animal object is possible (Animal myAnimal = null;) and could be useful as a place-holder, but may not be used for calling a method. In this example, myAnimal.makeSound(); will throw a NullPointerException. Therefore, additional code may be necessary to test for null objects.The null object pattern solves this problem by providing a special NullAnimal class which can be instantiated as an object of type Animal. As with C++ and related languages, that special null class must be created for each class hierarchy that needs a null object, since a NullAnimal is of no use when what is needed is a null object that does not implement the Animal interface.The following null object pattern implementation demonstrates the concrete class providing its corresponding null object in a static field Empty. This approach is frequently used in the .NET Framework (String.Empty, EventArgs.Empty, Guid.Empty, etc.).This pattern should be used carefully as it can make errors/bugs appear as normal program execution.Care should be taken not to implement this pattern just to avoid null checks and make code more readable, since the harder to read code may just move to another place and be less standard - such as when different logic must execute in case the object provided is indeed the null object. The common pattern in most languages with reference types is to compare a reference to a single value referred to as null or nil. Also, there is additional need for testing that no code anywhere ever assigns null instead of the null object, because in most cases and languages with static typing, this is not a compiler error if the null object is of a reference type, although it would certainly lead to errors at run time in parts of the code where the pattern was used to avoid null checks. On top of that, in most languages and assuming there can be many null objects (i.e. the null object is a reference type but doesn't implement the singleton pattern in one or another way), checking for the null object instead of for the null or nil value introduces overhead, as does the singleton pattern likely itself upon obtaining the singleton reference."
"4"	"Chris Lattner (born 1978) is an American software developer, best known as the main author of LLVM and related projects, such as the compiler Clang and the programming language Swift. He works at Google Brain, following a brief stint at Tesla, Inc.  as Vice President of Autopilot Software. Prior to that, he worked at Apple Inc. as Senior Director of the Developer Tools department, leading the Xcode, Instruments, and compiler teams.Lattner studied computer science at the University of Portland, Oregon, graduating in 2000. While in Oregon, he worked as an operating system developer, enhancing Sequent Computer Systems's DYNIX/ptx. He is married to compiler engineer Tanya Lattner, who has been serving as president of the LLVM Foundation since 2015.In late 2000, Lattner joined the University of Illinois at Urbana-Champaign as a research assistant and M.Sc. student. While working with Vikram Adve, he designed and began implementing LLVM, an innovative infrastructure for optimizing compilers, which was the subject of his 2002 M.Sc. thesis. He completed his Ph.D. in 2005, researching new techniques for optimizing pointer-intensive programs and adding them to LLVM.[citation needed]In 2005, Apple Inc. hired Lattner to begin work bringing LLVM to production quality for use in Apple products.  Over time, Lattner built out the technology, personally implementing many major new features in LLVM, formed and built a team of LLVM developers at Apple, started the Clang project, took responsibility for evolving Objective-C (contributing to the blocks language feature, and driving the ARC and Objective-C literals features), and nurtured the open source community (leading it through many open source releases). Apple first shipped LLVM-based technology in the 10.5 (and 10.4.8) OpenGL stack as a just-in-time (JIT) compiler, shipped the llvm-gcc compiler in the integrated development environment (IDE) Xcode 3.1, Clang 1.0 in Xcode 3.2, Clang 2.0 (with C++ support) in Xcode 4.0, and LLDB, libc++, assemblers, and disassembler technology in later releases.[citation needed]Lattner's recent work involves designing, implementing, and evangelizing the LLVM and Clang compilers, productizing and driving the debugger LLDB, and overseeing development of the low-level toolchain. As of 2016, LLVM technologies are the core of Apple's developer tools and the default toolchain on FreeBSD.[citation needed]In June 2010, the Association for Computing Machinery (ACM) Special Interest Group on programming languages (SIGPLAN) gave Lattner its inaugural ACM SIGPLAN Programming Languages Software Award for his design and development of the Low Level Virtual Machine, noting that Professor Adve has stated: Lattner’s talent as a compiler architect, together with his programming skills, technical vision, and leadership ability were crucial to the success of LLVM.In April 2013, the ACM awarded Lattner its Software System Award, which is presented to anyone recognized for developing a software system that has had a lasting influence, reflected in contributions to concepts, in commercial acceptance, or both.Swift is an open sourceprogramming language with first-class functions for iOS and macOS development, created by Apple and introduced at Apple's developer conference Apple Worldwide Developers Conference (WWDC) 2014.Swift is designed to coexist with Objective-C, the object-oriented programming language formerly preferred by Apple, and to be more resilient against erroneous code. It is built with the LLVM compiler included in Xcode 6.Lattner began developing Swift in 2010, with the eventual collaboration of many other programmers. On June 2, 2014, the WWDC app became the first publicly released app that used Swift.He then decided to give the Project Lead role to Ted Kremenek in January 2017."
"5"	"Automatic Reference Counting (ARC) is a memory management feature of the Clang compiler providing automatic reference counting for the Objective-C and Swift programming languages. At compile time, it inserts into the object code messages retain and release which increase and decrease the reference count at run time, marking for deallocation those objects when the number of references to them reaches zero.ARC differs from tracing garbage collection in that there is no background process that deallocates the objects asynchronously at runtime. Unlike garbage collection, ARC does not handle reference cycles automatically. This means that as long as there are strong references to an object, it will not be deallocated. Strong cross-references can accordingly create deadlocks and memory leaks. It is up to the developer to break cycles by using weak references.Apple Inc. deploys ARC in their operating systems, such as macOS (OS X) and iOS. Limited support (ARCLite) has been available since Mac OS X Snow Leopard and iOS 4, with complete support following in Mac OS X Lion and iOS 5. Garbage collection was declared deprecated in OS X Mountain Lion, in favor of ARC, and removed from the Objective-C runtime library in macOS Sierra.The following rules are enforced by the compiler when ARC is turned on:ARC introduces some new property declaration attributes, some of which replace the old attributes.Zeroing weak references is a feature in Objective-C ARC that automatically clears (sets to nil) weak-reference local variables, instance variables, and declared properties immediately before the object being pointed to starts deallocating. This ensures that the pointer goes to either a valid object or nil, and avoids dangling pointers. Prior to the introduction of this feature, weak references referred to references that were not retaining, but were not set to nil when the object they pointed to was deallocated (equivalent to unsafe_unretained in ARC), thus possibly leading to a dangling pointer. The programmer typically had to ensure that all possible weak references to an object were set to nil manually when it was being deallocated. Zeroing weak references obviates the need to do this.Zeroing weak references are indicated by using the declared property attribute weak or by using the variable attribute __weak.Zeroing weak references are only available in Mac OS X Lion (10.7) or later and iOS 5 or later, because they require additional support from the Objective-C runtime.  However, some OS X classes do not currently support weak references. Code that uses ARC but needs to support versions of the OS older than those above cannot use zeroing weak references, and therefore must use unsafe_unretained weak references. There exists a third-party library called PLWeakCompatibility  that allows one to use zeroing weak references even on these older OS versions.Xcode 4.2 or later provides a way to convert code to ARC.  As of Xcode 4.5, it is found by choosing Edit > Refactor > Convert to Objective-C ARC... Although Xcode will automatically convert most code, some code may have to be converted manually.  Xcode will inform the developer when more complex use cases arise, such as when a variable is declared inside an autorelease pool and used outside it or when two objects need to be toll-free bridged with special casts.In Swift, references to objects are strong, unless they are declared weak or unowned. Swift requires explicit handling of nil with the Optional type: a value type that can either have a value or be nil. An Optional type must be handled by unwrapping it with a conditional statement, allowing safe usage of the value, if present. Conversely, any non-Optional type will always have a value and cannot be nil.Accordingly, a strong reference to an object cannot be of type Optional, as the object will be kept in the heap until the reference itself is deallocated. A weak reference is of type Optional, as the object can be deallocated and the reference be set to nil. Unowned references fall in-between; they are neither strong nor of type Optional. Instead, the compiler assumes that the object to which an unowned reference points is not deallocated as long the reference itself remains allocated. This is typically used in situations where the target object itself holds a reference to the object that holds the unowned reference.Swift also differs from Objective-C in its usage and encouragement of value types instead of reference types. Most types in the Swift standard library are value types and they are copied by reference, whereas classes and closures are reference types and passed by reference. Because value types are copied when passed around, they are deallocated automatically with the reference that created them."
"6"	"Objective-C is a general-purpose, object-oriented programming language that adds Smalltalk-style messaging to the C programming language. It was the main programming language used by Apple for the OS X and iOS operating systems, and their respective application programming interfaces (APIs) Cocoa and Cocoa Touch prior to the introduction of Swift.The programming language Objective-C was originally developed in the early 1980s. It was selected as the main language used by NeXT for its NeXTSTEP operating system, from which OS X and iOS are derived. Portable Objective-C programs that do not use the Cocoa or Cocoa Touch libraries, or those using parts that may be ported or reimplemented for other systems, can also be compiled for any system supported by GNU Compiler Collection (GCC) or Clang.Objective-C source code 'implementation' program files usually have .m filename extensions, while Objective-C 'header/interface' files have .h extensions, the same as C header files. Objective-C++ files are denoted with a .mm file extension.Objective-C was created primarily by Brad Cox and Tom Love in the early 1980s at their company Stepstone. Both had been introduced to Smalltalk while at ITT Corporation's Programming Technology Center in 1981. The earliest work on Objective-C traces back to around that time. Cox was intrigued by problems of true reusability in software design and programming. He realized that a language like Smalltalk would be invaluable in building development environments for system developers at ITT. However, he and Tom Love also recognized that backward compatibility with C was critically important in ITT's telecom engineering milieu.Cox began writing a pre-processor for C to add some of the abilities of Smalltalk. He soon had a working implementation of an object-oriented extension to the C language, which he called OOPC for Object-Oriented Pre-Compiler. Love was hired by Schlumberger Research in 1982 and had the opportunity to acquire the first commercial copy of Smalltalk-80, which further influenced the development of their brainchild.In order to demonstrate that real progress could be made, Cox showed that making interchangeable software components really needed only a few practical changes to existing tools. Specifically, they needed to support objects in a flexible manner, come supplied with a usable set of libraries, and allow for the code (and any resources needed by the code) to be bundled into one cross-platform format.Love and Cox eventually formed a new venture, Productivity Products International (PPI), to commercialize their product, which coupled an Objective-C compiler with class libraries. In 1986, Cox published the main description of Objective-C in its original form in the book Object-Oriented Programming, An Evolutionary Approach. Although he was careful to point out that there is more to the problem of reusability than just the language, Objective-C often found itself compared feature for feature with other languages.In 1988, NeXT licensed Objective-C from StepStone (the new name of PPI, the owner of the Objective-C trademark) and extended the GCC compiler to support Objective-C. NeXT developed the AppKit and Foundation Kit libraries on which the NeXTSTEP user interface and Interface Builder were based. While the NeXT workstations failed to make a great impact in the marketplace, the tools were widely lauded in the industry. This led NeXT to drop hardware production and focus on software tools, selling NeXTSTEP (and OpenStep) as a platform for custom programming.In order to circumvent the terms of the GPL, NeXT had originally intended to ship the Objective-C frontend separately, allowing the user to link it with GCC to produce the compiler executable. After being initially accepted by Richard M. Stallman, this plan was rejected after Stallman consulted with GNU's lawyers and NeXT agreed to make Objective-C part of GCC.The work to extend GCC was led by Steve Naroff, who joined NeXT from StepStone. The compiler changes were made available as per GPL license terms, but the runtime libraries were not, rendering the open source contribution unusable to the general public.  This led to other parties developing such runtime libraries under open source license.  Later, Steve Naroff was also principal contributor to work at Apple to build the Objective-C frontend to Clang.The GNU project started work on its free software implementation of Cocoa, named GNUstep, based on the OpenStep standard. Dennis Glatting wrote the first GNU Objective-C runtime in 1992. The GNU Objective-C runtime, which has been in use since 1993, is the one developed by Kresten Krab Thorup when he was a university student in Denmark.[citation needed] Thorup also worked at NeXT from 1993 to 1996.After acquiring NeXT in 1996, Apple Computer used OpenStep in its new operating system, OS X. This included Objective-C, NeXT's Objective-C-based developer tool, Project Builder, and its interface design tool, Interface Builder, both now merged into one application, Xcode. Most of Apple's current Cocoa API is based on OpenStep interface objects and is the most significant Objective-C environment being used for active development.At WWDC 2014, Apple introduced a new language, Swift, which was characterized as Objective-C without the C.Objective-C is a thin layer atop C, and is a strict superset of C, meaning that it is possible to compile any C program with an Objective-C compiler, and to freely include C language code within an Objective-C class.Objective-C derives its object syntax from Smalltalk. All of the syntax for non-object-oriented operations (including primitive variables, pre-processing, expressions, function declarations, and function calls) are identical to those of C, while the syntax for object-oriented features is an implementation of Smalltalk-style messaging.The Objective-C model of object-oriented programming is based on message passing to object instances. In Objective-C one does not call a method; one sends a message. This is unlike the Simula-style programming model used by C++. The difference between these two concepts is in how the code referenced by the method or message name is executed. In a Simula-style language, the method name is in most cases bound to a section of code in the target class by the compiler. In Smalltalk and Objective-C, the target of a message is resolved at runtime, with the receiving object itself interpreting the message. A method is identified by a selector or SEL — a NUL-terminated string representing its name — and resolved to a C method pointer implementing it: an IMP. A consequence of this is that the message-passing system has no type checking. The object to which the message is directed — the receiver — is not guaranteed to respond to a message, and if it does not, it raises an exception.Sending the message method to the object pointed to by the pointer obj would require the following code in C++:In Objective-C, this is written as follows:Both styles of programming have their strengths and weaknesses. Object-oriented programming in the Simula (C++) style allows multiple inheritance and faster execution by using compile-time binding whenever possible, but it does not support dynamic binding by default. It also forces all methods to have a corresponding implementation unless they are abstract. The Smalltalk-style programming as used in Objective-C allows messages to go unimplemented, with the method resolved to its implementation at runtime. For example, a message may be sent to a collection of objects, to which only some will be expected to respond, without fear of producing runtime errors. Message passing also does not require that an object be defined at compile time. An implementation is still required for the method to be called in the derived object. (See the dynamic typing section below for more advantages of dynamic (late) binding.)Objective-C requires that the interface and implementation of a class be in separately declared code blocks. By convention, developers place the interface in a header file and the implementation in a code file. The header files, normally suffixed .h, are similar to C header files while the implementation (method) files, normally suffixed .m, can be very similar to C code files.In other programming languages, this is called a class declaration.The interface of a class is usually defined in a header file. A common convention is to name the header file after the name of the class, e.g. Ball.h would contain the interface for the class Ball.An interface declaration takes the form:In the above, plus signs denote class methods, or methods that can be called on the class itself (not on an instance), and minus signs denote instance methods, which can only be called on a particular instance of the class. Class methods also have no access to instance variables.The code above is roughly equivalent to the following C++ interface:Note that instanceMethod2With2Parameters:param2_callName: demonstrates the interleaving of selector segments with argument expressions, for which there is no direct equivalent in C/C++.Return types can be any standard C type, a pointer to a generic Objective-C object, a pointer to a specific type of object such as NSArray *, NSImage *, or NSString *, or a pointer to the class to which the method belongs (instancetype). The default return type is the generic Objective-C type id.Method arguments begin with a name labeling the argument that is part of the method name, followed by a colon followed by the expected argument type in parentheses and the argument name. The label can be omitted.The interface only declares the class interface and not the methods themselves: the actual code is written in the implementation file. Implementation (method) files normally have the file extension .m, which originally signified messages.Methods are written using their interface declarations. Comparing Objective-C and C:The syntax allows pseudo-naming of arguments.Internal representations of a method vary between different implementations of Objective-C. If myColor is of the class Color, instance method -changeColorToRed:green:blue: might be internally labeled _i_Color_changeColorToRed_green_blue. The i is to refer to an instance method, with the class and then method names appended and colons changed to underscores. As the order of parameters is part of the method name, it cannot be changed to suit coding style or expression as with true named parameters.However, internal names of the function are rarely used directly. Generally, messages are converted to function calls defined in the Objective-C runtime library. It is not necessarily known at link time which method will be called because the class of the receiver (the object being sent the message) need not be known until runtime.Once an Objective-C class is written, it can be instantiated. This is done by first allocating an uninitialized instance of the class (an object) and then by initializing it. An object is not fully functional until both steps have been completed. These steps should be accomplished with one line of code so that there is never an allocated object that hasn't undergone initialization (and because it is unwise to keep the intermediate result since -init can return a different object than that on which it is called).Instantiation with the default, no-parameter initializer:Instantiation with a custom initializer:In the case where no custom initialization is being performed, the new method can often be used in place of the alloc-init messages:Also, some classes implement class method initializers. Like +new, they combine +alloc and -init, but unlike +new, they return an autoreleased instance. Some class method initializers take parameters:The alloc message allocates enough memory to hold all the instance variables for an object, sets all the instance variables to zero values, and turns the memory into an instance of the class; at no point during the initialization is the memory an instance of the superclass.The init message performs the set-up of the instance upon creation. The init method is often written as follows:In the above example, notice the id return type. This type stands for pointer to any object in Objective-C (See the Dynamic typing section).The initializer pattern is used to assure that the object is properly initialized by its superclass before the init method performs its initialization. It performs the following actions:A non-valid object pointer has the value nil; conditional statements like if treat nil like a null pointer, so the initialization code will not be executed if [super init] returned nil. If there is an error in initialization the init method should perform any necessary cleanup, including sending a release message to self, and return nil to indicate that initialization failed. Any checking for such errors must only be performed after having called the superclass initialization to ensure that destroying the object will be done correctly.If a class has more than one initialization method, only one of them (the designated initializer) needs to follow this pattern; others should call the designated initializer instead of the superclass initializer.In other programming languages, these are called interfaces.Objective-C was extended at NeXT to introduce the concept of multiple inheritance of specification, but not implementation, through the introduction of protocols. This is a pattern achievable either as an abstract multiple inherited base class in C++, or as an interface (as in Java and C#). Objective-C makes use of ad hoc protocols called informal protocols and compiler-enforced protocols called formal protocols.An informal protocol is a list of methods that a class can opt to implement. It is specified in the documentation, since it has no presence in the language. Informal protocols are implemented as a category (see below) on NSObject and often include optional methods, which, if implemented, can change the behavior of a class. For example, a text field class might have a delegate that implements an informal protocol with an optional method for performing auto-completion of user-typed text. The text field discovers whether the delegate implements that method (via reflection) and, if so, calls the delegate's method to support the auto-complete feature.A formal protocol is similar to an interface in Java, C#, and Ada 2005. It is a list of methods that any class can declare itself to implement. Versions of Objective-C before 2.0 required that a class must implement all methods in a protocol it declares itself as adopting; the compiler will emit an error if the class does not implement every method from its declared protocols. Objective-C 2.0 added support for marking certain methods in a protocol optional, and the compiler will not enforce implementation of optional methods.A class must be declared to implement that protocol to be said to conform to it. This is detectable at runtime. Formal protocols cannot provide any implementations; they simply assure callers that classes that conform to the protocol will provide implementations. In the NeXT/Apple library, protocols are frequently used by the Distributed Objects system to represent the abilities of an object executing on a remote system.The syntaxdenotes that there is the abstract idea of locking. By stating in the class definition that the protocol is implemented,instances of NSLock claim that they will provide an implementation for the two instance methods.Objective-C, like Smalltalk, can use dynamic typing: an object can be sent a message that is not specified in its interface. This can allow for increased flexibility, as it allows an object to capture a message and send the message to a different object that can respond to the message appropriately, or likewise send the message on to another object. This behavior is known as message forwarding or delegation (see below). Alternatively, an error handler can be used in case the message cannot be forwarded. If an object does not forward a message, respond to it, or handle an error, then the system will generate a runtime exception.  If messages are sent to nil (the null object pointer), they will be silently ignored or raise a generic exception, depending on compiler options.Static typing information may also optionally be added to variables. This information is then checked at compile time. In the following four statements, increasingly specific type information is provided. The statements are equivalent at runtime, but the extra information allows the compiler to warn the programmer if the passed argument does not match the type specified.In the above statement, foo may be of any class.In the above statement, foo may be an instance of any class that conforms to the NSCopying protocol.In the above statement, foo must be an instance of the NSNumber class.In the above statement, foo must be an instance of the NSNumber class, and it must conform to the NSCopying protocol.Objective-C permits the sending of a message to an object that may not respond. Rather than responding or simply dropping the message, an object can forward the message to an object that can respond. Forwarding can be used to simplify implementation of certain design patterns, such as the observer pattern or the proxy pattern.The Objective-C runtime specifies a pair of methods in ObjectAn object wishing to implement forwarding needs only to override the forwarding method with a new method to define the forwarding behavior. The action method performv:: need not be overridden, as this method merely performs an action based on the selector and arguments. Notice the SEL type, which is the type of messages in Objective-C.Note: in OpenStep, Cocoa, and GNUstep, the commonly used frameworks of Objective-C, one does not use the Object class. The - (void)forwardInvocation:(NSInvocation *)anInvocation method of the NSObject class is used to do forwarding.Here is an example of a program that demonstrates the basics of forwarding.When compiled using gcc, the compiler reports:The compiler is reporting the point made earlier, that Forwarder does not respond to hello messages. In this circumstance, it is safe to ignore the warning since forwarding was implemented. Running the program produces this output:During the design of Objective-C, one of the main concerns was the maintainability of large code bases. Experience from the structured programming world had shown that one of the main ways to improve code was to break it down into smaller pieces. Objective-C borrowed and extended the concept of categories from Smalltalk implementations to help with this process.Furthermore, the methods within a category are added to a class at run-time. Thus, categories permit the programmer to add methods to an existing class without the need to recompile that class or even have access to its source code. For example, if a system does not contain a spell checker in its String implementation, it could be added without modifying the String source code.Methods within categories become indistinguishable from the methods in a class when the program is run. A category has full access to all of the instance variables within the class, including private variables.If a category declares a method with the same method signature as an existing method in a class, the category's method is adopted. Thus categories can not only add methods to a class, but also replace existing methods. This feature can be used to fix bugs in other classes by rewriting their methods, or to cause a global change to a class's behavior within a program. If two categories have methods with the same name but different method signatures, it is undefined which category's method is adopted.Other languages have attempted to add this feature in a variety of ways. TOM took the Objective-C system a step further and allowed for the addition of variables also. Other languages have used prototype-based solutions instead, the most notable being Self.The C# and Visual Basic.NET languages implement superficially similar functionality in the form of extension methods, but these lack access to the private variables of the class.Ruby and several other dynamic programming languages refer to the technique as monkey patching.Logtalk implements a concept of categories (as first-class entities) that subsumes Objective-C categories functionality (Logtalk categories can also be used as fine-grained units of composition when defining e.g. new classes or prototypes; in particular, a Logtalk category can be virtually imported by any number of classes and prototypes).This example builds up an Integer class, by defining first a basic class with only accessor methods implemented, and adding two categories, Arithmetic and Display, which extend the basic class. While categories can access the base class's private data members, it is often good practice to access these private data members through the accessor methods, which helps keep categories more independent from the base class. Implementing such accessors is one typical usage of categories. Another is to use categories to add methods to the base class. However, it is not regarded as good practice to use categories for subclass overriding, also known as monkey patching. Informal protocols are implemented as a category on the base NSObject class. By convention, files containing categories that extend base classes will take the name BaseClass+ExtensionClass.h.Compilation is performed, for example, by:One can experiment by leaving out the #import Integer+Arithmetic.h  and [num1 add:num2] lines and omitting Integer+Arithmetic.m in compilation. The program will still run. This means that it is possible to mix-and-match added categories if needed; if a category does not need to have some ability, it can simply not be compile in.Objective-C permits a class to wholly replace another class within a program. The replacing class is said to pose as the target class.Class posing was declared deprecated with Mac OS X v10.5, and is unavailable in the 64-bit runtime. Similar functionality can be achieved by using method swizzling in categories, that swaps one method's implementation with another's that have the same signature.For the versions still supporting posing, all messages sent to the target class are instead received by the posing class. There are several restrictions:Posing, similarly with categories, allows global augmentation of existing classes. Posing permits two features absent from categories:For example,This intercepts every invocation of setMainMenu to NSApplication.In the C language, the #include pre-compile directive always causes a file's contents to be inserted into the source at that point. Objective-C has the #import directive, equivalent except that each file is included only once per compilation unit, obviating the need for include guards.Objective-C's features often allow for flexible, and often easy, solutions to programming issues.Objective-C++ is a language variant accepted by the front-end to the GNU Compiler Collection and Clang, which can compile source files that use a combination of C++ and Objective-C syntax. Objective-C++ adds to C++ the extensions that Objective-C adds to C. As nothing is done to unify the semantics behind the various language features, certain restrictions apply:At the 2006 Worldwide Developers Conference, Apple announced the release of Objective-C 2.0, a revision of the Objective-C language to include modern garbage collection, syntax enhancements, runtime performance improvements, and 64-bit support. Mac OS X v10.5, released in October 2007, included an Objective-C 2.0 compiler. GCC 4.6 supports many new Objective-C features, such as declared and synthesized properties, dot syntax, fast enumeration, optional protocol methods, method/protocol/class attributes, class extensions and a new GNU Objective-C runtime API.Objective-C 2.0 provided an optional conservative, generational garbage collector. When run in backwards-compatible mode, the runtime turned reference counting operations such as retain and release into no-ops. All objects were subject to garbage collection when garbage collection was enabled. Regular C pointers could be qualified with __strong to also trigger the underlying write-barrier compiler intercepts and thus participate in garbage collection. A zero-ing weak subsystem was also provided such that pointers marked as __weak are set to zero when the object (or more simply, GC memory) is collected. The garbage collector does not exist on the iOS implementation of Objective-C 2.0. Garbage collection in Objective-C runs on a low-priority background thread, and can halt on user events, with the intention of keeping the user experience responsive.Garbage collection was deprecated in OS X v10.8 in favor of Automatic Reference Counting (ARC).  Objective-C on iOS 7 running on ARM64 uses 19 bits out of a 64-bit word to store the reference count, as a form of tagged pointers.Objective-C 2.0 introduces a new syntax to declare instance variables as properties, with optional attributes to configure the generation of accessor methods. Properties are, in a sense, public instance variables; that is, declaring an instance variable as a property provides external classes with access (possibly limited, e.g. read only) to that property. A property may be declared as readonly, and may be provided with storage semantics such as assign, copy or retain. By default, properties are considered atomic, which results in a lock preventing multiple threads from accessing them at the same time. A property can be declared as nonatomic, which removes this lock.Properties are implemented by way of the @synthesize keyword, which generates getter (and setter, if not read-only) methods according to the property declaration. Alternatively, the getter and setter methods must be implemented explicitly, or the @dynamic keyword can be used to indicate that accessor methods will be provided by other means. When compiled using clang 3.1 or higher, all properties which are not explicitly declared with @dynamic, marked readonly or have complete user-implemented getter and setter will be automatically implicitly @synthesize'd.Properties can be accessed using the traditional message passing syntax, dot notation, or, in Key-Value Coding, by name via the valueForKey:/setValue:forKey: methods.In order to use dot notation to invoke property accessors within an instance method, the self keyword should be used:A class or protocol's properties may be dynamically introspected.Objective-C 2.0 provides non-fragile instance variables where supported by the runtime (i.e. when building code for 64-bit Mac OS X, and all iOS). Under the modern runtime, an extra layer of indirection is added to instance variable access, allowing the dynamic linker to adjust instance layout at runtime. This feature allows for two important improvements to Objective-C code:Instead of using an NSEnumerator object or indices to iterate through a collection, Objective-C 2.0 offers the fast enumeration syntax. In Objective-C 2.0, the following loops are functionally equivalent, but have different performance traits.Fast enumeration generates more efficient code than standard enumeration because method calls to enumerate over objects are replaced by pointer arithmetic using the NSFastEnumeration protocol.A class extension has the same syntax as a category declaration with no category name, and the methods and properties declared in it are added directly to the main class. It is mostly used as an alternative to a category to add methods to a class without advertising them in the public headers, with the advantage that for class extensions the compiler checks that all the privately declared methods are actually implemented.All Objective-C applications developed for Mac OS X that make use of the above improvements for Objective-C 2.0 are incompatible with all operating systems prior to 10.5 (Leopard). Since fast enumeration does not generate exactly the same binaries as standard enumeration, its use will cause an application to crash on OS X version 10.4 or earlier.Blocks is a nonstandard extension for Objective-C (and C and C++) that uses special syntax to create closures. Blocks are only supported in Mac OS X 10.6 Snow Leopard or later, iOS 4 or later, and GNUstep with libobjc2 1.7 and compiling with clang 3.1 or later.Automatic Reference Counting (ARC) is a compile-time feature that eliminates the need for programmers to manually manage retain counts using retain and release.  Unlike garbage collection, which occurs at run time, ARC eliminates the overhead of a separate process managing retain counts. ARC and manual memory management are not mutually exclusive; programmers can continue to use non-ARC code in ARC-enabled projects by disabling ARC for individual code files. XCode can also attempt to automatically upgrade a project to ARC.NeXT and Apple Obj-C runtimes have long included a short-form way to create new strings, using the literal syntax @a new string, or drop to CoreFoundation constants kCFBooleanTrue and kCFBooleanFalse for NSNumber with Boolean values. Using this format saves the programmer from having to use the longer initWithString or similar methods when doing certain operations.When using Apple LLVM compiler 4.0 or later, arrays, dictionaries, and numbers (NSArray, NSDictionary, NSNumber classes) can also be created using literal syntax instead of methods.Example without literals:Example with literals:However, different from string literals, which compile to constants in the executable, these literals compile to code equivalent to the above method calls. In particular, under manually reference-counted memory management, these objects are autoreleased, which requires added care when e.g., used with function-static variables or other kinds of globals.When using Apple LLVM compiler 4.0 or later, arrays and dictionaries (NSArray and NSDictionary classes) can be manipulated using subscripting.  Subscripting can be used to retrieve values from indexes (array) or keys (dictionary), and with mutable objects, can also be used to set objects to indexes or keys. In code, subscripting is represented using brackets [ ].Example without subscripting:Example with subscripting:After the purchase of NeXT by Apple, attempts were made to make the language more acceptable to programmers more familiar with Java than Smalltalk. One of these attempts was introducing what was dubbed Modern Syntax for Objective-C at the time (as opposed to the current, classic syntax). There was no change in behaviour, this was merely an alternative syntax. Instead of writing a method invocation likeIt was instead written asSimilarly, declarations went from the formtoThis modern syntax is no longer supported in current dialects of the Objective-C language.Besides the GCC/NeXT/Apple implementation, which added several extensions to the original Stepstone implementation, another free, open-source Objective-C implementation called the Portable Object Compiler also exists. The set of extensions implemented by the Portable Object Compiler differs from the GCC/NeXT/Apple implementation; in particular, it includes Smalltalk-like blocks for Objective-C, while it lacks protocols and categories, two features used extensively in OpenStep and its derivatives and relatives. Overall, POC represents an older, pre-NeXT stage in the language's evolution, roughly conformant to Brad Cox's 1991 book.It also includes a runtime library called ObjectPak, which is based on Cox's original ICPak101 library (which in turn derives from the Smalltalk-80 class library), and is quite radically different from the OpenStep FoundationKit.The PC GEOS system used a programming language known as GEOS Objective-C or goc; despite the name similarity, the two languages are similar only in overall concept and the use of keywords prefixed with an @ sign.The Clang compiler suite, part of the LLVM project, implements Objective-C, and other languages.WinObjC (Also known as The Bridge) is a open-source ObjC compiler project started by Microsoft on GitHub as a way to allow the reuse of iOS Application code inside of a Windows Universal Applications.On Windows, Objective-C Development tools are provided for download on GNUStep's website.  The GNUStep Development System consists of the following packages: GNUstep MSYS System, GNUstep Core, GNUstep Devel, GNUstep Cairo, ProjectCenter IDE (Like Xcode, but not as complex), Gorm (Interface Builder Like Xcode NIB builder).Objective-C today is often used in tandem with a fixed library of standard objects (often known as a kit or framework), such as Cocoa, GNUstep or ObjFW. These libraries often come with the operating system: the GNUstep libraries often come with Linux-based distributions and Cocoa comes with OS X. The programmer is not forced to inherit functionality from the existing base class (NSObject / OFObject). Objective-C allows for the declaration of new root classes that do not inherit any existing functionality. Originally, Objective-C-based programming environments typically offered an Object class as the base class from which almost all other classes inherited. With the introduction of OpenStep, NeXT created a new base class named NSObject, which offered additional features over Object (an emphasis on using object references and reference counting instead of raw pointers, for example). Almost all classes in Cocoa inherit from NSObject.Not only did the renaming serve to differentiate the new default behavior of classes within the OpenStep API, but it allowed code that used Object—the original base class used on NeXTSTEP (and, more or less, other Objective-C class libraries)—to co-exist in the same runtime with code that used NSObject (with some limitations). The introduction of the two letter prefix also became a simplistic form of namespaces, which Objective-C lacks. Using a prefix to create an informal packaging identifier became an informal coding standard in the Objective-C community, and continues to this day.More recently, package managers have started appearing, such as CocoaPods, which aims to be both a package manager and a repository of packages. A lot of open-source Objective-C code that was written in the last few years can now be installed using CocoaPods.Objective-C implementations use a thin runtime system written in C, which adds little to the size of the application. In contrast, most object-oriented systems at the time that it was created used large virtual machine runtimes. Programs written in Objective-C tend to be not much larger than the size of their code and that of the libraries (which generally do not need to be included in the software distribution), in contrast to Smalltalk systems where a large amount of memory was used just to open a window. Objective-C applications tend to be larger than similar C or C++ applications because Objective-C dynamic typing does not allow methods to be stripped or inlined. Since the programmer has such freedom to delegate, forward calls, build selectors on the fly and pass them to the runtime system, the Objective-C compiler cannot assume it is safe to remove unused methods or to inline calls.Likewise, the language can be implemented atop extant C compilers (in GCC, first as a preprocessor, then as a module) rather than as a new compiler. This allows Objective-C to leverage the huge existing collection of C code, libraries, tools, etc. Existing C libraries can be wrapped in Objective-C wrappers to provide an OO-style interface. In this aspect, it is similar to GObject library and Vala language, which are widely used in development of GTK applications.All of these practical changes lowered the barrier to entry, likely the biggest problem for the widespread acceptance of Smalltalk in the 1980s.A common criticism is that Objective-C does not have language support for namespaces. Instead, programmers are forced to add prefixes to their class names, which are traditionally shorter than namespace names and thus more prone to collisions. As of 2007, all Mac OS X classes and functions in the Cocoa programming environment are prefixed with NS (e.g. NSObject, NSButton) to identify them as belonging to the Mac OS X or iOS core; the NS derives from the names of the classes as defined during the development of NeXTSTEP.Since Objective-C is a strict superset of C, it does not treat C primitive types as first-class objects.Unlike C++, Objective-C does not support operator overloading. Also unlike C++, Objective-C allows an object to directly inherit only from one class (forbidding multiple inheritance). However, in most cases, categories and protocols may be used as alternative ways to achieve the same results.Because Objective-C uses dynamic runtime typing and because all method calls are function calls (or, in some cases, syscalls), many common performance optimizations cannot be applied to Objective-C methods (for example: inlining, constant propagation, interprocedural optimizations, and scalar replacement of aggregates). This limits the performance of Objective-C abstractions relative to similar abstractions in languages such as C++ where such optimizations are possible.The first versions of Objective-C did not support garbage collection. At the time this decision was a matter of some debate, and many people considered long dead times (when Smalltalk performed collection) to render the entire system unusable. Some 3rd party implementations have added this feature (most notably GNUstep) and Apple has implemented it as of Mac OS X v10.5. However, in more recent versions of Mac OS X and iOS, garbage collection has been deprecated in favor of Automatic Reference Counting (ARC), introduced in 2011.With ARC, the compiler inserts retain and release calls automatically into Objective-C code based on static code analysis. The automation relieves the programmer of having to write in memory management code. ARC also adds weak references to the Objective-C language.The design and implementation of C++ and Objective-C represent fundamentally different approaches to extending C.In addition to C's style of procedural programming, C++ directly supports certain forms of object-oriented programming, generic programming, and metaprogramming. C++ also comes with a large standard library that includes several container classes. Similarly, Objective-C adds object-oriented programming, dynamic typing, and reflection to C. Objective-C does not provide a standard library per se, but in most places where Objective-C is used, it is used with an OpenStep-like library such as OPENSTEP, Cocoa, or GNUstep, which provides functionality similar to C++'s standard library.One notable difference is that Objective-C provides runtime support for reflective features, whereas C++ adds only a small amount of runtime support to C. In Objective-C, an object can be queried about its own properties, e.g., whether it will respond to a certain message. In C++, this is not possible without the use of external libraries.The use of reflection is part of the wider distinction between dynamic (run-time) features and static (compile-time) features of a language. Although Objective-C and C++ each employ a mix of both features, Objective-C is decidedly geared toward run-time decisions while C++ is geared toward compile-time decisions. The tension between dynamic and static programming involves many of the classic trade-offs in programming: dynamic features add flexibility, static features add speed and type checking.Generic programming and metaprogramming can be implemented in both languages using runtime polymorphism. In C++ this takes the form of virtual functions and runtime type identification, while Objective-C offers dynamic typing and reflection.  Objective-C lacks compile-time polymorphism (generic functions) entirely, while C++ supports it via function overloading and templates."
"7"	"NeXTSTEP is a discontinued object-oriented, multitasking operating system based on UNIX. It was developed by NeXT Computer in the late 1980s and early 1990s and was initially used for its range of proprietary workstation computers such as the NeXTcube and later ported to several other computer architectures.Although relatively unsuccessful at the time, it attracted interest from computer scientists and researchers. It was used as the original platform for the development of the Electronic AppWrapper, the first commercial electronic software distribution catalog to collectively manage encryption and provide digital rights for application software and digital media, a forerunner of the modern app store concept. It was also the platform on which Tim Berners-Lee created the first web browser. After the purchase of NeXT by Apple, it became the source of the popular operating systems macOS, iOS, watchOS, tvOS, and audioOS. Many bundled macOS applications, such as TextEdit, Mail, and Chess, are descendants of NeXTSTEP applications.NeXTSTEP (also stylized as NeXTstep, NeXTStep, and NEXTSTEP) is a combination of several parts:NeXTSTEP is notable for having been a preeminent implementation of the latter three items. The toolkits offer considerable power, and are the canonical development system for all of the software on the machine.It introduced the idea of the Dock (carried through OpenStep and into today's macOS) and the Shelf. NeXTSTEP also originated or innovated a large number of other GUI concepts which became common in other operating systems: 3D chiseled widgets, large full-color icons, system-wide drag and drop of a wide range of objects beyond file icons, system-wide piped services, real-time scrolling and window dragging, properties dialog boxes called inspectors, and window modification notices (such as the saved status of a file). The system is among the first general-purpose user interfaces to handle publishing color standards, transparency, sophisticated sound and music processing (through a Motorola 56000 DSP), advanced graphics primitives, internationalization, and modern typography, in a consistent manner across all applications.Additional kits were added to the product line to make the system more attractive. These include Portable Distributed Objects (PDO), which allow easy remote invocation, and Enterprise Objects Framework, a powerful object-relational database system. The kits made the system particularly interesting to custom application programmers, and NeXTSTEP had a long history in the financial programming community.[citation needed]A preview release of NeXTSTEP (version 0.8) was shown with the launch of the NeXT Computer on October 12, 1988. The first full release, NeXTSTEP 1.0, shipped on September 18, 1989. The last version, 3.3, was released in early 1995, by which time it ran on not only the Motorola 68000 family processors used in NeXT computers, but also on Intel x86, Sun SPARC, and HP PA-RISC-based systems.NeXTSTEP was later modified to separate the underlying operating system from the higher-level object libraries. The result was the OpenStep API, which ran on multiple underlying operating systems, including NeXT's own OPENSTEP, Windows NT and SUN Solaris. NeXTSTEP's legacy stands today in the form of its direct descendents, Apple's macOS, iOS, watchOS, tvOS, and audioOS operating systems.From day one, the operating system of NeXTSTEP was built upon Mach/BSD.The first web browser, WorldWideWeb, and the first ever app store were all invented on the NeXTSTEP platform.Some features and keyboard shortcuts now commonly found in web browsers can be traced back to NeXTSTEP conventions. The basic layout options of HTML 1.0 and 2.0 are attributable to those features available in NeXT's Text class.Features seen first on NeXTSTEP:In the 1990s, the pioneering PC games Doom (with its WAD level editor), Doom II, and Quake (with its respective level editor) were developed by id Software on NeXT machines. Other games based on the Doom engine such as Heretic and its sequel Hexen by Raven Software as well as Strife by Rogue Entertainment were also developed on NeXT hardware using id's tools.Altsys made a NeXTSTEP application called Virtuoso, version 2 of which was ported to Mac OS and Windows to become Macromedia FreeHand version 4. The modern Notebook interface for Mathematica, and the advanced spreadsheet Lotus Improv, were developed using NeXTSTEP. The software that controlled MCI's Friends and Family calling plan program was developed using NeXTSTEP.About the time of the release of NeXTSTEP 3.2, NeXT partnered with Sun Microsystems to develop OpenStep. It is the product of an effort to separate the underlying operating system from the higher-level object libraries to create a cross-platform object-oriented API standard derived from NeXTSTEP. The OpenStep API targets multiple underlying operating systems, including NeXT's own OPENSTEP. Implementations of that standard were released for Sun's Solaris, Windows NT, and NeXT's version of the Mach kernel. NeXT's implementation is called OPENSTEP for Mach and its first release (4.0) superseded NeXTSTEP 3.3 on NeXT, Sun, and Intel IA-32 systems.Following an announcement on December 20, 1996,Apple Computer acquired NeXT on February 4, 1997 for $429 million. Based upon the OPENSTEP for Mach operating system, and developing the OPENSTEP API to become Cocoa, Apple created the basis of Mac OS X, and eventually, in turn, of iOS, watchOS, tvOS, and audioOS.A free software implementation of the OpenStep standard, GNUstep, also exists.Delivered on 2 CDs: NeXTSTEP CISC and NeXTSTEP RISC. The Developer CD includes libraries for all architectures, so that programs can be cross-compiled on any architecture for all architectures.Allegedly dropped due to complaints of having to re-teach users but not for technical reasons (the new UI worked well in the beta).Versions up to 4.1 are general releases. OPENSTEP 4.2 pre-release 2 is a bug-fix release published by Apple and was supported for five years after its September 1997 release.This article is based on material taken from  the Free On-line Dictionary of Computing prior to 1 November 2008 and incorporated under the relicensing terms of the GFDL, version 1.3 or later."
"8"	"OpenStep is an object-oriented application programming interface (API) specification for a legacy object-oriented operating system, with the basic goal of offering a NeXTSTEP-like environment on a non-NeXTSTEP operating system. OpenStep was principally developed by NeXT with Sun Microsystems, to allow NeXTSTEP (like) development on Sun's operating systems, specifically Solaris. NeXT produced a version of OpenStep for their own Mach-based Unix, known as OPENSTEP (all capitalized),  as well as a version that ran on Windows NT. The software libraries that shipped with OPENSTEP are a superset of the original OpenStep specification, including many features from the original NeXTSTEP.The OpenStep API was created as the result of a 1993 collaboration between NeXT and Sun Microsystems, allowing this cut-down version of the NeXTSTEP operating system object layers to be run on Sun's Solaris operating system (more specifically, Solaris on SPARC-based hardware). Most of the OpenStep effort was to strip away those portions of NeXTSTEP that depended on Mach or NeXT-specific hardware being present. This resulted in a smaller system that consisted primarily of Display PostScript, the Objective-C runtime and compilers, and the majority of the NeXTSTEP Objective-C libraries. Not included was the basic operating system, or the lower-level display system.The first draft of the API was published by NeXT in summer 1994. Later that year they released an OpenStep compliant version of NeXTSTEP as OPENSTEP, supported on several of their platforms as well as Sun SPARC systems. The official OpenStep API, published in September 1994, was the first to split the API between Foundation and Application Kit and the first to use the NS prefix. Early versions of NeXTSTEP used an NX prefix and contained only the Application Kit, relying on standard Unix libc types for low-level data structures. OPENSTEP remained NeXT's primary operating system product until they were purchased by Apple Computer in 1996. OPENSTEP was then combined with technologies from the existing classic Mac OS to produce Mac OS X. iPhone and iPad's iOS is also a descendant of OPENSTEP, but targeted at touch devices. Sun originally adopted the OpenStep environment with the intent of complementing Sun's CORBA-compliant object system, Solaris NEO (formerly known as Project DOE), by providing an object-oriented user interface toolkit to complement the object-oriented CORBA plumbing. The port involved integrating the OpenStep AppKit with the Display PostScript layer of the Sun X11 server, making the AppKit tolerant of multi-threaded code (as Project DOE was inherently heavily multi-threaded), implementing a Solaris daemon to simulate the behavior of Mach ports, extending the SunPro C++ compiler to support Objective-C using NeXT's ObjC runtime, writing an X11 window manager to implement the NeXTSTEP look and feel as much as possible, and integrating the NeXT development tools, such as Project Manager and Interface Builder, with the SunPro compiler. In order to provide a complete end-user environment, Sun also ported the NeXTSTEP-3.3 versions of several end-user applications, including Mail.app, Preview.app, Edit.app, Workspace Manager, and the Dock.The OpenStep and CORBA parts of the products were later split, and NEO was released in late 1995 without the OpenStep environment. In March 1996, Sun announced Joe, a product to integrate NEO with Java. Sun shipped a beta release of the OpenStep environment for Solaris on July 22, 1996, and made it freely available for download in August 1996 for non-commercial use, and for sale in September 1996. OpenStep/Solaris was shipped only for the SPARC architecture.The API OpenStep contrasts with the earlier NeXTSTEP primarily in five ways:The API specification itself is composed of the two main sets of object-oriented classes: the GUI and graphics front-end known as the Application Kit, and the aforementioned Foundation Kit.However, OpenStep also specified the use of Display PostScript, a versatile and powerful PostScript-based method of drawing windows and graphics on screen. NeXT, with its devotion to implementing object-oriented solutions, supplied pswraps for interfacing C code to Display PostScript. pswraps acted in an encapsulative way similar to Embedded SQL, and was somewhat object oriented. The Application Kit, Foundation, and Display PostScript comprise the three key technologies in the OpenStep specification; many of the specific calls in the API were available in NeXTSTEP as well, but many were modified or re-packaged for OpenStep.The standardization on OpenStep also allowed for the creation of several new library packages that were delivered on the OPENSTEP platform. Unlike the operating system as a whole, these packages were designed to run stand-alone on practically any operating system. The idea was to use OpenStep code as a basis for network-wide applications running across different platforms, as opposed to using CORBA or some other system.Primary among these packages was Portable Distributed Objects (PDO). PDO was essentially an even more stripped down version of OpenStep containing only the Foundation Kit technologies, combined with new libraries to provide remote invocation with very little code. Unlike OpenStep, which defined an operating system that applications would run in, under PDO the libraries were compiled into the application itself, creating a stand-alone native application for a particular platform. PDO was small enough to be easily portable, and versions were released for all major server vendors.In the mid-1990s, NeXT staff took to writing in solutions to various CORBA magazine articles in a few lines of code, whereas the original article would fill several pages. Even though using PDO required the installation of a considerable amount of supporting code (Objective-C and the libraries), PDO applications were nevertheless considerably smaller than similar CORBA solutions, typically about one-half to one-third the size.The similar D'OLE provided the same types of services, but presented the resulting objects as COM objects, with the goal of allowing programmers to create COM services running on high-powered platforms, called from Microsoft Windows applications. For instance one could develop a high-powered financial modeling application using D'OLE, and then call it directly from within Microsoft Excel. When D'OLE was first released, OLE by itself only communicated between applications running on a single machine. PDO enabled NeXT to demonstrate Excel talking to other Microsoft applications across a network before Microsoft themselves were able to implement this functionality (DCOM).Another package developed on OpenStep was Enterprise Objects Framework (EOF), a tremendously powerful (for the time) object-relational mapping product. EOF became very popular in the enterprise market, notably in the financial sector where OPENSTEP caused something of a minor revolution.[citation needed]NeXT's first operating system was NeXTSTEP, a sophisticated Mach-UNIX based operating system that originally ran only on NeXT's Motorola 68k-based workstations and that was then ported to run on 32-bit Intel x86-based IBM-compatible personal computers, PA-RISC-based workstations from Hewlett-Packard, and SPARC-based workstations from Sun Microsystems.NeXT completed an implementation of OpenStep on their existing Mach-based OS and called it OPENSTEP for Mach 4.0 (July, 1996), 4.1 (December, 1996), and 4.2 (January, 1997). It was, for all intents, NeXTSTEP 4.0, and still retained flagship NeXTSTEP technologies (such as DPS, UNIX underpinnings, user interface characteristics like the Dock and Shelf, and so on), and retained the classic NeXTSTEP user interface and styles. OPENSTEP for Mach was further improved, in comparison to NeXTSTEP 3.3, with vastly improved driver support – however the environment to actually write drivers was changed with the introduction of the object-oriented DriverKit.OPENSTEP for Mach supported Intel x86-based PC's, Sun's SPARC workstations, and NeXT's own 68k-based architectures, while the HP PA-RISC version was dropped. These versions continued to run on the underlying Mach-based OS used in NeXTSTEP. OPENSTEP for Mach became NeXT's primary OS from 1995 on, and was used mainly on the Intel platform. In addition to being a complete OpenStep implementation, the system was delivered with a complete set of NeXTSTEP libraries for backward compatibility. This was an easy thing to do in OpenStep due to library versioning, and OPENSTEP did not suffer in bloat because of it.In addition to the OPENSTEP for Mach port for SPARC, Sun and NeXT developed an OpenStep compliant set of frameworks to run on Sun's Solaris operating system. After developing Solaris OpenStep, Sun lost interest in OpenStep and shifted its attention toward Java. As a virtual machine development environment, Java served as a direct competitor to OpenStep.NeXT also delivered an implementation running on top of Windows NT 4.0 called OPENSTEP Enterprise (often abbreviated OSE). This was an unintentional demonstration on the true nature of the portability of programs created under the OpenStep specification. Programs for OPENSTEP for Mach could be ported to OSE with little difficulty. This allowed their existing customer base to continue using their tools and applications, but running them on Windows, to which many of them were in the process of switching. Never a clean match from the UI perspective, probably due to OPENSTEP's routing of window graphics through the Display Postscript server—which was also ported to Windows—OSE nevertheless managed to work fairly well and extended OpenStep's commercial lifespan.OPENSTEP and OSE had two revisions (and one major one that was never released) before NeXT was purchased by Apple in 1997.After acquiring NeXT, Apple intended to ship Rhapsody as a reworked version of OPENSTEP for Mach for both the Mac and standard PCs. Rhapsody was OPENSTEP for Mach with a Copland appearance from Mac OS 8 and support for Java and Apple's own technologies, including ColorSync and QuickTime; it could be regarded as OPENSTEP 5. Two developer versions of Rhapsody were released, known as Developer Preview 1 and 2; these ran on a limited subset of both Intel and PowerPC hardware.  Mac OS X Server 1.0 was the first commercial release of this operating system, and was delivered exclusively for PowerPC Mac hardware.After replacing the Display Postscript WindowServer with Quartz, and responding to developers by including better backward compatibility for classic Mac OS applications through the addition of Carbon, Apple released Mac OS X and Mac OS X Server, starting at version 10.0; Mac OS X is now named macOS.macOS's primary programming environment is essentially OpenStep (with certain additions such as XML property lists and URL classes for Internet connections) with macOS ports of the development libraries and tools, now called Cocoa.macOS has since become the single most popular desktop Unix-like operating system in the world, although macOS is no longer an OpenStep compliant operating system.[citation needed]GNUstep, a free software implementation of the NeXT libraries, began at the time of NeXTSTEP, predating OPENSTEP. While OPENSTEP and OSE were purchased by Apple, who effectively ended the commercial development of implementing OpenStep for other platforms, GNUstep is an ongoing open source project aiming to create a portable, free software implementation of the Cocoa/OPENSTEP libraries.GNUstep also features a fully functional development environment, reimplementations of some of the newer innovations from macOS's Cocoa framework, as well as its own extensions to the API."
"9"	" (Learn how and when to remove this template message)GNUstep is a free software implementation of the Cocoa (formerly OpenStep) Objective-C frameworks, widget toolkit, and application development tools for Unix-like operating systems and Microsoft Windows. It is part of the GNU Project.GNUstep features a cross-platform, object-oriented IDE.  Apart from the default Objective-C interface, GNUstep also has bindings for Java, Ruby,Guile and Scheme. The GNUstep developers track some additions to Apple's Cocoa to remain compatible. The roots of the GNUstep application interface are the same as the roots of Cocoa: NeXTSTEP and OpenStep. GNUstep thus predates Cocoa, which emerged when Apple acquired NeXT's technology and incorporated it into the development of the original Mac OS X, while GNUstep was initially an effort by GNU developers to replicate the technically ambitious NeXTSTEP's programmer-friendly features.GNUstep began when Paul Kunz and others at Stanford Linear Accelerator Center wanted to port HippoDraw from NeXTSTEP to another platform. Instead of rewriting HippoDraw from scratch and reusing only the application design, they decided to rewrite the NeXTSTEP object layer on which the application depended. This was the first version of libobjcX. It enabled them to port HippoDraw to Unix systems running the X Window System without changing a single line of their application source. After the OpenStep specification was released to the public in 1994, they decided to write a new objcX which would adhere to the new APIs. The software would become known as GNUstep.GNUstep contain a set of graphical control elements written in the Objective-C programming language. The graphical user interface (GUI) of e.g. GNUMail is composed of graphics control element. GNUMail has to interact with the windowing system, e.g. X11 or Wayland, and its graphical user interface has to be rendered. GNUstep's backend provides a small set of functions used by the user interface library to interface to the actual windowing system. It also has a rendering engine which emulates common PostScript functions. The package gnustep-back provides the following backends:GNUstep inherits some design principles proposed in OPENSTEP (GNUstep predates Cocoa, but Cocoa is based on OPENSTEP) as well as the Objective-C language. Here are some examples of applications written for or ported to GNUstep.The Foundation Kit provides basic classes such as wrapper classes and data structure classes.The Application Kit provides classes oriented around graphical user interface capabilities."
"10"	"The architecture of macOS describes the layers of the operating system that is the culmination of Apple Inc.'s decade-long search and development process to replace the classic Mac OS.After the failures of their previous attempts; Pink, which started as an Apple project but evolved into a joint venture with IBM called Taligent, and Copland, which started in 1994 and was cancelled two years later, Apple began development of Mac OS X with the acquisition of NeXT's NeXTSTEP in 1997.Note that Mac OS X was renamed to OS X in 2012 and then again to macOS in 2016.NeXTSTEP used a hybrid kernel that combined the Mach 2.5 kernel developed at Carnegie Mellon University with subsystems from 4.3BSD. NeXTSTEP also introduced a new windowing system based on Display PostScript that intended to achieve better WYSIWYG systems by using the same language to draw content on monitors that drew content on printers. NeXT also included object-oriented programming tools based on the Objective-C language that they had acquired from Stepstone and a collection of Frameworks (or Kits) that were intended to speed software development. NeXTSTEP originally ran on Motorola's 68k processors, but was later ported to Intel's x86, Hewlett-Packard's PA-RISC and Sun Microsystems' SPARC processors. Later on, the developer tools and frameworks were released, as OpenStep, as a development platform that would run on other operating systems.On February 4, 1997, Apple acquired NeXT and began development of the Rhapsody operating system. Rhapsody built on NeXTSTEP, porting the core system to the PowerPC architecture and adding a redesigned user interface based on the Platinum user interface from Mac OS 8. An emulation layer called Blue Box allowed Mac OS applications to run within an actual instance of the Mac OS and an integrated Java platform. The Objective-C developer tools and Frameworks were referred to as the Yellow Box and also made available separately for Microsoft Windows. The Rhapsody project eventually bore the fruit of all Apple's efforts to develop a new generation Mac OS, which finally shipped in the form of Mac OS X Server.At the 1998 Worldwide Developers Conference (WWDC), Apple announced a move that was intended as a response to complaints from Macintosh software developers who were not happy with the two options (Yellow Box and Blue Box) available in Rhapsody. Mac OS X would add another developer API to the existing ones in Rhapsody. Key APIs from the Macintosh Toolbox would be implemented in Mac OS X to run directly on the BSD layers of the operating system instead of in the emulated Macintosh layer. This modified interface, called Carbon, would eliminate approximately 2000 troublesome API calls (of about 8000 total) and replace them with calls compatible with a modern OS.At the same conference, Apple announced that the Mach side of the kernel had been updated with sources from the OSFMK 7.3 (Open Source Foundation Mach Kernel)  and the BSD side of the kernel had been updated with sources from the FreeBSD, NetBSD and OpenBSD projects. They also announced a new driver model called I/O Kit, intended to replace the Driver Kit used in NeXTSTEP citing Driver Kit's lack of power management and hot-swap capabilities and its lack of automatic configuration capability.At the 1999 WWDC, Apple revealed Quartz, a new Portable Document Format (PDF) based windowing system for the operating system that was not encumbered with licensing fees to Adobe like the Display PostScript windowing system of NeXTSTEP. Apple also announced that the Yellow Box layer had been renamed Cocoa and began to move away from their commitment to providing the Yellow Box on Windows. At this WWDC, Apple also showed Mac OS X booting off of a HFS Plus formatted drive for the first time.The first public release of Mac OS X released to consumers was a Public Beta released on September 13, 2000."
"11"	"In programming languages and type theory, polymorphism (from Greek p<U+03BF><U+03BB><U+03CD><U+03C2>, polys, many, much and µ<U+03BF><U+03C1>f<U+03AE>, morphe, form, shape) is the provision of a single interface to entities of different types. A polymorphic type is one whose operations can also be applied to values of some other type, or types. There are several fundamentally different kinds of polymorphism:The interaction between parametric polymorphism and subtyping leads to the concepts of variance and bounded quantification.Ad hoc polymorphism and parametric polymorphism were originally described in Fundamental Concepts in Programming Languages, a set of lecture notes written in 1967 by British computer scientist Christopher Strachey. In a 1985 paper, Peter Wegner and Luca Cardelli introduced the term inclusion polymorphism to model subtypes and inheritance. However, implementations of subtyping and inheritance predate the term inclusion polymorphism, having appeared with Simula in 1967.Christopher Strachey chose the term ad hoc polymorphism to refer to polymorphic functions that can be applied to arguments of different types, but that behave differently depending on the type of the argument to which they are applied (also known as function overloading or operator overloading). The term ad hoc in this context is not intended to be pejorative; it refers simply to the fact that this type of polymorphism is not a fundamental feature of the type system. In the Pascal / Delphi example below, the Add functions seem to work generically over various types when looking at the invocations, but are considered to be two entirely distinct functions by the compiler for all intents and purposes:In dynamically typed languages the situation can be more complex as the correct function that needs to be invoked might only be determinable at run time.Implicit type conversion has also been defined as a form of polymorphism, referred to as coercion polymorphism.Parametric polymorphism allows a function or a data type to be written generically, so that it can handle values uniformly without depending on their type. Parametric polymorphism is a way to make a language more expressive while still maintaining full static type-safety.The concept of parametric polymorphism applies to both data types and functions. A function that can evaluate to or be applied to values of different types is known as a polymorphic function. A data type that can appear to be of a generalized type (e.g. a list with elements of arbitrary type) is designated polymorphic data type like the generalized type from which such specializations are made.Parametric polymorphism is ubiquitous in functional programming, where it is often simply referred to as polymorphism. The following example in Haskell shows a parametrized list data type and two parametrically polymorphic functions on them:Parametric polymorphism is also available in several object-oriented languages. For instance, templates in C++ and D, or under the name generics in C# and Java:John C. Reynolds (and later Jean-Yves Girard) formally developed this notion of polymorphism as an extension to lambda calculus (called the polymorphic lambda calculus or System F). Any parametrically polymorphic function is necessarily restricted in what it can do, working on the shape of the data instead of its value, leading to the concept of parametricity.Some languages employ the idea of subtyping (also called subtype polymorphism or inclusion polymorphism) to restrict the range of types that can be used in a particular case of polymorphism. In these languages, subtyping allows a function to be written to take an object of a certain type T, but also work correctly, if passed an object that belongs to a type S that is a subtype of T (according to the Liskov substitution principle). This type relation is sometimes written S <: T. Conversely, T is said to be a supertype of S—written T :> S. Subtype polymorphism is usually resolved dynamically (see below).In the following example we make cats and dogs subtypes of animals. The procedure letsHear() accepts an animal, but will also work correctly if a subtype is passed to it:In another example, if Number, Rational, and Integer are types such that Number :> Rational and Number :> Integer, a function written to take a Number will work equally well when passed an Integer or Rational as when passed a Number. The actual type of the object can be hidden from clients into a black box, and accessed via object identity. In fact, if the Number type is abstract, it may not even be possible to get your hands on an object whose most-derived type is Number (see abstract data type, abstract class). This particular kind of type hierarchy is known—especially in the context of the Scheme programming language—as a numerical tower, and usually contains many more types.Object-oriented programming languages offer subtype polymorphism using subclassing (also known as inheritance). In typical implementations, each class contains what is called a virtual table—a table of functions that implement the polymorphic part of the class interface—and each object contains a pointer to the vtable of its class, which is then consulted whenever a polymorphic method is called. This mechanism is an example of:The same goes for most other popular object systems. Some, however, such as Common Lisp Object System, provide multiple dispatch, under which method calls are polymorphic in all arguments.Row polymorphism is a similar, but distinct concept from subtyping. It deals with structural types.  It allows the usage of all values whose types have certain properties, without losing the remaining type information.A related concept is polytypism (or data type genericity). A polytypic function is more general than polymorphic, and in such a function, though one can provide fixed ad hoc cases for specific data types, an ad hoc combinator is absent.Polymorphism can be distinguished by when the implementation is selected: statically (at compile time) or dynamically (at run time, typically via a virtual function). This is known respectively as static dispatch and dynamic dispatch, and the corresponding forms of polymorphism are accordingly called static polymorphism and dynamic polymorphism.Static polymorphism executes faster, because there is no dynamic dispatch overhead, but requires additional compiler support. Further, static polymorphism allows greater static analysis by compilers (notably for optimization), source code analysis tools, and human readers (programmers). Dynamic polymorphism is more flexible but slower—for example, dynamic polymorphism allows duck typing, and a dynamically linked library may operate on objects without knowing their full type.Static polymorphism typically occurs in ad hoc polymorphism and parametric polymorphism, whereas dynamic polymorphism is usual for subtype polymorphism. However, it is possible to achieve static polymorphism with subtyping through more sophisticated use of template metaprogramming, namely the curiously recurring template pattern."
"12"	"In software engineering, dependency injection is a technique whereby one object supplies the dependencies of another object. A dependency is an object that can be used (a service). An injection is the passing of a dependency to a dependent object (a client) that would use it. The service is made part of the client's state.  Passing the service to the client, rather than allowing a client to build or find the service, is the fundamental requirement of the pattern.This fundamental requirement means that using values (services) produced within the class from new or static methods is prohibited.  The client should accept values passed in from outside. This allows the client to make acquiring dependencies someone else's problem.The intent behind dependency injection is to decouple objects to the extent that no client code has to be changed simply because an object it depends on needs to be changed to a different one.Dependency injection is one form of the broader technique of inversion of control. As with other forms of inversion of control, dependency injection supports the dependency inversion principle. The client delegates the responsibility of providing its dependencies to external code (the injector). The client is not allowed to call the injector code.  It is the injecting code that constructs the services and calls the client to inject them.  This means the client code does not need to know about the injecting code.  The client does not need to know how to construct the services.  The client does not need to know which actual services it is using.  The client only needs to know about the intrinsic interfaces of the services because these define how the client may use the services.  This separates the responsibilities of use and construction.There are three common means for a client to accept a dependency injection: setter-, interface- and constructor-based injection. Setter and constructor injection differ mainly by when they can be used.  Interface injection differs in that the dependency is given a chance to control its own injection. All require that separate construction code (the injector) take responsibility for introducing a client and its dependencies to each other.The Dependency Injection design pattern solves problems like: Creating objects directly within the class that requires the objects is inflexible because it commits the class to particular objects and makes it impossible to change the instantiation later independently from (without having to change) the class. It stops the class from being reusable if other objects are required, and it makes the class hard to test because real objects can't be replaced with mock objects.The Dependency Injection design pattern describes how to solve such problems:This makes a class independent of how its objects are created (which concrete classes are instantiated). A class is no longer responsible for creating the objects it requires, and it doesn't have to delegate instantiation to a factory object as in the Abstract Factory   design pattern. This greatly simplifies a class and makes it easier to implement, change, test, and reuse.  See also the UML class and sequence diagram below.When you go and get things out of the refrigerator for yourself, you can cause problems. You might leave the door open, you might get something Mommy or Daddy doesn't want you to have. You might even be looking for something we don't even have or which has expired.John Munsch, 28 October 2009.Dependency injection separates the creation of a client's dependencies from the client's behavior, which allows program designs to be loosely coupled and to follow the dependency inversion and single responsibility principles. It directly contrasts with the service locator pattern, which allows clients to know about the system they use to find dependencies.An injection, the basic unit of dependency injection, is not a new or a custom mechanism. It works in the same way that parameter passing works. Referring to parameter passing as an injection carries the added implication that it's being done to isolate the client from details.An injection is also about what is in control of the passing (never the client) and is independent of how the passing is accomplished, whether by passing a reference or a value.Dependency injection involves four roles:Any object that may be used can be considered a service. Any object that uses other objects can be considered a client. The names have nothing to do with what the objects are for and everything to do with the role the objects play in any one injection.The interfaces are the types the client expects its dependencies to be. At issue is what they make accessible. They may truly be interface types implemented by the services but also may be abstract classes or even the concrete services themselves, though this last would violate DIP and sacrifice the dynamic decoupling that enables testing. It's only required that the client does not know which they are and therefore never treats them as concrete, say by constructing or extending them.The client should have no concrete knowledge of the specific implementation of its dependencies. It should only know the interface's name and API. As a result, the client won't need to change even if what is behind the interface changes. However, if the interface is refactored from being a class to an interface type (or vice versa) the client will need to be recompiled. This is significant if the client and services are published separately. This unfortunate coupling is one that dependency injection cannot resolve.The injector introduces the services into the client. Often, it also constructs the client. An injector may connect together a very complex object graph by treating an object like a client and later as a service for another client. The injector may actually be many objects working together but may not be the client. The injector may be referred to by other names such as: assembler, provider, container, factory, builder, spring, construction code, or main.Dependency injection can be applied as a discipline, one that asks that all objects separate construction and behavior. Relying on a DI framework to perform construction can lead to forbidding the use of the new keyword, or, less strictly, only allowing direct construction of value objects.Inversion of control (IoC) is more general than DI. Put simply, IoC means letting other code call you rather than insisting on doing the calling. An example of IoC without DI is the template method pattern. Here, polymorphism is achieved through subclassing, that is, inheritance.Dependency injection implements IoC through composition so is often identical to that of the strategy pattern, but while the strategy pattern is intended for dependencies to be interchangeable throughout an object's lifetime, in dependency injection it may be that only a single instance of a dependency is used. This still achieves polymorphism, but through delegation and composition.Application frameworks such as CDI and its implementation Weld, Spring, Guice, Play framework, Salta, Glassfish HK2, Dagger, and Managed Extensibility Framework (MEF) support dependency injection but are not required to do dependency injection.In the above UML class diagram, the Client class  that requires ServiceA and ServiceB objects doesn't instantiate the ServiceA1 and ServiceB1 classes directly. Instead, an Injector class creates the objects and injects them into the Client, which makes the Client independent of how the objects are created (which concrete classes are instantiated).  The UML sequence diagram shows the run-time interactions: The Injector object creates the ServiceA1 and ServiceB1 objects. Thereafter, the Injector creates the Client object and injects the ServiceA1 and ServiceB1 objects.In the following Java example, the Client class contains a Service member variable that is initialized by the Client constructor.  The client controls which implementation of service is used and controls its construction.  In this situation, the client is said to have a hard-coded dependency on ExampleService.Dependency injection is an alternative technique to initialize the member variable rather than explicitly creating a service object as shown above.There are at least three ways an object can receive a reference to an external module:It is possible for DI frameworks to have other types of injection beyond those presented above.Testing frameworks may also use other types.  Some modern testing frameworks do not even require that clients actively accept dependency injection thus making legacy code testable.  In particular, in the Java language it is possible to use reflection to make private attributes public when testing and thus accept injections by assignment.Some attempts at Inversion of Control do not provide full removal of dependency but instead simply substitute one form of dependency for another.  As a rule of thumb, if a programmer can look at nothing but the client code and tell what framework is being used, then the client has a hard-coded dependency on the framework.This method requires the client to provide a parameter in a constructor for the dependency.  This method requires the client to provide a setter method for the dependency.  This is simply the client publishing a role interface to the setter methods of the client's dependencies.  It can be used to establish how the injector should talk to the client when injecting dependencies.Preferred when all dependencies can be constructed first because it can be used to ensure the client object is always in a valid state, as opposed to having some of its dependency references be null (not be set).  However, on its own, it lacks the flexibility to have its dependencies changed later.  This can be a first step towards making the client immutable and therefore thread safe.  Requires the client to provide a setter method for each dependency.  This gives the freedom to manipulate the state of the dependency references at any time.  This offers flexibility, but if there is more than one dependency to be injected, it is difficult for the client to ensure that all dependencies are injected before the client could be provided for use.Because these injections happen independently there is no way to tell when the injector is finished wiring the client.  A dependency can be left null simply by the injector failing to call its setter.  This forces the check that injection was completed from when the client is assembled to whenever it is used.The advantage of interface injection is that dependencies can be completely ignorant of their clients yet can still receive a reference to a new client and, using it, send a reference-to-self back to the client.  In this way, the dependencies become injectors.  The key is that the injecting method (which could just be a classic setter method) is provided through an interface.An assembler is still needed to introduce the client and its dependencies.  The assembler would take a reference to the client, cast it to the setter interface that sets that dependency, and pass it to that dependency object which would turn around and pass a reference-to-self back to the client.For interface injection to have value, the dependency must do something in addition to simply passing back a reference to itself. This could be acting as a factory or sub-assembler to resolve other dependencies, thus abstracting some details from the main assembler. It could be reference-counting so that the dependency knows how many clients are using it. If the dependency maintains a collection of clients, it could later inject them all with a different instance of itself.[example  needed]Manually assembling in main by hand is one way of implementing dependency injection.The example above constructs the object graph manually and then invokes it at one point to start it working.  Important to note is that this injector is not pure.  It uses one of the objects it constructs.  It has a purely construction-only relationship with ExampleService but mixes construction and using of Client.  This should not be common.  It is, however, unavoidable.  Just like object oriented software needs a non-object oriented static method like main() to get started, a dependency injected object graph needs at least one (preferably only one) entry point to get the using started.Manual construction in the main method may not be this straight forward and may involve calling builders, factories, or other construction patterns as well.  This can be fairly advanced and abstract.  The line is crossed from manual dependency injection to framework dependency injection once the constructing code is no longer custom to the application and is instead universal.Frameworks like Spring can construct these same objects and wire them together before returning a reference to client.  All mention of the concrete ExampleService can be moved from the code to the configuration data.Frameworks like Spring allow assembly details to be externalized in configuration files. This code (above) constructs objects and wires them together according to Beans.xml (below).  ExampleService is still constructed even though it's only mentioned below.  A long and complex object graph can be defined this way and the only class mentioned in code would be the one with the entry point method, which in this case is greet().In the example above Client and Service have not had to undergo any changes to be provided by spring. They are allowed to remain simple POJOs. This shows how spring can connect services and clients that are completely ignorant of its existence. This could not be said if spring annotations are added to the classes.  By keeping spring specific annotations and calls from spreading out among many classes, the system stays only loosely dependent on spring. This can be important if the system intends to outlive spring.The choice to keep POJOs pure doesn't come without cost.  Rather than spending the effort to develop and maintain complex configuration files it is possible to simply use annotations to mark classes and let spring do the rest of the work.  Resolving dependencies can be simple if they follow a convention such as matching by type or by name.  This is choosing convention over configuration.  It is also arguable that, when refactoring to another framework, removing framework specific annotations would be a trivial part of the task and many injection annotations are now standardized.The different injector implementations (factories, service locators, and dependency injection containers) are not that different as far as dependency injection is concerned.  What makes all the difference is where they are allowed to be used.  Move calls to a factory or a service locator out of the client and into main and suddenly main makes a fairly good dependency injection container.By moving all knowledge of the injector out, a clean client, free of knowledge of the outside world, is left behind.  However, any object that uses other objects can be considered a client.  The object that contains main is no exception.  This main object is not using dependency injection.  It's actually using the service locator pattern.  This can't be avoided because the choice of service implementations must be made somewhere.Externalizing the dependencies into configuration files doesn't change this fact.  What makes this reality part of a good design is that the service locator is not spread throughout the code base.  It's confined to one place per application.  This leaves the rest of the code base free to use dependency injection to make clean clients.In the AngularJS framework, there are only three ways a component (object or function) can directly access its dependencies:The first two options of creating or looking up dependencies are not optimal because they hard code the dependency to the component. This makes it difficult, if not impossible, to modify the dependencies. This is especially problematic in tests, where it is often desirable to provide mock dependencies for test isolation.The third option is the most viable, since it removes the responsibility of locating the dependency from the component. The dependency is simply handed to the component.In the above example SomeClass is not concerned with creating or locating the greeter dependency, it is simply handed the greeter when it is instantiated.This is desirable, but it puts the responsibility of getting hold of the dependency on the code that constructs SomeClass.To manage the responsibility of dependency creation, each AngularJS application has an injector. The injector is a service locator that is responsible for construction and look-up of dependencies.Here is an example of using the injector service:Create a new injector that can provide components defined in the myModule module and request our greeter service from the injector. (This is usually done automatically by the AngularJS bootstrap).Asking for dependencies solves the issue of hard coding, but it also means that the injector needs to be passed throughout the application. Passing the injector breaks the Law of Demeter. To remedy this, we use a declarative notation in our HTML templates, to hand the responsibility of creating components over to the injector, as in this example:When AngularJS compiles the HTML, it processes the ng-controller directive, which in turn asks the injector to create an instance of the controller and its dependencies.This is all done behind the scenes. Because the ng-controller defers to the injector to instantiate the class, it can satisfy all of the dependencies of MyController without the controller ever knowing about the injector. The application code simply declares the dependencies it needs, without having to deal with the injector. This setup does not break the Law of Demeter."
"13"	"In the area of mathematical logic and computer science known as type theory, a unit type is a type that allows only one value (and thus can hold no information). The carrier (underlying set) associated with a unit type can be any singleton set. There is an isomorphism between any two such sets, so it is customary to talk about the unit type and ignore the details of its value. One may also regard the unit type as the type of 0-tuples, i.e. the product of no types.The unit type is the terminal object in the category of types and typed functions. It should not be confused with the zero or bottom type, which allows no values and is the initial object in this category. Similarly, the Boolean is the type with two values.The unit type is implemented in most functional programming languages. The void type that is used in some imperative programming languages serves some of its functions, but because its carrier set is empty, it has some limitations (as detailed below).Several computer programming languages provide a unit type to specify the result type of a function with the sole purpose of causing a side effect, and the argument type of a function that does not require arguments. In C, C++, C#, D and Java, void is used to designate a function that does not return anything useful, or a function that accepts no arguments. The unit type in C is conceptually similar to an empty struct, but a struct without members is not allowed in the C language specification. Instead, 'void' is used in a manner that simulates some, but not all, of the properties of the unit type, as detailed below. Like most imperative languages, C allows functions that do not return a value; these are specified as having the void return type. Such functions are called procedures in other imperative languages like Pascal, where a syntactic distinction, instead of type-system distinction, is made between functions and procedures.The first notable difference between a true unit type and the void type is that the unit type may always be the type of the argument to a function, but the void type cannot be the type of an argument in C, despite the fact that it may appear as the sole argument in the list. This problem is best illustrated by the following program, which is a compile-time error in C:This issue does not arise in most programming practice in C, because since the void type carries no information, it is useless to pass it anyway; but it may arise in generic programming, such as C++ templates, where void must be treated differently from other types. In C++ however, empty classes are allowed, so it is possible to implement a real unit type; the above example becomes compilable as:(For brevity, we're not worried in the above example whether the_unit is really a singleton; see singleton pattern for details on that issue.)The second notable difference is that the void type is special and can never be stored in a record type, i.e. in a struct or a class in C/C++. In contrast, the unit type can be stored in records in functional programming languages, i.e. it can appear as the type of a field; the above implementation of the unit type in C++ can also be stored. While this may seem a useless feature, it does allow one for instance to elegantly implement a set as a map to the unit type; in the absence of a unit type, one can still implement a set this way by storing some dummy value of another type for each key.In Java Generics, type parameters must be reference types. The wrapper type Void is often used when a unit type parameter is needed. Although the Void type can never have any instances, it does have one value, null (like all other reference types), so it acts as a unit type. In practice, any other non-instantiable type, e.g. Math, can also be used for this purpose, since they also have exactly one value, null."
"14"	"This article describes the syntax of the C# programming language. The features described are compatible with .NET Framework and Mono.An identifier is the name of an element in the code. There are certain standard naming conventions to follow when selecting names for elements.An identifier can:An identifier cannot:Keywords are predefined reserved words with special syntactic meaning. The language has two types of keyword — contextual and reserved. The reserved keywords such as false or byte may only be used as keywords. The contextual keywords such as where or from are only treated as keywords in certain situations. If an identifier is needed which would be the same as a reserved keyword, it may be prefixed by the @ character to distinguish it. This facilitates reuse of .NET code written in other languages.Using a keyword as an identifier:The underscore symbol separates digits in number values for readability purposes. Compiler will ignore it.Generally, it may be put only between digit characters. It cannot be put at the beginning (_121) or the end of the value (121_ or 121.05_), next to the decimal in floating point values (10_.0), next to the exponent character (1.1e_1) and next to the type specifier (10_f).Variables are identifiers associated with values. They are declared by writing the variable's type and name, and are optionally initialized in the same statement.DeclareAssigningInitializeMultiple variables of the same type can be declared and initialized in one statement.C# 3.0 introduced type inference, allowing the type specifier of a variable declaration to be replaced by the keyword var, if its actual type can be statically determined from the initializer. This reduces repetition, especially for types with multiple generic type-parameters, and adheres more closely to the DRY principle.See alsoConstants are immutable values.When declaring a local variable or a field with the const keyword as a prefix the value must be given when it is declared. After that it is locked and cannot change. They can either be declared in the context as a field or a local variable. Constants are implicitly static.This shows all the uses of the keyword.The readonly keyword does a similar thing to fields. Like fields marked as const they cannot change once initialized. The difference is that you can choose to initialize them in a constructor. This only works on fields. Read-only fields can either be members of an instance or static class members.The operators { ... } are used to signify a code block and a new scope. Class members and the body of a method are examples of what can live inside these braces in various contexts.Inside of method bodies you can use the braces to create new scopes like so:A C# application consists of classes and their members. Classes and other types exist in namespaces but can also be nested inside other classes.Whether it is a console or a graphical interface application, the program must have an entry point of some sort. The entry point of the C# application is the Main method. There can only be one, and it is a static method in a class. The method usually returns void and is passed command-line arguments as an array of strings.A Main method is also allowed to return an integer value if specified.Namespaces are a part of a type name and they are used to group and/or distinguish named entities from other ones.A namespace is defined like this:The using statement loads a specific namespace from a referenced assembly. It is usually placed in the top (or header) of a code file but it can be placed elsewhere if wanted, e.g. inside classes.The statement can also be used to define another name for an existing namespace or type. This is sometimes useful when names are too long and less readable.Some of the existing operators can be overloaded by writing an overload method.These are the overloadable operators:See alsoThe cast operator is not overloadable but you can write a conversion operator method which lives in the target class. Conversion methods can define two varieties of operators, implicit and explicit conversion operators. The implicit operator will cast without specifying with the cast operator (( )) and the explicit operator requires it to be used.Implicit conversion operatorExplicit conversion operatorThe as operator will attempt to do a silent cast to a given type. If it succeeds it will return the object as the new type, if it fails it will return a null reference.The following:is shorthand for:Meaning that if the content of variable ifNotNullValue is not null, that content will be returned, otherwise the content of variable otherwiseValue is returned.C# inherits most of the control structures of C/C++ and also adds new ones like the foreach statement.These structures control the flow of the program through given conditions.The if statement is entered when the given condition is true. Single-line case statements do not require block braces although it is mostly preferred by convention.Simple one-line statement:Multi-line with else-block (without any braces):Recommended coding conventions for an if-statement.The switch construct serves as a filter for different values. Each value leads to a case. It is not allowed to fall through case sections and therefore the keyword break is typically used to end a case. An unconditional return in a case section can also be used to end a case. See also how goto statement can be used to fall through from one case to the next. Many cases may lead to the same code though. The default case handles all the other cases not handled by the construct.Iteration statements are statements that are repeatedly executed when a given condition is evaluated as true.The for loop consists of three parts: declaration, condition and increment. Any of them can be left out as they are optional.Is equivalent to this code represented with a while statement, except here the i variable is not local to the loop.The foreach statement is derived from the for statement and makes use of a certain pattern described in C#'s language specification in order to obtain and use an enumerator of elements to iterate over.Each item in the given collection will be returned and reachable in the context of the code block. When the block has been executed the next item will be returned until there are no items remaining.Jump statements are inherited from C/C++ and ultimately assembly languages through it. They simply represent the jump-instructions of an assembly language that controls the flow of a program.Labels are given points in code that can be jumped to by using the goto statement.The goto statement can be used in switch statements to jump from one case to another or to fall through from one case to the next.The break statement breaks out of the closest loop or switch statement. Execution continues in the statement after the terminated statement, if any.The continue statement discontinues the current iteration of the current control statement and begins the next iteration.The while loop in the code above reads characters by calling GetChar(), skipping the statements in the body of the loop if the characters are spaces.Runtime exception handling method in C# is inherited from Java and C++.The base class library has a class called System.Exception from which all other exception classes are derived. An Exception-object contains all the information about a specific exception and also the inner exceptions that were caused. Programmers may define their own exceptions by deriving from the Exception class.An exception can be thrown this way:Exceptions are managed within try ... catch blocks.The statements within the try block are executed, and if any of them throws an exception, execution of the block is discontinued and the exception is handled by the catch block. There may be multiple catch blocks, in which case the first block with an exception variable whose type matches the type of the thrown exception is executed.If no catch block matches the type of the thrown exception, the execution of the outer block (or method) containing the try ... catch statement is discontinued, and the exception is passed up and outside the containing block or method. The exception is propagated upwards through the call stack until a matching catch block is found within one of the currently active methods. If the exception propagates all the way up to the top-most Main() method without a matching catch block being found, the entire program is terminated and a textual description of the exception is written to the standard output stream.The statements within the finally block are always executed after the try and catch blocks, whether or not an exception was thrown. Such blocks are useful for providing clean-up code.Either a catch block, a finally block, or both, must follow the try block.C# is a statically typed language like C and C++. That means that every variable and constant gets a fixed type when it is being declared. There are two kinds of types: value types and reference types.Instances of value types reside on the stack, i.e. they are bound to their variables. If you declare a variable for a value type the memory gets allocated directly. If the variable gets out of scope the object is destroyed with it.Structures are more commonly known as structs. Structs are user-defined value types that are declared using the struct keyword. They are very similar to classes but are more suitable for lightweight types. Some important syntactical differences between a class and a struct are presented later in this article.The primitive data types are all structs.These are the primitive datatypes.Note: string (System.String) is not a struct and is not a primitive type.Enumerated types (enums) are named values representing integer values.enum variables are initialized by default to zero. They can be assigned or initialized to the named values defined by the enumeration type.enum type variables are integer values. Addition and subtraction between variables of the same type is allowed without any specific cast but multiplication and division is somewhat more risky and requires an explicit cast. Casts are also required for converting enum variables to and from integer types. However, the cast will not throw an exception if the value is not specified by the enum type definition.Values can be combined using the bitwise-OR operator  .See alsoVariables created for reference types are typed managed references. When the constructor is called, an object is created on the heap and a reference is assigned to the variable. When a variable of an object goes out of scope the reference is broken and when there are no references left the object gets marked as garbage. The garbage collector will then soon collect and destroy it.A reference variable is null when it does not reference any object.An array type is a reference type that refers to a space containing one or more elements of a certain type. All array types derive from a common base class, System.Array. Each element is referenced by its index just like in C++ and Java.An array in C# is what would be called a dynamic array in C++.Array initializers provide convenient syntax for initialization of arrays.Arrays can have more than one dimension, for example 2 dimensions to represent a grid.See alsoClasses are self-describing user-defined reference types. Essentially all types in the .NET Framework are classes, including structs and enums, that are compiler generated classes. Class members are private by default, but can be declared as public to be visible outside of the class or protected to be visible by any descendants of the class.The System.String class, or simply string, represents an immutable sequence of unicode characters (char).Actions performed on a string will always return a new string.The System.StringBuilder class can be used when a mutable string is wanted.Interfaces are data structures that contain member definitions with no actual implementation. A variable of an interface type is a reference to an instance of a class which implements this interface. See #Interfaces.C# provides type-safe object-oriented function pointers in the form of delegates.Initializing the delegate with an anonymous method. Initializing the delegate with lambda expression. Events are pointers that can point to multiple methods. More exactly they bind method pointers to one identifier. This can therefore be seen as an extension to delegates. They are typically used as triggers in UI development. The form used in C# and the rest of the Common Language Infrastructure is based on that in the classic Visual Basic.An event requires an accompanied event handler that is made from a special delegate that in a platform specific library like in Windows Presentation Foundation and Windows Forms usually takes two parameters: sender and the event arguments. The type of the event argument-object derive from the EventArgs class that is a part of the CLI base library.Once declared in its class the only way of invoking the event is from inside of the owner. A listener method may be implemented outside to be triggered when the event is fired.Custom event implementation is also possible:See alsoNullable types were introduced in C# 2.0 firstly to enable value types to be null (useful when working with a database).In reality this is the same as using the Nullable<T> struct.C# has and allows pointers to selected types (some primitives, enums, strings, pointers, and even arrays and structs if they contain only types that can be pointed) in unsafe context: methods and codeblock marked unsafe. These are syntactically the same as pointers in C and C++. However, runtime-checking is disabled inside unsafe blocks.Structs are required only to be pure structs with no members of a managed reference type, e.g. a string or any other class.In use:See alsoType dynamic is a feature that enables dynamic runtime lookup to C# in a static manner. Dynamic denotes a variable with an object with a type that is resolved at runtime, as opposed to compile-time, as normally is done.This feature takes advantage of the Dynamic Language Runtime (DLR) and has been designed specifically with the goal of interoping with dynamically typed languages like IronPython and IronRuby (Implementations of Python and Ruby for .NET).Dynamic-support also eases interop with COM objects.Anonymous types are nameless classes that are generated by the compiler. They are only consumable and yet very useful in a scenario like where you have a LINQ query which returns an object on select and you just want to return some specific values. Then you can define an anonymous type containing auto-generated read-only fields for the values.When instantiating another anonymous type declaration with the same signature the type is automatically inferred by the compiler.Boxing is the operation of converting a value of a value type into a value of a corresponding reference type.  Boxing in C# is implicit.Unboxing is the operation of converting a value of a reference type (previously boxed) into a value of a value type. Unboxing in C# requires an explicit type cast.Example:C# has direct support for object-oriented programming.An object is created with the type as a template and is called an instance of that particular type.In C#, objects are either references or values. No further syntactical distinction is made between those in code.All types, even value types in their boxed form, implicitly inherit from the System.Object class, the ultimate base class of all objects. This class contains the most common methods shared by all objects. Some of these are virtual and can be overridden.Classes inherit System.Object either directly or indirectly through another base class.Members Some of the members of the Object class:Classes are fundamentals of an object-oriented language such as C#. They serve as a template for objects. They contain members that store and manipulate data in a real-lifelike way.See alsoAlthough classes and structures are similar in both the way they are declared and how they are used, there are some significant differences. Classes are reference types and structs are value types. A structure is allocated on the stack when it is declared and the variable is bound to its address. It directly contains the value. Classes are different because the memory is allocated as objects on the heap. Variables are rather managed pointers on the stack which point to the objects. They are references.Structures require some more work than classes. For example, you need to explicitly create a default constructor which takes no arguments to initialize the struct and its members. The compiler will create a default one for classes. All fields and properties of a struct must have been initialized before an instance is created. Structs do not have finalizers and cannot inherit from another class like classes do. However, they inherit from System.ValueType, that inherits from System.Object. Structs are more suitable for smaller constructs of data.This is a short summary of the differences:2Always auto generated, and cannot be written by the programmerA class is declared like this:A partial class is a class declaration whose code is divided into separate files. The different parts of a partial class must be marked with keyword partial.Before you can use the members of the class you need to initialize the variable with a reference to an object. To create it you call the appropriate constructor using the new keyword. It has the same name as the class.For structs it is optional to explicitly call a constructor because the default one is called automatically. You just need to declare it and it gets initialized with standard values.Provides a more convenient way of initializing public fields and properties of an object. Constructor calls are optional when there is a default constructor.Collection initializers give an array-like syntax for initializing collections. The compiler will simply generate calls to the Add-method. This works for classes that implement the interface ICollection.Members of an instance and static members of a class are accessed using the . operator.Accessing an instance member Instance members can be accessed through the name of a variable.Accessing a static class member Static members are accessed by using the name of the class or other type.Accessing a member through a pointer In unsafe code, members of a value (struct type) referenced by a pointer are accessed with the -> operator just like in C and C++.Modifiers are keywords used to modify declarations of types and type members. Most notably there is a sub-group containing the access modifiers.The static modifier states that a member belongs to the class and not to a specific object. Classes marked static are only allowed to contain static members. Static members are sometimes referred to as class members since they apply to the class as a whole and not to its instances.The access modifiers, or inheritance modifiers, set the accessibility of classes, methods, and other members. Something marked public can be reached from anywhere. private members can only be accessed from inside of the class they are declared in and will be hidden when inherited. Members with the protected modifier will be private, but accessible when inherited. internal classes and members will only be accessible from the inside of the declaring assembly.Classes and structs are implicitly internal and members are implicitly private if they do not have an access modifier.This table defines where the access modifiers can be used.A constructor is a special method that is called automatically when an object is created. Its purpose is to initialize the members of the object. Constructors have the same name as the class and do not return anything. They may take parameters like any other method.Constructors can be public, private, protected or internal.See alsoThe destructor is called when the object is being collected by the garbage collector to perform some manual clean-up. There is a default destructor method called finalize that can be overridden by declaring your own.The syntax is similar to the one of constructors. The difference is that the name is preceded by a ~ and it cannot contain any parameters. There cannot be more than one destructor..Finalizers are always private.See alsoLike in C and C++ there are functions that group reusable code. The main difference is that functions, just like in Java, have to reside inside of a class. A function is therefore called a method. A method has a return value, a name and usually some parameters initialized when it is called with some arguments. It can either belong to an instance of a class or be a static member.A method is called using . notation on a specific variable, or as in the case of static methods, the name of a type.See alsoOne can explicitly make arguments be passed by reference when calling a method with parameters preceded by keywords ref or out. These managed pointers come in handy when passing variables that you want to be modified inside the method by reference. The main difference between the two is that an out parameter must have been assigned within the method by the time the method returns, while ref need not assign a value.C# 4.0 introduces optional parameters with default values as seen in C++. For example:In addition, to complement optional parameters, it is possible to explicitly specify parameter names in method calls, allowing to selectively pass any given subset of optional parameters for a method. The only restriction is that named parameters must be placed after the unnamed parameters. Parameter names can be specified for both optional and required parameters, and can be used to improve readability or arbitrarily reorder arguments in a call. For example:Optional parameters make interoperating with COM easier. Previously, C# had to pass in every parameter in the method of the COM component, even those that are optional. For example:With support for optional parameters, the code can be shortened asA feature of C# is the ability to call native code. A method signature is simply declared without a body and is marked as extern. The DllImport attribute also needs to be added to reference the desired DLL file.Fields, or class variables, can be declared inside the class body to store data.Fields can be initialized directly when declared (unless declared in struct).Modifiers for fields:Properties bring field-like syntax and combine them with the power of methods. A property can have two accessors: get and set.Modifiers for properties:Modifiers for property accessors:The default modifiers for the accessors are inherited from the property. Note that the accessor's modifiers can only be equal or more restrictive than the property's modifier.A feature of C# 3.0 is auto-implemented properties. You define accessors without bodies and the compiler will generate a backing field and the necessary code for the accessors.Indexers add array-like indexing capabilities to objects. They are implemented in a way similar to properties.Classes in C# may only inherit from one class. A class may derive from any class that is not marked as sealed.See alsoMethods marked virtual provide an implementation, but they can be overridden by the inheritors by using the override keyword.The implementation is chosen by the actual type of the object and not the type of the variable.When overloading a non-virtual method with another signature, the keyword new may be used. The used method will be chosen by the type of the variable instead of the actual type of the object.This demonstrates the case:Abstract classes are classes that only serve as templates and you can not initialize an object of that type. Otherwise it is just like an ordinary class.There may be abstract members too. Abstract members are members of abstract classes that do not have any implementation. They must be overridden by the class that inherits the member.The sealed modifier can be combined with the others as an optional modifier for classes to make them uninheritable.Interfaces are data structures that contain member definitions and not actual implementation. They are useful when you want to define a contract between members in different types that have different implementations. You can declare definitions for methods, properties, and indexers. Interface members are implicitly public. An interface can either be implicitly or explicitly implemented.An interface is implemented by a class or extended by another interface in the same way you derive a class from another class using the : notation.Implicit implementationWhen implicitly implementing an interface the members of the interface have to be public.In use:Explicit implementationYou can also explicitly implement members. The members of the interface that are explicitly implemented by a class are accessible only when the object is handled as the interface type.In use:Note: The properties in the class that extends IBinaryOperation are auto-implemented by the compiler and a backing field is automatically added (see #Automatic properties).Extending multiple interfacesInterfaces and classes are allowed to extend multiple interfaces.Here is an interface that extends two interfaces.Interfaces and abstract classes are similar. The following describes some important differences:Generics (or parameterized types, parametric polymorphism) use type parameters, which make it possible to design classes and methods that do not specify the type used until the class or method is instantiated. The main advantage is that one can use generic type parameters to create classes and methods that can be used without incurring the cost of runtime casts or boxing operations, as shown here:When compared with C++ templates, C# generics can provide enhanced safety, but also have somewhat limited capabilities. For example, it is not possible to call arithmetic operators on a C# generic type. Unlike C++ templates, .NET parameterized types are instantiated at runtime rather than by the compiler; hence they can be cross-language whereas C++ templates cannot. They support some features not supported directly by C++ templates such as type constraints on generic parameters by use of interfaces. On the other hand, C# does not support non-type generic parameters.Unlike generics in Java, .NET generics use reification to make parameterized types first-class objects in the Common Language Infrastructure (CLI) Virtual Machine, which allows for optimizations and preservation of the type information.Classes and structs can be generic.Type-parameters are names used in place of concrete types when defining a new generic. They may be associated with classes or methods by placing the type parameter in angle brackets < >. When instantiating (or calling) a generic, you can then substitute a concrete type for the type-parameter you gave in its declaration. Type parameters may be constrained by use of the where keyword and a constraint specification, any of the six comma separated constraints may be used:Generic interfaces and delegates can have their type parameters marked as covariant or contravariant, using keywords out and in, respectively. These declarations are then respected for type conversions, both implicit and explicit, and both compile-time and run-time. For example, the existing interface IEnumerable<T> has been redefined as follows:Therefore, any class that implements IEnumerable<Derived> for some class Derived is also considered to be compatible with IEnumerable<Base> for all classes and interfaces Base that Derived extends, directly, or indirectly. In practice, it makes it possible to write code such as:For contravariance, the existing interface IComparer<T> has been redefined as follows:Therefore, any class that implements IComparer<Base> for some class Base is also considered to be compatible with IComparer<Derived> for all classes and interfaces Derived that are extended from Base. It makes it possible to write code such as:An enumerator is an iterator. Enumerators are typically obtained by calling the GetEnumerator() method of an object implementing the IEnumerable interface. Container classes typically implement this interface. However, the foreach statement in C# can operate on any object providing such a method, even if it doesn't implement IEnumerable. This interface was expanded into generic version in .NET 2.0.The following shows a simple use of iterators in C# 2.0:The .NET 2.0 Framework allowed C# to introduce an iterator that provides generator functionality, using a yield return construct similar to yield in Python. With a yield return, the function automatically keeps its state during the iteration.LINQ, short for Language Integrated Queries, is a .NET Framework feature which simplifies the handling of data. Mainly it adds support that allows you to query arrays, collections, and databases. It also introduces binders, which makes it easier to access to databases and their data.The LINQ query syntax was introduced in C# 3.0 and lets you write SQL-like queries in C#.The statements are compiled into method calls, whereby almost only the names of the methods are specified. Which methods are ultimately used is determined by normal overload resolution. Thus, the end result of the translation is affected by what symbols are in scope.What differs from SQL is that the from-statement comes first and not last as in SQL. This is because it seems more natural writing like this in C# and supports Intellisense (Code completion in the editor).Anonymous methods, or in their present form more commonly referred to as lambda expressions, is a feature which allows you to write inline closure-like functions in your code.There are various ways to create anonymous methods. Prior to C# 3.0 there was limited support by using delegates.See alsoAnonymous delegates are functions pointers that hold anonymous methods. The purpose is to make it simpler to use delegates by simplifying the process of assigning the function. Instead of declaring a separate method in code the programmer can use the syntax to write the code inline and the compiler will then generate an anonymous function for it.Lambda expressions provide a simple syntax for inline functions that are similar to closures. Functions with parameters infer the type of the parameters if other is not explicitly specified.Multi-statement lambdas have bodies enclosed by braces and inside of them code can be written like in standard methods.Lambda expressions can be passed as arguments directly in method calls similar to anonymous delegates but with a more aesthetic syntax.Lambda expressions are essentially compiler-generated methods that are passed via delegates. These methods are reserved for the compiler only and can not be used in any other context.Extension methods are a form of syntactic sugar providing the illusion of adding new methods to the existing class outside its definition. In practice, an extension method is a static method that is callable as if it were an instance method; the receiver of the call is bound to the first parameter of the method, decorated with keyword this:See alsoLocal functions can be defined in the body of another method, constructor or property’s getter and setter. Such functions have access to all variables in the enclosing scope, including parent method local variables. They are in scope for the entire method, regardless of whether they’re invoked before or after their declaration. Access modifiers (public, private, protected) cannot be used with local functions. Also they do not support function overloading. It means there cannot be two local functions in the same method with the same name even if the signatures don’t overlap. After a compilation, a local function is transformed into a private static method, but when defined it cannot be marked static.In code example below, the Sum method is a local function inside Main method. So it can be used only inside its parent method Main:C# implements closure blocks by means of the using statement. The using statement accepts an expression which results in an object implementing IDisposable, and the compiler generates code that guarantees the object's disposal when the scope of the using-statement is exited. The using statement is syntactic sugar. It makes the code more readable than the equivalent try ... finally block.C# provides the lock statement, which is yet another example of beneficial syntactic sugar. It works by marking a block of code as a critical section by mutual exclusion of access to a provided object. Like the using statement, it works by the compiler generating a try ... finally block in its place.Attributes are entities of data that are stored as metadata in the compiled assembly. An attribute can be added to types and members like properties and methods. Attributes can be used for better maintenance of preprocessor directives.The .NET Framework comes with predefined attributes that can be used. Some of them serve an important role at runtime while some are just for syntactic decoration in code like CompilerGenerated. It does only mark that it is a compiler-generated element. Programmer-defined attributes can also be created.An attribute is essentially a class which inherits from the System.Attribute class. By convention, attribute classes end with Attribute in their name. This will not be required when using it.Showing the attribute in use using the optional constructor parameters.C# features preprocessor directives (though it does not have an actual preprocessor) based on the C preprocessor that allow programmers to define symbols, but not macros. Conditionals such as #if, #endif, and #else are also provided.Directives such as #region give hints to editors for code folding. The #region block must be terminated with a #endregion directive.C# utilizes a double slash (//) to indicate the rest of the line is a comment.Multi-line comments can be indicated by a starting slash/asterisk (/*) and ending asterisk/forward slash (*/).Comments do not nest. These are two single comments:Single-line comments beginning with three slashes are used for XML documentation. This, however, is a convention used by Visual Studio and is not part of the language definition:C#'s documentation system is similar to Java's Javadoc, but based on XML. Two methods of documentation are currently supported by the C# compiler.Single-line documentation comments, such as those commonly found in Visual Studio generated code, are indicated on a line beginning with // /.Multi-line documentation comments, while defined in the version 1.0 language specification, were not supported until the .NET 1.1 release. These comments are designated by a starting forward slash/asterisk/asterisk (/**) and ending asterisk/forward slash (*/).There are some stringent criteria regarding white space and XML documentation when using the forward slash/asterisk/asterisk (/**) technique.This code block:produces a different XML comment than this code block:Syntax for documentation comments and their XML markup is defined in a non-normative annex of the ECMA C# standard. The same standard also defines rules for processing of such comments, and their transformation to a plain XML document with precise rules for mapping of Common Language Infrastructure (CLI) identifiers to their related documentation elements. This allows any C# integrated development environment (IDE) or other development tool to find documentation for any symbol in the code in a certain well-defined way.As of .NET Framework 4 there is a task library that makes it easier to write parallel and multi-threaded applications through tasks.C# 5.0 has native language support for asynchrony.Consider this code that takes advantage of the task library directly:Here is the same logic written in the async-await syntax:Spec# is a dialect of C# that is developed in parallel with the standard implementation from Microsoft. It extends C# with specification language features and is a possible future feature to the C# language. It also adds syntax for the code contracts API that was introduced in .NET Framework 4.0. Spec# is being developed by Microsoft Research.This sample shows two of the basic structures that are used when adding contracts to your code.Spec# extends C# with non-nullable types that simply checks so the variables of nullable types that has been set as non-nullable are not null. If is null then an exception will be thrown.In use:Preconditions are checked before a method is executed.Postconditions are conditions that are ensured to be correct when a method has been executed.Spec# adds checked exceptions like those in Java.Checked exceptions are problematic, because when a lower-level function adds a new exception type, the whole chain of methods using this method at some nested lower level must also change its contract. This violates the open/closed principle."
"15"	"In software engineering, the module pattern is a design pattern used to implement the concept of software modules, defined by modular programming, in a programming language with incomplete direct support for the concept.This pattern can be implemented in several ways depending on the host programming language, such as the singleton design pattern, object-oriented static members in a class and procedural global functions. In Python, the pattern is built into the language, and each .py file is automatically a module.The module software design pattern provides the features and syntactic structure defined by the modular programming paradigm to programming languages that have incomplete support for the concept.In software development, source code can be organized into components that accomplish a particular function or contain everything necessary to accomplish a particular task. Modular programming is one of those approaches.The concept of a module is not fully supported in many common programming languages.In order to consider that a Singleton or any group of related code implements this pattern, the following features must be supplied:The semantics and syntax of each programming language may affect the implementation of this pattern.Although Java supports the notion of a namespace, a reduced version of a module, some scenarios benefit from employing the design pattern instead of using namespaces.The following example uses the singleton pattern.C#, like Java, supports namespaces although the pattern remains useful in specific cases.The following example uses the singleton pattern.JavaScript is commonly used to automate web pages.This pattern may be seen as a procedural extension to object-oriented languages.Although the procedural and modular programming paradigms are often used together, there are cases where a procedural programming language may not fully support modules, hence requiring a design pattern implementation.This example applies to procedural PHP before namespaces (introduced in version 5.3.0). It is recommended that each member of a module is given a prefix related to the filename or module name in order to avoid identifier collisions.Note that this example applies to procedural C without namespaces. It is recommended that each member of a module is given a prefix related to the filename or module name in order to avoid identifier collisions.Note that this example applies to procedural non-modular Pascal. Many Pascal dialects have namespace support, called unit (s). Some dialects also support initialization and finalization.If namespaces are not supported, it is recommended to give all member names a prefix related to the filename or module name in order to prevent identifier collisions.Both namespaces and modules allow to group several related entities by a single identifier, and in some situations, used interchangeably. Those entities can be globally accessed. The main purpose of both concepts is the same.In some scenarios a namespace requires that the global elements that compose it are initialized and finalized by a function or method call.In many programming languages, namespaces are not directly intended to support an initialization process nor a finalization process, and are therefore not equivalent to modules. That limitation can be worked around in two ways. In namespaces that support global functions, a function for initialization and a function for finalization are coded directly, and called directly in the main program code.Classes are used sometimes used as or with namespaces. In programming languages that don't support namespaces (e.g., JavaScript) but do support classes and objects, classes are often used to substitute for namespaces. These classes are usually not instantiated and consist exclusively of static members.In object-oriented programming languages where namespaces are incompletely supported, the singleton pattern may be used instead of static members within a non-instantiable class.The module pattern can be implemented using a specialization of the singleton pattern. However, other design patterns may be applied and combined, in the same class.This pattern can be used as a decorator, a flyweight, or an adapter.The Module pattern can be considered a creational pattern and a structural pattern. It manages the creation and organization of other elements, and groups them as the structural pattern does.An object that applies this pattern can provide the equivalent of a namespace, providing the initialization and finalization process of a static class or a class with static members with cleaner, more concise syntax and semantics.It supports specific cases where a class or object can be considered structured, procedural data. And, vice versa, migrate structured, procedural data, and considered as object-oriented."
"16"	"Xcode is an integrated development environment (IDE) for macOS containing a suite of software development tools developed by Apple for developing software for macOS, iOS, watchOS, and tvOS. First released in 2003, the latest stable release is version 9.2 and is available via the Mac App Store free of charge for macOS High Sierra and macOS Sierra users.Registered developers can download preview releases and prior versions of the suite through the Apple Developer website.Xcode supports source code for the programming languages C, C++, Objective-C, Objective-C++, Java, AppleScript, Python, Ruby, ResEdit (Rez), and Swift, with a variety of programming models, including but not limited to Cocoa, Carbon, and Java. Third parties have added support for GNU Pascal,Free Pascal,Ada,C#,Perl, and D.Thanks to the Mach-O executable format, which allows fat binary files, containing code for multiple architectures, Xcode can build universal binary files, which allow software to run on both PowerPC and Intel-based (x86) platforms and that can include both 32-bit and 64-bit code for both architectures. Using the iOS SDK, Xcode can also be used to compile and debug applications for iOS that run on ARM architecture processors.Xcode includes the GUI tool Instruments, which runs atop a dynamic tracing framework, DTrace, created by Sun Microsystems and released as part of OpenSolaris.The main application of the suite is the integrated development environment (IDE), also named Xcode. The Xcode suite includes most of Apple's developer documentation, and built-in Interface Builder, an application used to construct graphical user interfaces.Up to Xcode 4.1, the Xcode suite included a modified version of the GNU Compiler Collection.  In Xcode 3.1 up to Xcode 4.6.3, it included the LLVM-GCC compiler, with front ends from the GNU Compiler Collection and a code generator based on LLVM. In Xcode 3.2 and later, it included the Clang C/C++/Objective-C compiler, with newly-written front ends and a code generator based on LLVM, and the Clang static analyzer.  Starting with Xcode 4.2, the Clang compiler became the default compiler, Starting with Xcode 5.0, Clang was the only compiler provided.Up to Xcode 4.6.3, the Xcode suite used the GNU Debugger (GDB) as the back-end for the IDE's debugger. Starting with Xcode 4.3, the LLDB debugger was also provided; starting with Xcode 4.5 LLDB replaced GDB as the default back-end for the IDE's debugger. Starting with Xcode 5.0, GDB was no longer supplied.Formerly, Xcode supported distributing a product build process over multiple systems. One technology involved was named Shared Workgroup Build, which used the Bonjour protocol to automatically discover systems providing compiler services, and a modified version of the free software product distcc to facilitate the distribution of workloads. Earlier versions of Xcode provided a system named Dedicated Network Builds. These features are absent in the supported versions of Xcode.Xcode also includes Apple's WebObjects tools and frameworks for building Java web applications and web services (formerly sold as a separate product). As of Xcode 3.0, Apple dropped WebObjects development inside Xcode; WOLips should be used instead. Xcode 3 still includes the WebObjects frameworks.Xcode 1.0 was released in fall 2003. Xcode 1.0 was based on Project Builder, but had an updated user interface (UI), ZeroLink, Fix & Continue, distributed build support, and Code Sense indexing.The next significant release, Xcode 1.5, had better code completion and an improved debugger.Xcode 2.0 was released with Mac OS X v10.4 Tiger. It included the Quartz Composer visual programming language, better Code Sense indexing for Java, and Ant support. It also included the Apple Reference Library tool, which allows searching and reading online documentation from Apple’s website and documentation installed on a local computer.Xcode 2.1 could create universal binary files. It supported shared precompiled headers, unit testing targets, conditional breakpoints, and watchpoints. It also had better dependency analysis.The final version of Xcode for Mac OS X v10.4 was 2.5.Xcode 3.0 was released with Mac OS X v10.5 Leopard. Notable changes since 2.1 include the DTrace debugging tool (now named Instruments), refactoring support, context-sensitive documentation, and Objective-C 2.0 with garbage collection.  It also supports Project Snapshots, which provide a basic form of version control; Message Bubbles, which show build errors debug values alongside code; and building four-architecture fat binaries (32 and 64-bit Intel and PowerPC).Xcode 3.1 was an update release of the developer tools for Mac OS X, and was the same version included with the iPhone SDK. It could target non-Mac OS X platforms, including iPhone OS 2.0. It included the GCC 4.2 and LLVM GCC 4.2 compilers. Another new feature since Xcode 3.0 is that Xcode's SCM support now includes Subversion 1.5.Xcode 3.2 was released with Mac OS X v10.6 Snow Leopard and installs on no earlier version of OS X.  It supports static program analysis, among other features. It also drops official support for targeting versions earlier than iPhone OS 3.0. But it is still possible to target older versions, and the simulator supports iPhone OS 2.0 through 3.1. Also, Java support is exiled in 3.2 to the organizer.Xcode 3.2.6 is the last version that can be downloaded for free for users of Mac OS X v10.6. Downloading it requires a free registration at Apple's developer site.In June 2010, at the Apple Worldwide Developers Conference version 4 of Xcode was announced during the Developer Tools State of the Union address. Version 4 of the developer tools consolidates the Xcode editing tools and Interface Builder into one application, among other enhancements. Apple released the final version of Xcode 4.0 on March 9, 2011. The software was made available for free to all registered members of the $99 per year Mac Developer program and the $99 per year iOS Developer program. It was also sold for $4.99 to non-members on the Mac App Store (no longer available).  Xcode 4.0 drops support for many older systems, including all PowerPC development and software development kits (SDKs) for Mac OS X 10.4 and 10.5, and all iOS SDKs older than 4.3.  The deployment target can still be set to produce binaries for those older platforms, but for Mac OS platforms, one is then limited to creating x86 and x86-64 binaries. Later, Xcode was free to the general public. Before version 4.1, Xcode cost $4.99.Xcode 4.1 was made available for free on July 20, 2011 (the day of Mac OS X Lion's release) to all users of Mac OS X Lion on the Mac App Store. On August 29, 2011, Xcode 4.1 was made available for Mac OS X Snow Leopard for members of the paid Mac or iOS developer programs. Xcode 4.1 was the last version to include GNU Compiler Collection (GCC) instead of only LLVM GCC or Clang.On October 12, 2011, Xcode 4.2 was released concurrently with the release of iOS 5.0, and it included many more and improved features, such as storyboarding and automatic reference counting (ARC). Xcode 4.2 is the last version to support Mac OS X 10.6 Snow Leopard, but is only available to registered developers with paid accounts; without a paid account, 3.2.6 is the latest download that appears for Snow Leopard.Xcode 4.3, released on February 16, 2012, is distributed as one application bundle, Xcode.app, installed from the Mac App Store. Xcode 4.3 reorganizes the Xcode menu to include development tools. Xcode 4.3.1 was released on March 7, 2012 to add support for iOS 5.1. Xcode 4.3.2 was released on March 22, 2012 with enhancements to the iOS Simulator and a suggested move to the LLDB debugger versus the GDB debugger (which appear to be undocumented changes).[citation needed] Xcode 4.3.3, released in May 2012, featured an updated SDK for Mac OS X 10.7.4 Lion and a few bug fixes.Xcode 4.4 was released on July 25, 2012. It runs on both Mac OS X Lion (10.7) and OS X Mountain Lion (10.8) and is the first version of Xcode to contain the OS X 10.8 Mountain Lion SDK. Xcode 4.4 includes support for automatic synthesizing of declared properties, new Objective-C features such as literal syntax and subscripting, improved localization, and more. On August 7, 2012, Xcode 4.4.1 was released with a few bug fixes.On September 19, 2012, iOS 6 and Xcode 4.5 were released. Xcode added support for iOS 6 and the 4-inch Retina Display on iPhone 5 and iPod touch 5th generation. It also brought some new Objective-C features to iOS, simplified localization, and added auto-layout support for iOS. On October 3, 2012, Xcode 4.5.1 was released with bug fixes and stability improvements. Less than a month later, Xcode 4.5.2 was released, with support for iPad Mini and iPad with Retina Display, and bug fixes and stability improvements.On January 28, 2013, iOS 6.1 and Xcode 4.6 were released.In June 2013, at the Apple Worldwide Developers Conference, version 5 of Xcode was announced. On September 18, 2013 Xcode 5.0 was released. It added support for iOS 7 SDK, with always support of OS X 10.8 Mountain Lion SDK but not the support of OS X 10.9 Mavericks SDK. This latest was only included in the betas version. It also added a version of Clang generating 64-bit ARM code for iOS 7. Apple removed support for building garbage collected Cocoa binaries in Xcode 5.1.On June 2, 2014 at the World Wide Developers Conference, Apple announced version 6 of Xcode. Features include Playgrounds, live debugging tools, and a new programming language named Swift. On September 17, 2014, at the same time, iOS and Xcode 6 were released. Xcode could be downloaded on the Mac App Store.On June 8, 2015 at the Apple Worldwide Developers Conference Xcode version 7 was announced. It introduced support for Swift 2, and Metal for OS X, and added support for deploying on iOS devices without an Apple Developer license. Xcode 7 was released on September 16, 2015.On June 13, 2016 at the Apple Worldwide Developers Conference Xcode version 8 was announced. It introduced support for Swift 3. Xcode 8 was released on September 13, 2016.On June 5, 2017 at the Apple Worldwide Developers Conference Xcode version 9 was announced. It introduced support for Swift 4 and Metal 2. It also introduced remotely debugging iOS and tvOS devices wirelessly through WiFi.Xcode 9 was publicly released on September 19, 2017.1.01.11.21.52.02.12.22.2.12.32.42.4.12.53.03.13.1.13.1.23.1.33.1.43.23.2.13.2.23.2.33.2.43.2.53.2.64.04.0.14.0.24.14.1.14.24.2.14.34.3.14.3.24.3.34.44.4.14.54.5.14.5.24.64.6.14.6.24.6.35.05.0.15.0.25.15.1.16.0.16.16.1.16.26.36.3.16.3.26.47.07.0.17.17.1.17.27.2.17.37.3.18.08.18.28.2.18.38.3.18.3.28.3.39.09.0.19.19.2"
"17"	"The LLVM compiler infrastructure project is a collection of modular and reusable compiler and toolchain technologies used to develop compiler front ends and back ends.LLVM is written in C++ and is designed for compile-time, link-time, run-time, and idle-time optimization of programs written in arbitrary programming languages. Originally implemented for C and C++, the language-agnostic design of LLVM has since spawned a wide variety of front ends: languages with compilers that use LLVM include ActionScript, Ada, C#,Common Lisp, Crystal, CUDA, D, Delphi, Fortran, Halide, Haskell, Java bytecode, Julia, Kotlin, Lua, Objective-C, OpenGL Shading Language, Pony,Python, R, Ruby,Rust, Scala,Swift, and Xojo.The LLVM project started in 2000 at the University of Illinois at Urbana–Champaign, under the direction of Vikram Adve and Chris Lattner. LLVM was originally developed as a research infrastructure to investigate dynamic compilation techniques for static and dynamic programming languages. LLVM was released under the University of Illinois/NCSA Open Source License, a permissive free software licence. In 2005, Apple Inc. hired Lattner and formed a team to work on the LLVM system for various uses within Apple's development systems. LLVM is an integral part of Apple's latest development tools for macOS and iOS. Since 2013, Sony has been using LLVM's primary front end Clang compiler in the software development kit (SDK) of its PS4 console.The name LLVM was originally an initialism for Low Level Virtual Machine. This initialism has officially been removed to avoid confusion, as the LLVM has evolved into an umbrella project that has little relationship to what most current developers think of as virtual machines. Now, LLVM is a brand that applies to the LLVM umbrella project, the LLVM intermediate representation (IR), the LLVM debugger, the LLVM implementation of the C++ Standard Library (with full support of C++11 and C++14), etc. LLVM is administered by the LLVM Foundation. Its president is compiler engineer Tanya Lattner.The Association for Computing Machinery presented Adve, Lattner, and Evan Cheng with the 2012 ACM Software System Award for LLVM.LLVM can provide the middle layers of a complete compiler system, taking intermediate representation (IR) code from a compiler and emitting an optimized IR. This new IR can then be converted and linked into machine-dependent assembly language code for a target platform. LLVM can accept the IR from the GNU Compiler Collection (GCC) toolchain, allowing it to be used with a wide array of extant compilers written for that project.LLVM can also generate relocatable machine code at compile-time or link-time or even binary machine code at run-time.LLVM supports a language-independent instruction set and type system. Each instruction is in static single assignment form (SSA), meaning that each variable (called a typed register) is assigned once and then frozen. This helps simplify the analysis of dependencies among variables. LLVM allows code to be compiled statically, as it is under the traditional GCC system, or left for late-compiling from the IR to machine code via just-in-time compilation (JIT), similar to Java. The type system consists of basic types such as integer or floating point numbers and five derived types: pointers, arrays, vectors, structures, and functions. A type construct in a concrete language can be represented by combining these basic types in LLVM. For example, a class in C++ can be represented by a mix of structures, functions and arrays of function pointers.The LLVM JIT compiler can optimize unneeded static branches out of a program at runtime, and thus is useful for partial evaluation in cases where a program has many options, most of which can easily be determined unneeded in a specific environment. This feature is used in the OpenGL pipeline of Mac OS X Leopard (v10.5) to provide support for missing hardware features.Graphics code within the OpenGL stack can be left in intermediate representation, and then compiled when run on the target machine. On systems with high-end graphics processing units (GPUs), the resulting code remains quite thin, passing the instructions on to the GPU with minimal changes. On systems with low-end GPUs, LLVM will compile optional procedures that run on the local central processing unit (CPU) that emulate instructions that the GPU cannot run internally. LLVM improved performance on low-end machines using Intel GMA chipsets. A similar system was developed under the Gallium3D LLVMpipe, and incorporated into the GNOME shell to allow it to run without a proper 3D hardware driver loaded.For run-time performance of the compiled programs, GCC formerly outperformed LLVM by 10% on average. Newer results indicate that LLVM has now caught up with GCC in this area, and is now compiling binaries of approximately equal performance.LLVM has become an umbrella project containing multiple components.LLVM was originally written to be a replacement for the existing code generator in the GCC stack, and many of the GCC front ends have been modified to work with it. LLVM currently supports compiling of Ada, C, C++, D, Delphi, Fortran, Haskell, Objective-C and Swift using various front ends, some derived from version 4.0.1 and 4.2 of the GNU Compiler Collection (GCC).Widespread interest in LLVM has led to several efforts to develop new front ends for a variety of languages. The one that has received the most attention is Clang, a new compiler supporting C, C++, and Objective-C. Primarily supported by Apple, Clang is aimed at replacing the C/Objective-C compiler in the GCC system with a system that is more easily integrated with integrated development environments (IDEs) and has wider support for multithreading. Support for OpenMP directives has been included in Clang since release 3.8.The Utrecht Haskell compiler can generate code for LLVM. Though the generator is in the early stages of development, in many cases it has been more efficient than the C code generator. The Glasgow Haskell Compiler (GHC) has a working LLVM backend that achieves a 30% speed-up of the compiled code relative to native code compiling via GHC or C code generation followed by compiling, missing only one of the many optimizing techniques implemented by the GHC.Many other components are in various stages of development, including, but not limited to, the Rust compiler, a Java bytecode front end, a Common Intermediate Language (CIL) front end, the MacRuby implementation of Ruby 1.9, various front ends for Standard ML, and a new graph coloring register allocator.[citation needed]The core of LLVM is the intermediate representation (IR), a low-level programming language similar to assembly. IR is a strongly typed reduced instruction set computing (RISC) instruction set which abstracts away details of the target. For example, the calling convention is abstracted through call and ret instructions with explicit arguments. Also, instead of a fixed set of registers, IR uses an infinite set of temporaries of the form %0, %1, etc. LLVM supports three isomorphic (i.e., functionally equivalent) forms of IR: a human-readable assembly format, a C++ object format suitable for frontends, and a dense bitcode format for serializing. A simple Hello, world! program in the assembly format:At version 3.4, LLVM supports many instruction sets, including ARM, Qualcomm Hexagon, MIPS, Nvidia Parallel Thread Execution (PTX; called NVPTX in LLVM documentation), PowerPC,  AMD TeraScale, AMD Graphics Core Next (GCN), SPARC, z/Architecture (called SystemZ in LLVM documentation), x86, x86-64, and XCore. Some features are not available on some platforms. Most features are present for x86, x86-64, z/Architecture, ARM, and PowerPC.The LLVM machine code (MC) subproject is LLVM's framework for translating machine instructions between textual forms and machine code. Formerly, LLVM relied on the system assembler, or one provided by a toolchain, to translate assembly into machine code. LLVM MC's integrated assembler supports most LLVM targets, including x86, x86-64, ARM, and ARM64. For some targets, including the various MIPS instruction sets, integrated assembly support is usable but still in the beta stage.The lld subproject is an attempt to develop a built-in, platform-independent linker for LLVM. lld aims to remove dependence on a third-party linker. As of  May 2017[update], lld supports ELF, PE/COFF, and Mach-O in descending order of completeness. In cases where lld is insufficient, another linker such as GNU ld can be used.Using lld allows link-time optimization. When link-time optimization is enabled, the compiler generates LLVM bitcode instead of native code, and native code generation is done by the linker.The LLVM project includes an implementation of the C++ Standard Library, dual-licensed under the MIT License and the UIUC license.The LLVM project started in 2000 at the University of Illinois at Urbana–Champaign, under the direction of Vikram Adve and Chris Lattner. LLVM was originally developed as a research infrastructure to investigate dynamic compilation techniques for static and dynamic programming languages. LLVM was released under the University of Illinois/NCSA Open Source License, a permissive free software licence. In 2005, Apple Inc. hired Lattner and formed a team to work on the LLVM system for various uses within Apple's development systems. LLVM is an integral part of Apple's latest development tools for macOS and iOS. Since 2013, Sony has been using LLVM's primary front end Clang compiler in the software development kit (SDK) of its PS4 console."
"18"	"Clang /'klæ<U+014B>/ is a compiler front end for the programming languages C, C++, Objective-C, Objective-C++, OpenMP,OpenCL, and CUDA. It uses LLVM as its back end and has been part of the LLVM release cycle since LLVM 2.6.It is designed to act as a drop-in replacement for the GNU Compiler Collection, supporting most of its compilation flags and unofficial language extensions. Its contributors include Apple, Microsoft, Google, ARM, Sony, Intel and Advanced Micro Devices (AMD). It is open-source software, with source code released under the University of Illinois/NCSA License, a permissive free software licence.The Clang project includes the Clang front end and the Clang static analyzer and several code analysis tools.Starting in 2005, Apple made extensive use of LLVM in a number of commercial systems, including the iPhone software development kit (SDK) and integrated development environment (IDE) Xcode 3.1.One of the first uses of LLVM was an OpenGL code compiler for OS X that converts OpenGL calls into more fundamental calls for graphics processing units (GPU) that do not support certain features. This allowed Apple to support the entire OpenGL application programming interface (API) on computers using Intel Graphics Media Accelerator (GMA) chipsets, increasing performance on those machines. For GPUs that support it, the code is compiled to exploit fully the underlying hardware, but on GMA machines, LLVM compiles the same OpenGL code into subroutines to ensure continued proper function.LLVM was intended originally to use GCC's front end, but GCC turned out to cause some problems for developers of LLVM and at Apple. The GCC source code is a large and somewhat cumbersome system for developers to work with; as one long-time GCC developer put it, Trying to make the hippo dance is not really a lot of fun.Apple software makes heavy use of Objective-C, but the Objective-C front-end in GCC is a low priority for GCC developers. Also, GCC does not integrate smoothly into Apple's IDE. Finally, GCC is licensed under the GNU General Public License (GPL) version 3, which requires developers who distribute extensions for, or modified versions of, GCC to make their source code available, whereas LLVM has a BSD-like license which does not require users to release their source code changes when publishing compiled binaries of those changes.Apple chose to develop a new compiler front end from scratch, supporting C, Objective-C and C++. This clang project was open-sourced in July 2007.Clang is intended to work atop LLVM. The combination of Clang and LLVM provides most of the toolchain, to allow replacing the full GCC stack. Because it is built with a library-based design, like the rest of LLVM, Clang is easy to embed into other applications. This is one reason why most OpenCL implementations are built with Clang and LLVM.[citation needed]One of Clang's main goals is to provide a library-based architecture, to allow the compiler to be more tightly tied to tools that interact with source code, such as an integrated development environment (IDE) graphical user interface (GUI). In contrast, GCC is designed to work in a classic compile-link-debug cycle, and integrating it with other tools is not always easy. For instance, GCC uses a step called fold that is key to the overall compile process, which has the side effect of translating the code tree into a form that looks unlike the original source code. If an error is found during or after the fold step, it can be difficult to translate that back into one location in the original source. Also, vendors using the GCC stack within IDEs use separate tools to index the code, to provide features like syntax highlighting and autocomplete.Clang is designed to retain more information during the compiling process than GCC, and to preserve the overall form of the original code. The goal of this is to make it easier to map errors back into the original source. The error reports offered by Clang are also aimed to be more detailed and specific, as well as machine-readable, so IDEs can index the output of the compiler during compiling. Modular design of the compiler can offer source code indexing, syntax checking, and other features normally associated with rapid application development systems. The parse tree is also more suitable for supporting automated code refactoring, as it directly represents the original source code.Clang is a compiler for only C-like languages, including C, C++, Objective-C, Objective-C++, OpenCL, and CUDA. For other languages, like Ada, LLVM remains dependent on GCC or another compiler frontend. In many cases, Clang can be used or swapped out for GCC as needed, with no other effects on the toolchain as a whole.[citation needed] It supports most of the commonly used GCC options. An unofficial sub-project Flang by Nvidia added Fortran support.Clang is designed to be highly compatible with GCC. Clang's command-line interface is similar to and shares many flags and options with GCC. Clang implements many GNU language extensions and enables them by default. Clang implements many GCC compiler intrinsics purely for compatibility. For example, even though Clang implements atomic intrinsics which correspond exactly with C11 atomics, it also implements GCC's __sync_* intrinsics for compatibility with GCC and libstdc++. Clang also maintains ABI compatibility with GCC-generated object code. In practice Clang can often be used as a drop-in replacement for GCC.[citation needed]Clang's developers aim to reduce memory footprint and increase compilation speed compared to competing compilers, such as GCC. In October 2007, they report that Clang compiled the Carbon libraries more than twice as fast as GCC, while using about one-sixth GCC's memory and disk space. However, as of 2011 this was not a typical result. As of mid-2014, Clang won more than a third of the benchmarks, with GCC winning most. As of 2014, performance of Clang-compiled programs lagged behind performance of the GCC-compiled program, sometimes by large factors (up to 5.5x),, replicating earlier reports of slower performance.More recent comparisons indicate that both compilers have evolved to increase their performance. As of GCC 4.8.1 versus clang 3.3, on a large harness of test files, clang had improved significantly, outperforming GCC by ~ 25%. Test results are code-specific, and optimized C source code can reverse such differences. The two compilers now seem broadly comparable.This table presents only significant steps and releases in Clang history."
"19"	"The LLDB Debugger (LLDB) is a software debugger. It is built as a set of reusable components which extensively use existing libraries from the larger LLVM Project, such as the Clang expression parser and LLVM disassembler.All of the code in the LLDB project is free and open-source software subject to the terms of the University of Illinois/NCSA Open Source License, a permissive free software licence, as is the case with other parts of the LLVM project.Although LLDB is in early development, it is mature enough to support basic debugging of programs written in C, Objective-C, C++ and Swift.LLDB is known to work on macOS, Linux, FreeBSD, and Windows and supports i386, x86-64 and ARM instruction sets. It is used as a default debugger for Xcode 5 and later versions."
"20"	"In computer science, garbage collection (GC) is a form of automatic memory management. The garbage collector, or just collector, attempts to reclaim garbage, or memory occupied by objects that are no longer in use by the program. Garbage collection was invented by John McCarthy around 1959 to simplify manual memory management in Lisp.Garbage collection is often portrayed as the opposite of manual memory management, which requires the programmer to specify which objects to deallocate and return to the memory system. However, many systems use a combination of approaches, including other techniques such as stack allocation and region inference. Like other memory management techniques, garbage collection may take a significant proportion of total processing time in a program and, as a result, can have significant influence on performance. With good implementations, enough memory, and depending on application, garbage collection can be faster than manual memory management, while the opposite can also be true and has often been the case in the past with sub-optimal GC algorithms.Resources other than memory, such as network sockets, database handles, user interaction windows, and file and device descriptors, are not typically handled by garbage collection. Methods used to manage such resources, particularly destructors, may suffice to manage memory as well, leaving no need for GC. Some GC systems allow such other resources to be associated with a region of memory that, when collected, causes the other resource to be reclaimed; this is called finalization. Finalization may introduce complications limiting its usability, such as intolerable latency between disuse and reclaim of especially limited resources, or a lack of control over which thread performs the work of reclaiming.The basic principles of garbage collection are to find data objects in a program that cannot be accessed in the future, and to reclaim the resources used by those objects.Many programming languages require garbage collection, either as part of the language specification (for example, Java, C#, D,Go and most scripting languages) or effectively for practical implementation (for example, formal languages like lambda calculus); these are said to be garbage collected languages. Other languages were designed for use with manual memory management, but have garbage-collected implementations available (for example, C and C++). Some languages, like Ada, Modula-3, and C++/CLI, allow both garbage collection and manual memory management to co-exist in the same application by using separate heaps for collected and manually managed objects; others, like D, are garbage-collected but allow the user to manually delete objects and also entirely disable garbage collection when speed is required.While integrating garbage collection into the language's compiler and runtime system enables a much wider choice of methods,[citation needed]post-hoc GC systems exist, such as Automatic Reference Counting (ARC), including some that do not require recompilation. (Post-hoc GC is sometimes distinguished as litter collection.) The garbage collector will almost always be closely integrated with the memory allocator.Garbage collection frees the programmer from manually dealing with memory deallocation. As a result, certain categories of bugs are eliminated or substantially reduced:Some of the bugs addressed by garbage collection have security implications.Typically, garbage collection has certain disadvantages, including consuming additional resources, performance impacts, possible stalls in program execution, and incompatibility with manual resource management.Garbage collection consumes computing resources in deciding which memory to free, even though the programmer may have already known this information. The penalty for the convenience of not annotating object lifetime manually in the source code is overhead, which can lead to decreased or uneven performance. A peer-reviewed paper came to the conclusion that GC needs five times the memory to compensate for this overhead and to perform as fast as explicit memory management. Interaction with memory hierarchy effects can make this overhead intolerable in circumstances that are hard to predict or to detect in routine testing. The impact on performance was also given by Apple as a reason for not adopting garbage collection in iOS despite being the most desired feature.The moment when the garbage is actually collected can be unpredictable, resulting in stalls (pauses to shift/free memory) scattered throughout a session. Unpredictable stalls can be unacceptable in real-time environments, in transaction processing, or in interactive programs. Incremental, concurrent, and real-time garbage collectors address these problems, with varying trade-offs.The modern GC implementations try to minimize blocking stop-the-world stalls by doing as much work as possible on the background (i.e. on a separate thread), for example marking unreachable garbage instances while the application process continues to run. In spite of these advancements, for example in the .NET CLR paradigm it is still very difficult to maintain large heaps (millions of objects) with resident objects that get promoted to older generations without incurring noticeable delays (sometimes a few seconds).Non-deterministic GC is incompatible with resource acquisition is initialization (RAII) based management of non-GCed resources[citation needed]. As a result, the need for explicit manual resource management (release/close) for non-GCed resources becomes transitive to composition. That is: in a non-deterministic GC system, if a resource or a resource-like object requires manual resource management (release/close), and this object is used as part of another object, then the composed object will also become a resource-like object that itself requires manual resource management (release/close).Tracing garbage collection is the most common type of garbage collection, so much so that garbage collection often refers to tracing garbage collection, rather than other methods such as reference counting. The overall strategy consists of determining which objects should be garbage collected by tracing which objects are reachable by a chain of references from certain root objects, and considering the rest as garbage and collecting them. However, there are a large number of algorithms used in implementation, with widely varying complexity and performance characteristics.Reference counting garbage collection is where each object has a count of the number of references to it. Garbage is identified by having a reference count of zero. An object's reference count is incremented when a reference to it is created, and decremented when a reference is destroyed. When the count reaches zero, the object's memory is reclaimed. As with manual memory management, and unlike tracing garbage collection, reference counting guarantees that objects are destroyed as soon as their last reference is destroyed, and usually only accesses memory which is either in CPU caches, in objects to be freed, or directly pointed by those, and thus tends to not have significant negative side effects on CPU cache and virtual memory operation.There are a number of disadvantages to reference counting; this can generally be solved or mitigated by more sophisticated algorithms:Escape analysis can be used to convert heap allocations to stack allocations, thus reducing the amount of work needed to be done by the garbage collector. This is done using a compile-time analysis to determine whether an object allocated within a function is not accessible outside of it (i.e. escape) to other functions or threads. In such a case the object may be allocated directly on the thread stack and released when the function returns, reducing its potential garbage collection overhead.Generally speaking, higher-level programming languages are more likely to have garbage collection as a standard feature. In some languages that do not have built in garbage collection, it can be added through a library, as with the Boehm garbage collector for C and C++.Most functional programming languages, such as ML, Haskell, and APL, have garbage collection built in. Lisp is especially notable as both the first functional programming language and the first language to introduce garbage collection.Other dynamic languages, such as Ruby and Julia (but not Perl 5 or PHP before version 5.3, which both use reference counting), JavaScript and ECMAScript also tend to use GC. Object-oriented programming languages such as Smalltalk and Java usually provide integrated garbage collection. Notable exceptions are C++ and Delphi which have destructors.Historically, languages intended for beginners, such as BASIC and Logo, have often used garbage collection for heap-allocated variable-length data types, such as strings and lists, so as not to burden programmers with manual memory management. On early microcomputers, with their limited memory and slow processors, BASIC garbage collection could often cause apparently random, inexplicable pauses in the midst of program operation.Some BASIC interpreters, such as Applesoft BASIC on the Apple II family, repeatedly scanned the string descriptors for the string having the highest address in order to compact it toward high memory, resulting in O(n2) performance, which could introduce minutes-long pauses in the execution of string-intensive programs. A replacement garbage collector for Applesoft BASIC published in Call-A.P.P.L.E. (January 1981, pages 40–45, Randy Wigginton) identified a group of strings in every pass over the heap, which cut collection time dramatically. BASIC.System, released with ProDOS in 1983, provided a windowing garbage collector for BASIC that reduced most collections to a fraction of a second.While the Objective-C traditionally had no garbage collection, with the release of OS X 10.5 in 2007 Apple introduced garbage collection for Objective-C 2.0, using an in-house developed runtime collector. However, with the 2012 release of OS X 10.8, garbage collection was deprecated in favor of LLVM's automatic reference counter (ARC) that was introduced with OS X 10.7. Furthermore, since May 2015 Apple even forbids the usage of garbage collection for new OS X applications in the App Store. For iOS, garbage collection has never been introduced due to problems in application responsivity and performance; instead, iOS uses ARC.Garbage collection is rarely used on embedded or real-time systems because of the perceived need for very tight control over the use of limited resources. However, garbage collectors compatible with such limited environments have been developed. The Microsoft .NET Micro Framework and Java Platform, Micro Edition are embedded software platforms that, like their larger cousins, include garbage collection.Compile-time garbage collection is a form of static analysis allowing memory to be reused and reclaimed based on invariants known during compilation. This form of garbage collection has been studied in the Mercury programming language, and it saw greater usage with the introduction of LLVM's automatic reference counter (ARC) into Apple's ecosystem (iOS and OS X) in 2011.Incremental, concurrent, and real-time garbage collectors have been developed, such as  Baker's algorithm or Lieberman's algorithm.In Baker's algorithm, the allocation is done in either half of a single region of memory. When it becomes half full, a garbage collection is performed which moves the live objects into the other half and the remaining objects are implicitly deallocated. The running program (the 'mutator') has to check that any object it references is in the correct half, and if not move it across, while a background task is finding all of the objects.Generational garbage collection schemes are based on the empirical observation that most objects die young. In generational garbage collection two or more allocation regions (generations) are kept, which are kept separate based on object's age. New objects are created in the young generation that is regularly collected, and when a generation is full, the objects that are still referenced from older regions are copied into the next oldest generation. Occasionally a full scan is performed.Some high-level language computer architectures include hardware support for real-time garbage collection.Most implementations of real-time garbage collectors use tracing. Such real-time garbage collectors meet hard real-time constraints when used with a real-time operating system."
"21"	"In computer programming, a weak reference is a reference that does not protect the referenced object from collection by a garbage collector, unlike a strong reference. An object referenced only by weak references – meaning every chain of references that reaches the object includes at least one weak reference as a link – is considered weakly reachable, and can be treated as unreachable and so may be collected at any time. Some garbage-collected languages feature or support various levels of weak references, such as C#, Java, Lisp, OCaml, Perl, and Python.Weak references have a number of common use cases. When using reference counting garbage collection, weak references can break reference cycles, by using a weak reference for a link in the cycle. When one has an associative array (mapping, hash map) whose keys are (references to) objects, for example to hold auxiliary data about objects, using weak references for the keys avoids keeping the objects alive just because of their use as a key. When one has an object where other objects are registered, such as in the observer pattern (particularly in event handling), if a strong reference is kept, objects must be explicitly unregistered, otherwise a memory leak occurs (the lapsed listener problem), while a weak reference removes the need to unregister. When holding cached data that can be recreated if necessary, weak references allow the cache to be reclaimed, effectively producing discardable memory. This last case (a cache) is distinct from others, as it is preferable that the objects only be garbage collected if necessary, and there is thus a need for finer distinctions within weak references, here a stronger form of a weak reference. In many cases weak references do not need to be directly used, instead simply using a weak array or other container whose keys or values are weak references.Garbage collection is used to clean up unused objects and so reduce the potential for memory leaks and data corruption. There are two main types of garbage collection: tracing and reference counting. Reference counting schemes record the number of references to a given object and collect the object when the reference count becomes zero. Reference-counting cannot collect cyclic (or circular) references because only one object may be collected at a time. Groups of mutually referencing objects which are not directly referenced by other objects and are unreachable can thus become permanently resident; if an application continually generates such unreachable groups of unreachable objects this will have the effect of a memory leak. Weak references (references which are not counted in reference counting) may be used to solve the problem of circular references if the reference cycles are avoided by using weak references for some of the references within the group.A very common case of such strong vs. weak reference distinctions is in tree structures, such as the Document Object Model (DOM), where parent-to-child references are strong, but child-to-parent references are weak. For example, Apple's Cocoa framework recommends this approach. Indeed, even when the object graph is not a tree, a tree structure can often be imposed by the notion of object ownership, where ownership relationships are strong and form a tree, and non-ownership relationships are weak and not needed to form the tree – this approach is common in C++ (pre-C++11), using raw pointers as weak references. This approach, however, has the downside of not allowing the ability to detect when a parent branch has been removed and deleted. Since the C++11 standard, a solution was added by using shared_ptr and weak_ptr, probably inherited from the Boost framework.Weak references are also used to minimize the number of unnecessary objects in memory by allowing the program to indicate which objects are of minor importance by only weakly referencing them.Some languages have multiple levels of weak reference strength. For example, Java has, in order of decreasing strength, soft, weak, and phantom references, defined in the package java.lang.ref. Each reference type has an associated notion of reachability. The garbage collector (GC) uses an object's type of reachability to determine when to free the object. It is safe for the GC to free an object that is softly reachable, but the GC may decide not to do so if it believes the JVM can spare the memory (e.g. the JVM has lots of unused heap space). The GC will free a weakly reachable object as soon as the GC notices the object. Unlike the other reference types, a phantom reference cannot be followed. On the other hand, phantom references provide a mechanism to notify the program when an object has been freed (notification is implemented using ReferenceQueues).In C#, weak references are distinguished by whether they track object resurrection or not. This distinction does not occur for strong references, as objects are not finalized if they have any strong references to them. By default, in C# weak reference do not track resurrection, meaning a weak reference is not updated if an object is resurrected; these are called short weak references, and weak references that track resurrection are called long weak references.Some non-garbage-collected languages, such as C++, provide weak/strong reference functionality as part of supporting garbage collection libraries. The Boost C++ library provides strong and weak references.  It is a mistake to use regular C++ pointers as the weak counterparts of smart pointers because such usage removes the ability to detect when the strong reference count has gone to 0 and the object has been deleted.  Worse yet, it doesn't allow for detection of whether another strong reference is already tracking a given plain pointer.  This introduces the possibility of having two (or more) smart pointers tracking the same plain pointer (which causes corruption as soon as one of these smart pointers' reference count reaches 0 and the object gets deleted).Weak references can be useful when keeping a list of the current variables being referenced in the application. This list must have weak links to the objects. Otherwise, once objects are added to the list, they will be referenced by it and will persist for the duration of the program.Java 1.2 in 1998 introduced two kinds of weak references, one known as a “soft reference” (intended to be used for maintaining GC-managed in-memory caches, but which doesn’t work very well in practice) and the other simply as a “weak reference”.  It also added a related experimental mechanism dubbed “phantom references” as an alternative to the dangerous and inefficient finalize() mechanism.If a weak reference is created, and then elsewhere in the code get() is used to get the actual object, the weak reference isn't strong enough to prevent garbage collection, so it may be (if there are no strong references to the object) that get() suddenly starts returning null.Another use of weak references is in writing a cache. Using, for example, a weak hash map, one can store in the cache the various referred objects via a weak reference. When the garbage collector runs — when for example the application's memory usage gets sufficiently high — those cached objects which are no longer directly referenced by other objects are removed from the cache.In Objective-C 2.0, not only garbage collection, but also automatic reference counting will be affected by weak references. All variables and properties in the following example are weak.The difference between weak (__weak) and unsafe_unretained (__unsafe_unretained) is that when the object the variable pointed to is being deallocated, whether the value of the variable is going to be changed or not. weak ones will be updated to nil and the unsafe_unretained one will be left unchanged, as a dangling pointer. The weak references is added to Objective-C since Mac OS X 10.7 Lion and iOS 5, together with Xcode 4.1 (4.2 for iOS), and only when using ARC. Older versions of Mac OS X, iOS, and GNUstep support only unsafe_unretained references as weak ones."
"22"	"Portable Distributed Objects (PDO) is an application programming interface (API) for creating object-oriented code that can be executed remotely on a network of computers. It was created by NeXT Computer, Inc. using their OpenStep system, whose use of Objective-C made the package very easy to write. It was characterized by its very light weight and high speed in comparison to similar systems such as CORBA.Versions of PDO were available for Solaris, HP-UX and all versions of the OPENSTEP system. A version that worked with Microsoft OLE was also available called D'OLE, allowing distributed code written using PDO on any platform to be presented on Microsoft systems as if they were local OLE objects.PDO was one of a number of distributed object systems created in the early 1990s, a design model where front end applications on GUI-based microcomputers would call code running on mainframe and minicomputers for their processing and data storage. Microsoft was evolving OLE into the Component Object Model (COM) and a similar distributed version called DCOM,[citation needed]IBM had their System Object Model (SOM/DSOM), Sun Microsystems was promoting their Distributed Objects Everywhere, and there were a host of smaller players as well. With the exception of the limited functionality in COM,[citation needed] most of these systems were extremely heavyweight, tended to be very large and slow, and often were very difficult to use.PDO, on the other hand, relied on a small number of features in the Objective-C runtime to handle both portability as well as distribution. The key feature was the language's support for a second chance method in all classes; if a method call on an object failed because the object didn't support it (normally not allowed in most languages due to strong typing), the runtime would then bundle the message into a compact format and pass it back into the object's forwardInvocation method.The normal behavior for forwardInvocation was to return an error, including details taken from the message (the invocation).[clarification needed] PDO instead supplied a number of new objects with forwardInvocation methods that passed the invocation object to another machine on the network, with various versions to support different networks and platforms. Calling methods on remote objects was almost invisible; after some network setup (a few lines typically) PDO objects were instantiated locally and called the same way as any other object on the system. The PDO object then forwarded the invocation to the remote computer for processing and unbundled the results when they were returned.In comparison with CORBA, PDO programs were typically 1/10 or less in size; it was common for NeXT staffers to write into magazines showing how to re-implement a multi-page CORBA article in perhaps 15 lines of code. From a programming standpoint, there was nearly nothing as easy to use as PDO.However, PDO was also reliant entirely on Objective-C to function. This was a price most were unwilling to pay, as at the time C++ was more widely used and the effort to shift codebases to an entirely new language and paradigm was considered too onerous.[citation needed] PDO never saw much use, and NeXT's emphasis shifted to its new WebObjects framework in 1995.PDO continues to be used by Mac OS X programmers as a method for interprocess and interapplication communication, and for communication between networked applications that only need compatibility with other Mac OS X applications.In addition to the OS X platform, there is GNUstep, which has its own implementation of Distributed Objects."
"23"	"PyObjC is a bidirectional bridge between the Python and Objective-C programming languages, allowing programmers to use and extend existing Objective-C libraries, such as Apple's Cocoa framework, using Python.PyObjC is used to develop macOS applications in pure Python.There is also limited support for GNUstep, an open source, cross-platform implementation of Cocoa.The most important usage of PyObjC is enabling programmers to create GUI applications using Cocoa libraries in pure Python.  Moreover, as an effect of Objective-C's close relationship with the C programming language (it is a pure superset), developers are also able to incorporate any C-based API by wrapping it with an Objective-C wrapper and then using the wrapped code over the PyObjC bridge. Using Objective-C++, the same can be done with C++ libraries.Cocoa developers may also benefit, as tasks written in Python generally take fewer lines than the Objective-C equivalent. This can be used to their advantage as it enables faster prototyping.PyObjC's origins date back to 1996, when Lele Gaifax built the original module in September of that year. Among the credited contributors were Guido van Rossum, creator of the Python programming language.PyObjC was rewritten in 2002. Notable additions include the ability to directly subclass Objective-C classes from Python and nearly complete support for the Foundation, App Kit and Address Book frameworks.Later the same year, support was added for non-framework Python builds, as well as subsequent support for the Python distribution included with Mac OS X. Along with these changes came project templates for standalone Cocoa applications for use with Project Builder, the predecessor to the current Apple platform IDE, Xcode.Apple incorporated PyObjC into Mac OS X in 2007, with the release of Mac OS X 10.5 Leopard.In Objective-C, objects communicate with each other by sending messages, which is analogous to method calls in other object-oriented languages. When an object receives a message, it looks up the message's name, or selector, and matches it up with a method designated the same selector, which it then invokes.The syntax for these message expressions is inherited from Smalltalk, and appears as an object, called the receiver, placed to the left of the name of the message, or selector, and both are enclosed within a pair of square brackets (the square bracket syntax is not inherited from Smalltalk). Colons within a selector indicate that it accepts one or more arguments, one for each colon. Intended to improve code readability, colons are placed within the selector such that when the required arguments are in place, the expression's intent is unambiguous:This is distinct from the syntax used in Python, and in many other languages, where an equivalent expression would read:Translating Objective-C selectors to Python method names is accomplished by replacing each colon with a single underscore and listing the arguments within a pair of parentheses at the end, as demonstrated above.Objective-C classes are subclassed in the same manner as a normal Python class:"
"24"	"The term target–action design paradigm refers to a kind of software architecture, where a computer program is divided  into objects which dynamically establish relationships by telling each other which object they should target and what action or message to send to that target when an event occurs. This is especially useful when implementing graphical user interfaces, which are by nature event-driven.The target–action approach to event-driven systems allows far more dynamism when compared to other, more static approaches, such as by subclassing. That is because subclassing is a relatively stiff way to program: a programmer must lay out the internal interconnection logic of a program at design time and this cannot be changed later, unless the program is stopped, reengineered, and rebuilt. On the other hand, target-action based programming can change these completely at run-time, thus allowing the program to create new interrelationships and novel behavior by itself.A prime example of this approach is the OpenStep API, which partly thanks to being based on the dynamic Objective-C language, has much of its graphical user interface implemented by using the target-action paradigm. Consider the following example, written in Objective-C:Now when the button identified by the button variable is pressed, the runtime system will try to send a message named doSomething to the object in which this code has been invoked. It is also very well possible to determine the message to be sent at run-time:Here the message which is to be sent is determined by consulting a text field's string value (the string of text which the user typed into a text field). This string is afterwards converted into a message (using the NSSelectorFromString function) and passed to the button as its action. This is possible because, under Objective-C, methods are represented by a selector, a simple string describing the method to be called. When a message is sent, the selector is sent into the ObjC runtime, matched against a list of available methods, and the method's implementation is called. The implementation of the method is looked up at runtime, not compile time.Because of the extreme dynamism and freedom of behavior given to programs designed with the target-action paradigm, it can happen that the program designer incorrectly implements a part of the interconnection logic and this can lead to sometimes hard to trace bugs. This is due to the lack of compile-time control provided by the compiler which cannot see the interconnections. Thus interconnection consistency control is left entirely to the programmer.The result of an incorrectly connected target-action binding can differ based on how the particular system in which the program is implemented regards this:"
"25"	"NeXT (later NeXT Computer and NeXT Software) was an American computer and software company founded in 1985 by Apple Computer co-founder Steve Jobs. Based in Redwood City, California, the company developed and manufactured a series of computer workstations intended for the higher education and business markets.  NeXT was founded by Jobs after he left Apple, along with several co-workers.  NeXT introduced the first NeXT Computer in 1988, and the smaller NeXTstation in 1990.  The NeXT computers experienced relatively limited sales, with estimates of about 50,000 units shipped in total. Nevertheless, their innovative object-oriented NeXTSTEP operating system and development environment were highly influential.NeXT later released much of the NeXTSTEP system as a programming environment standard called OpenStep. NeXT withdrew from the hardware business in 1993 to concentrate on marketing OPENSTEP for Mach, its own OpenStep implementation, for several OEMs. NeXT also developed WebObjects, one of the first enterprise Web application frameworks. WebObjects never became very popular because of its initial high price of $50,000, but it remains a prominent early example of a Web server based on dynamic page generation rather than on static content.Apple purchased NeXT in 1997 for $429 million (equivalent to $654 million in 2017), and 1.5 million shares of Apple stock. As part of the agreement, Steve Jobs, Chairman and CEO of NeXT Software, returned to Apple, the company he co-founded in 1976. The founder promised to merge software from NeXT with Apple's hardware platforms, eventually resulting in macOS, iOS, watchOS and tvOS. Parts of these operating systems incorporated the OPENSTEP foundation.In 1985, Apple co-founder Steve Jobs led Apple's SuperMicro division, which was responsible for the development of the Macintosh and Lisa personal computers. The Macintosh had been successful on university campuses partly because of the Apple University Consortium, which allowed students and institutions to buy the computers at a discount. The consortium had earned more than $50 million on computers by February 1984.While chairman, Jobs visited university departments and faculty members to sell Macintosh. Jobs met Paul Berg, a Nobel Laureate in chemistry, at a luncheon held in Silicon Valley to honor François Mitterrand, then President of France. Berg was frustrated by the expense of teaching students about recombinant DNA from textbooks instead of in wet laboratories, used for the testing and analysis of chemicals, drugs, and other materials or biological matter. Wet labs were prohibitively expensive for lower-level courses and were too complex to be simulated on personal computers of the time. Berg suggested to Jobs to use his influence at Apple to create a 3M computer workstation for higher education, featuring more than one megabyte of random-access memory (RAM), a megapixel display and megaFLOP performance, hence the name 3M.Jobs was intrigued by Berg's concept of a workstation and contemplated starting a higher education computer company in the fall of 1985, amidst increasing turmoil at Apple. Jobs' division did not release upgraded versions of the Macintosh and most of the Macintosh Office. As a result, sales plummeted, and Apple was forced to write off millions of dollars in unsold inventory. Apple's chief executive officer (CEO) John Sculley ousted Jobs from his day-to-day role at Apple, replacing him with Jean-Louis Gassée in 1985. Later that year, Jobs began a power struggle to regain control of the company. The board of directors sided with Sculley while Jobs took a business visit to Western Europe and the Soviet Union on behalf of Apple.After several months of being sidelined, Jobs resigned from Apple on September 13, 1985. He told the board he was leaving to set up a new computer company, and that he would be taking several Apple employees from the SuperMicro division with him. He also told the board that his new company would not compete with Apple and might even consider licensing its designs back to them to market under the Macintosh brand.Jobs named his new company Next, Inc. A number of former Apple employees followed him to Next, including  Joanna Hoffman, Bud Tribble, George Crow, Rich Page, Susan Barnes, Susan Kare, and Dan'l Lewin. After consulting with major educational buyers from around the country, including a follow-up meeting with Paul Berg, a tentative specification for the workstation was drawn up. It was designed to be powerful enough to run wet lab simulations and cheap enough for college students to use in their dormitory rooms. Before the specifications were finished, however, Apple sued Next for nefarious schemes to take advantage of the cofounders' insider information. Jobs remarked, It is hard to think that a $2 billion company with 4,300-plus people couldn't compete with six people in blue jeans. The suit was eventually dismissed before trial.In 1986, Jobs recruited the famous graphic designer Paul Rand to create a brand identity costing $100,000. Rand created a 20-page brochure detailing the brand, including the precise angle used for the logo (28°) and a new company name spelling, NeXT. The first major outside investment was from Ross Perot, who invested after seeing a segment about NeXT on The Entrepreneurs. In 1987, he invested $20 million in exchange for 16 percent of NeXT's stock and subsequently joined the board of directors in 1988.NeXT changed its business plan in mid-1986. The company decided to develop both computer hardware and software, instead of just a low-end workstation. A team led by Avie Tevanian, who had joined the company after working as one of the Mach kernel engineers at Carnegie Mellon University, was to develop the NeXTSTEP operating system. The hardware division, led by Rich Page — one of the cofounders who had previously led the Apple Lisa team — designed and developed the hardware. NeXT's first factory was completed in Fremont, California in 1987. It was capable of producing 150,000 machines per year. NeXT's first workstation was officially named the NeXT Computer, although it was widely termed the cube because of its distinctive case, a 1 ft magnesium cube, designed by Apple IIc case designer Frogdesign in accordance with an edict from Jobs.The original design team had anticipated releasing the computer for US$3,000 in spring of 1987 to be ready for sale by summer of that year. The NeXT Computer received standing ovations when revealed at a lavish, invitation-only gala event, NeXT Introduction — the Introduction to the NeXT Generation of Computers for Education at the Louise M. Davies Symphony Hall, San Francisco, California on Wednesday October 12, 1988. The following day, selected educators and software developers were invited (for $100 registration fee) to attend the first public technical overview of the NeXT computer at an event called The NeXT Day held at the San Francisco Hilton. This event gave developers interested in developing NeXT software an insight into the software architecture, object-oriented programming and developing for the NeXT Computer. The luncheon speaker was Steve Jobs.The first machines were tested in 1989, after which NeXT started selling limited numbers to universities with a beta version of the NeXTSTEP operating system installed. Initially the NeXT Computer was targeted at U.S. higher education establishments only, with a base price of $6,500. The machine was widely reviewed in magazines, generally concentrating on the hardware. When asked if he was upset that the computer's debut was delayed by several months, Jobs responded, Late? This computer is five years ahead of its time!The NeXT Computer was based on the new 25 MHz Motorola 68030 central processing unit (CPU). The Motorola 88000 RISC chip was originally considered, but was not available in sufficient quantities. It included between 8 and 64 MB of random-access memory (RAM), a 256 MB magneto-optical (MO) drive, a 40 MB (swap-only), 330 MB, or 660 MB hard disk drive, 10BASE2 Ethernet, NuBus and a 17-inch MegaPixel grayscale display measuring 1120 by 832 pixels. In 1989 a typical new PC, Macintosh, or Amiga computer included a few megabytes of RAM, a 640×480 16-color or 320x240 4000-color display, a 10 to 20 megabyte hard drive and few networking capabilities. It also was the first computer to ship with a general-purpose DSP chip (Motorola 56001) on the motherboard. This was used to support sophisticated music and sound processing, including the Music Kit software.The magneto-optical drive manufactured by Canon Inc. was used as the primary mass storage device. These drives were relatively new to the market, and the NeXT was the first computer to use them. They were cheaper than hard drives (blank media especially so: though each had a cost of $150 to Canon, Jobs's typically forthright negotiations saw Canon agree to a retail of only $50 apiece) but slower (with an average seek time of 96 ms). The design made it impossible to move files between computers without a network, since each NeXT Computer had only one MO drive and the disk could not be removed without shutting down the system. Storage options proved challenging for the first NeXT Computers. The magneto-optical media was relatively expensive and had performance and reliability problems despite being faster than a floppy drive. The drive was not sufficient to run as the primary medium running the NeXTSTEP operating system both in terms of speed or capacity.In 1989, NeXT struck a deal for former Compaq reseller Businessland to sell NeXT computers in select markets nationwide. Selling through a retailer was a major change from NeXT's original business model of only selling directly to students and educational institutions. Businessland founder David Norman predicted that sales of the NeXT Computer would surpass sales of Compaq computers after 12 months.In 1989, Canon invested US$100 million in NeXT, giving it a 16.67 percent stake, making NeXT worth almost $600 million. Canon invested in NeXT with the condition that it would be able to use the NeXTSTEP environment with its own workstations, which would mean a greatly expanded market for the software. After NeXT exited the hardware business, Canon produced a line of PCs, called object.station, including models 31, 41, 50 and 52, specifically designed to run NeXTSTEP/Intel. Canon also served as NeXT's distributor in Japan.NeXT computers were first released on the retail market in 1990, for $9,999. NeXT's original investor Ross Perot resigned from the board of directors in June 1991 to dedicate more time to Perot Systems, a Plano, Texas-based systems integrator.NeXT released a second generation of workstations in 1990. The new range included a revised NeXT Computer, renamed the NeXTcube, and the NeXTstation, nicknamed the slab, which used a pizza box case form-factor. Jobs was explicit in ensuring NeXT staff did not use the latter terminology, lest the NeXT machines be compared to competing Sun workstations. The magneto-optical drive was replaced with a 2.88 MB floppy drive to offer users a way to use their floppy disks. However, individual 2.88 MB floppies were expensive and the technology did not supplant the 1.44 MB floppy. Realizing this, NeXT utilized the CD-ROM drive, which eventually became an industry standard for storage. Color graphics were available on the NeXTstation Color and the NeXTdimension graphics processor hardware for the NeXTcube. The new computers were cheaper and faster than their predecessors, with the new Motorola 68040 processor.In 1992, NeXT launched Turbo variants of the NeXTcube and NeXTstation with a 33 MHz 68040 processor and maximum RAM capacity increased to 128 MB. NeXT sold 20,000 computers in 1992 (NeXT counted upgraded motherboards on back order as sales) — a small number compared with their competitors. However, the company reported sales of $140 million for the year, encouraging Canon to invest a further $30 million to keep the company afloat.In total, 50,000 NeXT machines were sold, including thousands to the then super secret National Reconnaissance Office located in Chantilly, Virginia.  NeXT's long-term aim was to migrate to the RISC (Reduced Instruction Set Computing) architecture, a processor design strategy intended to increase performance. The project was known as the NeXT RISC Workstation (NRW). Initially the NRW was to be based on the Motorola 88110 processor, but due to a lack of confidence in Motorola's commitment to the 88000-series architecture, it was later redesigned around dual PowerPC 601s. NeXT produced some motherboards and enclosures, but exited the hardware business before full production.NeXT computers were delivered with Mathematica pre-installed. Several developers used the NeXT platform to write pioneering programs. Tim Berners-Lee used a NeXT Computer in 1990 to create the first Web browser and Web server; accordingly, NeXT was instrumental in the development of the World Wide Web.NeXT was an engineering computer used by professors for the most serious science challenges, and also for developing finished newspaper layouts using News running on Next. George Mason University in the early 1990s had a set of them for publishing, as well as Silicon Graphics for CAD/GL and Mathematica for astrophysics. The games Doom, Doom II: Hell on Earth and Quake were developed by id Software on NeXT machines. Other games based on the Doom engine, such as Heretic and Hexen: Beyond Heretic by Raven Software, as well as Strife by Rogue Entertainment were also developed on NeXT hardware using id's tools.Other commercial programs were released for NeXT computers, including Altsys Virtuoso, a vector drawing program with page-layout features which was ported to Mac OS and Microsoft Windows as Aldus FreeHand v4, and the Lotus Improv spreadsheet program. The systems also came with a number of smaller built-in applications, such as the Merriam-Webster Collegiate Dictionary, Oxford Quotations, the complete works of William Shakespeare, and the Digital Librarian search engine to access them.NeXT started porting the NeXTSTEP operating system to IBM PC compatible computers using the Intel 80486 processor in late 1991. The operating system was ported to Intel's architecture because of a change in NeXT's business strategy, which was then to remove themselves from the hardware business entirely. A demonstration of the port was displayed at the NeXTWorld Expo in January 1992.  By mid-1993 the product was complete and version 3.1, also known as NeXTSTEP 486, was released. Prior to the release of NeXTSTEP, Chrysler planned to buy 3,000 copies in 1992.NeXTSTEP 3.x was later ported to PA-RISC and SPARC-based platforms, for a total of four versions: NeXTSTEP/NeXT (for NeXT's 68k black boxes), NeXTSTEP/Intel, NeXTSTEP/PA-RISC and NeXTSTEP/SPARC. Although these ports were not widely used, NeXTSTEP gained popularity at institutions such as First Chicago NBD, Swiss Bank Corporation, O'Connor and Company, and other organizations owing to its programming model. It was also used by many American federal agencies, such as United States Naval Research Laboratory, the National Security Agency, the Advanced Research Projects Agency, the Central Intelligence Agency and the National Reconnaissance Office. Some IBM PC clone vendors offered somewhat customized hardware solutions that were delivered running NeXTSTEP on Intel, such as the Elonex NextStation and the Canon object.station 41.NeXT withdrew from the hardware business in 1993 and the company was renamed NeXT Software Inc; consequently, 300 of the 540 staff employees were laid off. NeXT negotiated to sell the hardware business, including the Fremont factory, to Canon. Canon later pulled out of the deal. Work on the PowerPC machines was stopped, along with all hardware production. CEO of Sun Microsystems Scott McNealy announced plans to invest $10 million in 1993 and use NeXT software (OpenStep) in future Sun systems. NeXT partnered with Sun to create OpenStep which was NeXTSTEP without the Mach-based kernel.After dropping the hardware business, NeXT returned to selling a toolkit to run on other operating systems, in effect returning to the original business plan. New products based on OpenStep were released, including OpenStep Enterprise, a version for Microsoft's Windows NT. The company also launched WebObjects, a platform for building large-scale dynamic web applications. Many large businesses including Dell, Disney, WorldCom, and the BBC used this WebObjects software for a short time. Today, WebObjects is used almost solely to power Apple's iTunes Store and most of its corporate Web site.Apple Computer announced an intention to acquire NeXT on December 20, 1996. Apple paid $429 million in cash, which went to the initial investors and 1.5 million Apple shares, which went to Steve Jobs, who was deliberately not given cash for his part in the deal. The main purpose of the acquisition was to use NeXTSTEP as a foundation to replace the dated classic Mac OS, instead of BeOS or the in-development Copland. The deal was finalized on February 7, 1997, bringing Jobs back to Apple as a consultant, who was later appointed as interim CEO. In 2000 Jobs took the CEO position as a permanent assignment.Several NeXT executives replaced their Apple counterparts when Steve Jobs restructured the company's board of directors. Over the next five years the NeXTSTEP operating system was ported to the PowerPC architecture. At the same time, an Intel port and OpenStep Enterprise toolkit for Windows were both produced. The operating system was code named Rhapsody, while the toolkit for development on all platforms was called Yellow Box. For backwards compatibility Apple added the Blue Box to Rhapsody, allowing existing Mac applications to be run in a self-contained cooperative multitasking environment.A server version of the new operating system was released as Mac OS X Server 1.0 in 1999, and the first consumer version, Mac OS X 10.0, in 2001. The OpenStep developer toolkit was renamed Cocoa. Rhapsody's Blue Box was renamed Classic Environment and changed to run applications full-screen without requiring a separate window. Apple included an updated version of the original Macintosh toolbox, called Carbon, that gave existing Mac applications access to the environment without the constraints of Blue Box. Some of NeXTSTEP's interface features were used in Mac OS X, including the Dock, the Services menu, the Finder's browser view, and the Cocoa text system.NeXTSTEP's processor-independent capabilities were retained in Mac OS X, leading to both PowerPC and Intel x86 versions (although only PowerPC versions were publicly available before 2006). Apple moved to Intel processors by August 2006.Jobs created a different corporate culture at NeXT in terms of facilities, salaries, and benefits. Jobs had experimented with some structural changes at Apple but at NeXT he abandoned conventional corporate structures, instead making a community with members instead of employees. There were only two different salaries at NeXT until the early 1990s. Team members who joined before 1986 were paid $75,000 while those who joined afterwards were paid $50,000. This caused a few awkward situations where managers were paid less than their employees. Employees were given performance reviews and raises every six months because of the spartan salary plans. To foster openness, all employees had full access to the payrolls, although few employees ever took advantage of the privilege. NeXT's health insurance plan offered benefits to not only married couples but unmarried couples and same-sex couples, although the latter privilege was later withdrawn due to insurance complications. The payroll schedule was also very different from other companies in Silicon Valley at the time: instead of getting paid twice a month at the end of the pay period, employees would get paid once a month in advance.Jobs found office space in Palo Alto, California on 3475 Deer Creek Road, occupying a glass and concrete building which featured a staircase designed by architect I. M. Pei. The first floor used hardwood flooring and large worktables where the workstations would be assembled. To avoid inventory errors, NeXT used the just-in-time (JIT) inventory strategy. The company contracted out for all major components such as mainboards and cases and had the finished components shipped to the first floor for assembly. The second floor was the office space with an open floor plan. The only enclosed rooms were Jobs's office and a few conference rooms.As NeXT expanded, more office space was needed. The company rented an office at 800 and 900 Chesapeake Drive in Redwood City, also designed by Pei. The architectural centerpiece was a floating staircase with no visible supports. The open floor plan was retained, although furnishings became luxurious, with $5,000 chairs, $10,000 sofas and Ansel Adams prints.NeXT's first former campus in Palo Alto was subsequently occupied by SAP AG. Its second former campus in Redwood City was occupied by ApniCure and OncoMed Pharmaceuticals Inc.The first issue of NeXTWORLD magazine was printed in 1991. It was published in San Francisco by Integrated Media and edited by Michael Miley and later Dan Ruby. It was the only mainstream periodical to discuss NeXT computers, the operating system, and NeXT software. Publication was discontinued in 1994 after only four volumes. A NeXTWORLD Expo followed as a developer conference, held in 1991 and 1992 at the San Francisco Civic Center and in 1993 and 1994 at the Moscone Center in San Francisco, with Steve Jobs as the keynote speaker.Despite NeXT's limited commercial success, the company had a wide-ranging impact on the computer industry. Object-oriented programming and graphical user interfaces became more common after the 1988 release of the NeXTcube and NeXTSTEP, when other companies started to emulate NeXT's object-oriented system. Apple started the Taligent project in 1989, with the goal of building a NeXT-like operating system for the Macintosh, with collaboration from Hewlett-Packard and IBM.Microsoft announced the Cairo project in 1991; the Cairo specification included similar object-oriented user interface features for a coming consumer version of Windows NT. Although the project was ultimately abandoned, some elements were integrated into other projects. By 1994, Microsoft and NeXT were collaborating on a Windows NT port of OpenStep; the port, however, was never released.WebObjects failed to achieve wide popularity partly because of the initial high price of US$50,000, but it remains the first and most prominent early example of a web application server that enabled dynamic page generation based on user interactions as opposed to static content. WebObjects is now bundled with macOS Server and Xcode.  "
"26"	"Mac OS X Server 1.0, released on March 16, 1999, is the first operating system released into the retail market by Apple Computer based on NeXT technology. It was the final release of the product code-named Rhapsody, which was an interim combination of the OpenStep system (Mach OS and OpenStep API) and Mac OS 8.Although Mac OS X Server 1.0's graphical look and feel was a variation of the Platinum theme from Mac OS 8, its infrastructure is based on the OPENSTEP (and thus, NeXTSTEP) operating system instead of the classic Mac OS.  The resulting product gave users a preview of the operating system that was to become Mac OS X  (now referred to as macOS). Mac OS X Server was never officially known simply as Mac OS X, and was ultimately rendered obsolete by Mac OS X v10.0 in 2001 and macOS Server.Server 1.0 contains a mix of features from the classic Mac OS, NeXTSTEP and Mac OS X. Like classic Mac OS, it has a single menu bar across the top of the screen, but file management is performed in Workspace Manager from NeXTSTEP instead of the classic Mac OS Finder. The user interface still uses the Display PostScript-based window server from NeXTSTEP, instead of the Quartz-based WindowServer, which would appear a year later in Mac OS X Public Beta. Unlike any version of Classic Mac OS, windows with unsaved content display a black dot in the window close button like NeXTSTEP did. The Dock and the Aqua appearance were not included; these were added later in Mac OS X.Carbon, essentially a subset of classic Mac OS API calls, was also absent. This meant that the only native applications for OS X Server 1.0 were written for the Yellow Box API, which went on to become known as Cocoa. Furthermore, Apple's own FireWire was not supported.Server 1.0 also includes the first version of a NetBoot server, which allows computers to boot from a disk image over a local network. This was particularly useful in a school or other public-machine setting, as it allowed the machines to be booted from a single OS copy stored on Server 1.0.  This made it difficult for users to damage the OS by installing software – as soon as they signed out, the machine would re-boot with a fresh OS from the NetBoot server.To run classic Mac OS applications, Mac OS X Server 1.0 includes the Blue Box, which essentially ran a copy of Mac OS 8.5.1 (this could be updated to Mac OS 8.6 in version 1.2 and later) in a separate process as an emulation layer. Blue Box would eventually be renamed as the Classic Environment in Mac OS X, featuring the latest version of Mac OS 9."
"27"	"The Foundation Kit, or just Foundation for short, is an Objective-C framework in the OpenStep specification.  It provides basic classes such as wrapper classes and data structure classes.  This framework uses the prefix NS (for NeXTSTEP, or NeXT/Sun_Microsystems).This class is the most common base class for Objective-C hierarchies and provides standard methods for working with objects by managing the memory associated with them and querying them.A class used for string manipulation, representing a Unicode string (most typically using UTF-16 as its internal format). NSString is immutable, and thus can only be initialized but not modified. NSMutableString is a modifiable version.NSValue is a wrapper class for C data types, and NSNumber is a wrapper class for C number data types such as int, double, and float.  The data structures in Foundation Kit can only hold objects, not primitive types, so wrappers such as NSValue and NSNumber are used in those data structures.A dynamic array of objects, supporting constant-time indexing. NSArray is an immutable version that can only be initialized with objects but not modified. NSMutableArray may be modified by adding and removing objects.An associative data container of key-value pairs with unique keys. Searching and element addition and removal (in the case of NSMutableDictionary) is faster-than-linear. However, the order of the elements within the container is not guaranteed.An associative container of unique keys, similar to NSDictionary, with the difference that members do not contain a data object.A wrapper for raw byte data. An object of this type can dynamically allocate and manage its data, or it can refer to data owned by and managed by something else (such as a static numeric array).Classes that store times and dates and represent calendrical information. They offer methods for calculating date and time differences. Together with NSLocale, they provide methods for displaying dates and times in many formats, and for adjusting times and dates based on location in the world.The Foundation Kit is part of the Cocoa API.  Beginning as the successor to OPENSTEP/Mach, this framework has deviated from OpenStep compliance, and is in some places incompatible.The Foundation Kit is in the Cocoa Touch API.  This framework is based on the macOS Foundation, not OpenStep.[citation needed]The Foundation Kit is implemented in GNUstep's Base Package.  This implementation is mostly comparable (4 classes are missing) and aims to be comparable with both the OpenStep API and later macOS additions.The Foundation Kit is implemented in Cocotron, an open-source implementation of Cocoa.PureFoundation is an open-source implementation of Foundation that implements Foundation by wrapping Core Foundation, just like in Cocoa, rather than create a separate Foundation from scratch like GNUstep and Cocotron.SwiftFoundation is Apple's open-source Swift implementation of the Foundation API for platforms where there is no Objective-C runtime."
"28"	"Window Maker is a free and open source window manager for the X Window System, allowing graphical applications to be run on Unix-like operating-systems. It is designed to emulate NeXTSTEP's GUI as an OpenStep-compatible environment. Window Maker is part of the GNU Project.Window Maker has a reputation for being fast, efficient and highly stable.[citation needed] Window Maker has been characterized as reproducing the elegant look and feel of the NeXTstep GUI and is noted as easy to configure and easy to use. A graphical tool called Wprefs is included and can be used to configure most aspects of the UI. The interface tends towards a minimalist, high performance environment directly supporting XPM, PNG, JPEG, TIFF, GIF and PPM icons with an alpha-channel and a right-click, sliding-scrolling application menu system which can throw off pinnable menus, along with window-icon miniaturization and other animations on multiple desktops. Menus and preferences can be changed without restarting. As with most window managers it supports themes and many are available. Owing to its NeXT inspiration, Window Maker has a dock like MacOS, but Window Maker's look and feel hews mostly to that of its NeXT forebear.Window Maker has window hints which allow seamless integration with the GNUstep, GNOME, KDE, Motif and OpenLook environments. Significantly it has almost complete ICCCM compliance and internationalization support for at least 11 locales. Window Maker uses the lightweight WINGs widget set which was built specifically for Window Maker as a way to skirt what its developers said would have been the overkill (or bloat) of using GNUstep. WINGs is common to other applications including a login display manager called WINGs Display Manager (WDM) and many dockapps. Window Maker dock and clip applets are compatible with those from AfterStep's wharf.Window Maker was written from scratch primarily by Brazilian programmer Alfredo Kojima as a window manager for the GNUstep desktop environment and originally meant as an improved take on the AfterStep window manager's design concept. The first release was in 1997. For a time it was included as a standard window manager in several Linux distributions and is also available in the FreeBSD and OpenBSD ports collection. Since the goal of the project has been to closely emulate the design of the defunct NeXTstep and OpenStep GUIs, further development has been light. In late 2007 the widely available, stable release version was at 0.92 from July 2005 with subsequent maintenance updates having been made to some distribution packages and ports.In late June 2008 a post on the project's website said active development would resume, noting, ...we are working very hard to revitalize Window Maker's presence on X Window (and perhaps beyond) desktops... We expect to once again provide the de-facto minimalist yet extremely functional window manager to the world.  On 29 January 2012, Window Maker 0.95.1 was released, making it the first official release in almost seven years. This was followed by a number of releases; As of  October 2017[update] the latest release was 0.95.8, released on 11 March 2017.The program's original name was WindowMaker (camelcased and without the space) but a naming conflict arose with an older product called Windowmaker from Windowmaker Software Ltd, a UK company producing software for companies that manufacture windows and doors. A 1998 agreement between the developers of Window Maker and Windowmaker Software specified that Window Maker (in the X sense) should never be used as a single word.Though adhering closely to the NeXT interface, the default appearance can be confusing to someone expecting a Microsoft Windows-style taskbar and start menu. All applications can be accessed by right-clicking on the desktop background to access the fully configurable main menu. The menu can also be displayed using the keyboard, with F12 for the application menu and F11 for a window menu.Window Maker can be configured by double-clicking the screwdriver icon on the dock. An icon depicting a computer monitor is used to launch a command-window and a paperclip icon is used to cycle between workspaces. Any icon in Window Maker, including application icons, can be easily changed.Icons representing running applications appear at the bottom of the screen (the user can extend application windows to cover these). By default, the dock appears at upper right. Icons can be dragged onto the dock to make them permanent. The edge of an icon can be right-clicked to adjust its settings. A separate, dockable application called wmdrawer features a slide-out drawer which can hold application and file launching icons.While any X application can be docked in Window Maker, the archetypical WM dockable applications are called dockapps. These tend to be clocks and system monitoring applications. There are many clock implementations, including wmcalclock, wmtime, wmclock (a NeXTStep-like calendar clock clone) and wmclockmon. Monitoring applets include wmload, wmavgload, wmmon, wmnet and wmnd. Many other dockapps are available, typically ones intended to interact with other full fledged applications.The WPrefs configuration tool enables tuning of most Window Maker preferences. wmakerconf was developed to provide more configuration options, notably theme customization. Configuration files are typically stored in ~/GNUstep/. The background can be changed from the command line with wmsetbg -s -u [filename.jpg] (wmsetbg stands for window maker set background).FSViewer is a separate, configurable Miller Columns file browser developed for Window Maker in 1998 by George Clernon as a visual and functional analogy to NeXTstep's Workspace Manager. In 2002, it was adapted to later versions of the WINGs libraries and Window Maker by Guido Scholz.aterm is an rxvt based terminal emulator developed for Afterstep mainly for visual appeal, featuring a NeXTstep style scrollbar (which matches Window Maker's look and feel) along with pseudo-transparency.The application menu can be edited graphically with much versatility. The configuration is recorded in ~/GNUstep/Defaults/WMRootMenu as a text file which can be easily read and edited (in versions after 0.94.0 it can also be automatically generated from a list of installed applications using a program called wmgenmenu).Menu items can be set to:Many Linux distributions define their own applications menu for Window Maker. This cannot usually be edited using the configuration tool (which will instead offer to replace it with a generic default menu which can be edited).Amanda the Panda is the mascot of Window Maker. She was designed by Agnieszka Czajkowska."
"29"	" (Learn how and when to remove this template message)Gorm (Graphical Object Relationship Modeller) is a graphical user interface builder application. It is part of the developer tools of GNUstep. Gorm is the equivalent of Interface Builder that was originally found on NeXTSTEP, then OPENSTEP, and finally on Mac OS X.Gorm and Project Center represent the heart of the suite for GNUstep. Gorm follows Interface Builder so closely that using tutorials written for the latter is possible without much hassle and thus brings the power of Interface Builder to the open source world, being part of the GNU project.Gorm allows developers to quickly create graphical applications and to design every little aspect of the application's user interface. The developer can drag and drop all types of objects such as menus, buttons, tables, lists and browsers into the interface. With the mouse, it is possible to resize, move or convert the objects or connect them to functions, as well as to edit nearly every aspect of them using Gorm's powerful inspectors."
"30"	"Interface Builder is a software development application for Apple's Mac OS X operating system. It is part of Xcode (formerly Project Builder), the Apple Developer Connection developer's toolset. Interface Builder allows Cocoa and Carbon developers to create interfaces for applications using a graphical user interface. The resulting interface is stored as a .nib file, short for NeXT Interface Builder, or more recently, as a .xib file.Interface Builder is descended from the NeXTSTEP development software of the same name. A version of Interface Builder is also used in the development of OpenStep software, and a very similar tool called Gorm exists for GNUstep. On March 27, 2008, a specialized iPhone version of Interface Builder allowing interface construction for iPhone applications was released with the iPhone SDK Beta 2. Interface Builder was intentionally developed as a separate application, to allow interaction designers to design interfaces without having to use a code-oriented IDE, but as of Xcode 4, Apple has integrated its functionality directly into Xcode.Interface Builder first made its appearance in 1986 written in Lisp (for the ExperLisp product by ExperTelligence).  It was invented and developed by Jean-Marie Hullot using the object-oriented features in ExperLisp, and deeply integrated with the Macintosh toolbox. Denison Bollay took Jean-Marie Hullot to NeXT later that year to demonstrate it to Steve Jobs.  Jobs immediately recognized its value, and started incorporating it into NeXTSTEP, and by 1988 it was part of NeXTSTEP 0.8. It was the first commercial application that allowed interface objects, such as buttons, menus, and windows, to be placed in an interface using a mouse. One notable early use of Interface Builder was the development of the first WorldWideWeb web browser by Tim Berners-Lee at CERN, made using a NeXT workstation.Interface Builder provides palettes, or collections, of user interface objects to an Objective-C or Swift developer. These user interface objects contain items like text fields, data tables, sliders, and pop-up menus. Interface Builder's palettes are completely extensible, meaning any developer can develop new objects and add palettes to Interface Builder.To build an interface, a developer simply drags interface objects from the palette onto a window or menu. Actions (messages) which the objects can emit are connected to targets in the application's code and outlets (pointers) declared in the application's code are connected to specific objects. In this way all initialization is done before runtime, both improving performance[citation needed] and streamlining the development process. When Interface Builder was a standalone application, interface designers could ship nib files to developers, who would then drop them into their projects.Interface Builder saves an application's interface as a bundle that contains the interface objects and relationships used in the application. These objects are archived (a process also known as serialization or  marshalling in other contexts) into either an XML file or a NeXT-style property list file with a .nib extension. Upon running an application, the proper NIB objects are unarchived, connected into the binary of their owning application, and awakened. Unlike almost all other GUI designer systems which generate code to construct the UI (notable exceptions being Glade, Embarcadero Technologies's Delphi and C++ Builder, which stream UI objects similarly), NIBs are often referred to as freeze dried because they contain the archived objects themselves, ready to run. As of Interface Builder version 3, a new file format (with extension .xib) has been added, which is functionally identical to .nib, except it is stored in a flat file, making it more suitable for storage in revision control systems and processing by tools such as diff."
"31"	"Darwin is an open-source Unix operating system first released by Apple Inc. in 2000. It is composed of code developed by Apple, as well as code derived from NeXTSTEP, BSD, Mach, and other free software projects.Darwin forms the core set of components upon which macOS (previously OS X and Mac OS X), iOS, watchOS, and tvOS are based. It is mostly POSIX-compatible, but has never, by itself, been certified as compatible with any version of POSIX. Starting with Leopard, macOS has been certified as compatible with the Single UNIX Specification version 3 (SUSv3).The heritage of Darwin began with NeXT's NeXTSTEP operating system (later, since version 4.0, known as OPENSTEP), first released in 1989. After Apple bought NeXT in 1997, it announced it would base its next operating system on OPENSTEP. This was developed into Rhapsody in 1997, Mac OS X Server 1.0 in 1999, Mac OS X Public Beta in 2000, and Mac OS X 10.0 in 2001. In 2000, the core operating system components of Mac OS X were released as open-source software under the Apple Public Source License (APSL) as Darwin; the higher-level components, such as the Cocoa and Carbon frameworks, remained closed-source.Up to Darwin 8.0.1, Apple released a binary installer (as an ISO image) after each major Mac OS X release that allowed one to install Darwin on PowerPC and Intel x86 systems as a standalone operating system. Minor updates were released as packages that were installed separately. Darwin is now only available as source code, except for the ARM variant, which has not been released in any form separately from iOS. The older versions of Darwin have still been available from opensource.apple.com in binary form until recently, and a hobbyist developer winocm took the official Darwin source code and ported it to ARM.The kernel of Darwin is XNU, a hybrid kernel which uses OSFMK 7.3 (Open Software Foundation Mach Kernel) from the OSF, various elements of BSD (including the process model, network stack, and virtual file system), and an object-oriented device driver API called I/O Kit. The hybrid kernel design provides the flexibility of a microkernel[citation needed] and the performance of a monolithic kernel.Darwin currently includes support for the 64-bit x86-64 variant of the Intel x86 processors used in Macs and the 64-bit ARM processors used in the iPhone 5S and later, the 6th generation iPod Touch and later, the iPad Air and iPad Pro, and the fourth generation Apple TV, as well as the 32-bit ARM processors used in the iPhone 5C and older, earlier generations of the iPod Touch, the iPad up to the fourth generation, and the second and third generation Apple TV. An open-source port of the XNU kernel exists that supports Darwin on Intel and AMD x86 platforms not officially supported by Apple, although it does not appear to have been updated since 2009. An open-source port of the XNU kernel also exists for ARM platforms.  Older versions supported some or all of 32-bit PowerPC, 64-bit PowerPC, and 32-bit x86.It supports the POSIX API by way of its BSD lineage and a large number of programs written for various other UNIX-like systems can be compiled on Darwin with no changes to the source code.Darwin does not include many of the defining elements of macOS, such as the Carbon and Cocoa APIs or the Quartz Compositor and Aqua user interface, and thus cannot run Mac applications. It does, however, support a number of lesser known features of macOS, such as mDNSResponder, which is the multicast DNS responder and a core component of the Bonjour networking technology, and launchd, an advanced service management framework.In July 2003, Apple released Darwin under version 2.0 of the Apple Public Source License (APSL), which the Free Software Foundation (FSF) classifies as a free software license incompatible with the GNU General Public License. Previous versions were released under an earlier version of the APSL license, which did not meet the FSF definition of free software, although it did meet the requirements of the Open Source Definition.The following is a table of major Darwin releases with their dates of release and their corresponding macOS releases. Note that the corresponding macOS release may have been released on a different date; refer to the macOS pages for those dates.The jump in version numbers from Darwin 1.4.1 to 5.1 with the release of Mac OS X v10.1.1 was designed to tie Darwin to the Mac OS X version and build numbering system, which in turn is inherited from NeXTSTEP. In the build numbering system of macOS, every version has a unique beginning build number, which identifies what whole version of macOS it is part of. Mac OS X v10.0 had build numbers starting with 4, 10.1 had build numbers starting with 5, and so forth (earlier build numbers represented developer releases).The command uname -r in Terminal will show the Darwin version number, and the command uname -v will show the XNU build version string, which includes the Darwin version number.Due to the free software nature of Darwin, there are many projects that aim to modify or enhance the operating system.OpenDarwin was a community-led operating system based on the Darwin system. It was founded in April 2002 by Apple Inc. and Internet Systems Consortium. Its goal was to increase collaboration between Apple developers and the free software community. Apple benefited from the project because improvements to OpenDarwin would be incorporated into Darwin releases; and the free/open source community benefited from being given complete control over its own operating system, which could then be used in free software distributions such as GNU-Darwin.On July 25, 2006, the OpenDarwin team announced that the project was shutting down, as they felt OpenDarwin had become a mere hosting facility for Mac OS X related projects, and that the efforts to create a standalone Darwin operating system had failed. They also state: Availability of sources, interaction with Apple representatives, difficulty building and tracking sources, and a lack of interest from the community have all contributed to this. The last stable release was version 7.2.1, released on July 16, 2004.[citation needed]"
"32"	"Rhapsody was the code name given to Apple Computer's next-generation operating system during the period of its development between Apple's purchase of NeXT in late 1996 and the announcement of Mac OS X (now macOS) in 1998. At first more than an operating system, Rhapsody represented a new strategy for Apple, who intended the operating system to run on x86-based PCs, DEC Alpha workstations, as well as PowerPC-based Macintosh hardware. In addition, the underlying API frameworks would be ported to run natively on Microsoft Windows NT. Eventually the non-Apple platforms were dropped and later versions consisted primarily of the OPENSTEP operating system ported to the Power Macintosh along with a new GUI to make it appear more Mac-like. Several existing classic Mac OS technologies were also ported to Rhapsody, including QuickTime and AppleSearch. Rhapsody could also run Mac OS 8 in a Blue Box emulation layer.Rhapsody was announced at the MacWorld Expo in San Francisco on January 7, 1997 and first demonstrated at the 1997 Worldwide Developers Conference (WWDC). There were two subsequent general Developer Releases for computers with x86 or PowerPC processors. After this there was to be a Premier version somewhat analogous to the Mac OS X Public Beta, followed by the full Unified version in the second quarter of 1998. Apple's development schedule in integrating the features of two very different systems made it difficult to forecast the features of upcoming releases. At the 1998 MacWorld Expo in New York, Steve Jobs announced that Rhapsody would be released as Mac OS X Server 1.0 (which shipped in 1999). No home version of Rhapsody would be released. Its code base was forked into Darwin, the open source underpinnings of macOS.Defining features of the Rhapsody operating system included a heavily modified hybrid OSFMK 7.3 (Open Source Foundation Mach Kernel) from the OSF, a BSD operating system layer (based on 4.4BSD), the object-oriented Yellow Box API framework, the Blue Box compatibility environment for running classic Mac OS applications, and a Java Virtual Machine.The user interface was modeled after Mac OS 8's Platinum appearance. The file management functions served by the Finder in previous Mac OS versions were instead handled by a port of OPENSTEP's Workspace Manager. Additional features inherited from OPENSTEP and not found in the classic Mac OS Finder were included, such as the Shelf and column view. Although the Shelf was dropped in favor of Dock functionality, column view would later make its way to macOS's Finder. Rhapsody's Blue Box environment, available only when running on the PowerPC architecture, was responsible for providing runtime compatibility with existing Mac OS applications. Compared to the more streamlined and integrated Classic compatibility layer that was later featured in Mac OS X, Blue Box's interface presented users with a distinct barrier between emulated legacy software and native Rhapsody applications. All emulated applications and their associated windows were encapsulated within a single Blue Box emulation window instead of being interspersed with the other applications using the native Yellow Box API. This limited cross-environment interoperability and caused various user interface inconsistencies.To avoid the pitfalls of running within the emulation environment and take full advantage of Rhapsody's features, software needed to be rewritten to use the new Yellow Box API. Inherited from OPENSTEP, Yellow Box used an object-oriented model completely unlike the procedural model used by the Classic APIs. The large difference between the two frameworks meant transition of legacy code required significant changes and effort on the part of the developer. The consequent lack of adoption as well as objections by prominent figures in the Macintosh software market, including Adobe Systems and Microsoft, became major factors in Apple's decision to cancel the Rhapsody project in 1998.However, most of Yellow Box and other Rhapsody technologies went on to be used in macOS's Cocoa API. Bowing to developers' wishes, Apple also ported existing Classic Mac OS technologies into the new operating system and implemented the Carbon API to provide Classic Mac OS API compatibility. Widely used Mac OS libraries like QuickTime and AppleScript were ported and made available to developers. Carbon allowed developers to maintain full compatibility and native functionality using their current codebases, while enabling them to take advantage of new features at their discretion.The name Rhapsody followed a pattern of music-related code names that Apple designated for operating system releases during the 1990s. Another next-generation operating system, which was to be the successor to the never-completed Copland operating system, was code-named Gershwin after George Gershwin, composer of Rhapsody in Blue. Copland itself was named after another American composer, Aaron Copland. Other musical code names include Harmony (Mac OS 7.6), Tempo (Mac OS 8), Allegro (Mac OS 8.5), and Sonata (Mac OS 9)."
"33"	"A hybrid kernel is an operating system kernel architecture that attempts to combine aspects and benefits of microkernel and monolithic kernel architectures used in computer operating systems.The traditional kernel categories are monolithic kernels and microkernels (with nanokernels and exokernels seen as more extreme versions of microkernels). The hybrid category is controversial, due to the similarity of hybrid kernels and ordinary monolithic kernels; the term has been dismissed by Linus Torvalds as simple marketing.The idea behind a hybrid kernel is to have a kernel structure similar to that of a microkernel, but to implement that structure in the manner of a monolithic kernel. In contrast to a microkernel, all (or nearly all) operating system services in a hybrid kernel are still in kernel space. So there are none of the reliability benefits of having services in user space, as with a microkernel. However, just as with an ordinary monolithic kernel, there is none of the performance overhead for message passing and context switching between kernel and user mode that normally comes with a microkernel.One prominent example of a hybrid kernel is the Microsoft Windows NT kernel that powers all operating systems in the Windows NT family, up to and including Windows 10 and Windows Server 2016, and powers Windows Phone 8, Windows Phone 8.1, and Xbox One. NT-based Windows is classified as a hybrid kernel (or a macrokernel) rather than a monolithic kernel because the emulation subsystems run in user-mode server processes, rather than in kernel mode as on a monolithic kernel, and further because of the large number of design goals which resemble design goals of Mach (in particular the separation of OS personalities from a general kernel design). Conversely, the reason NT is not a microkernel system is because most of the system components run in the same address space as the kernel, as would be the case with a monolithic design (in a traditional monolithic design, there would not be a microkernel per se, but the kernel would implement broadly similar functionality to NT's microkernel and kernel-mode subsystems).The Windows NT design includes many of the same objectives as Mach, the archetypal microkernel system, one of the most important being its structure as a collection of modules that communicate via well-known interfaces, with a small microkernel limited to core functions such as first-level interrupt handling, thread scheduling and synchronization primitives. This allows for the possibility of using either direct procedure calls or interprocess communication (IPC) to communicate between modules, and hence for the potential location of modules in different address spaces (for example in either kernel space or server processes). Other design goals shared with Mach included support for diverse architectures, a kernel with abstractions general enough to allow multiple operating system personalities to be implemented on top of it and an object-oriented organisation.The reason NT is not a microkernel system is that nearly all of the subsystems providing system services, including the entire Executive, run in kernel mode, in the same address space as the microkernel itself, rather than in user-mode server processes, as would be the case with a microkernel design. This is an attribute NT shares with early versions of Mach, as well as all commercial systems based on Mach, and stems from the superior performance offered by using direct procedure calls in a single memory space, rather than IPC, for communication amongst subsystems. The user-mode subsystems on NT include one or more emulation subsystems, each of which provides an operating system personality to applications, the Session Manager Subsystem (smss.exe), which starts the emulation subsystems during system startup and the Local Security Authority Subsystem Service (lsass.exe), which enforces security on the system. The subsystems are not written to a particular OS personality, but rather to the native NT API (or Native API).The primary operating system personality on Windows is the Windows API, which is always present. The emulation subsystem which implements the Windows personality is called the Client/Server Runtime Subsystem (csrss.exe). On versions of NT prior to 4.0, this subsystem process also contained the window manager, graphics device interface and graphics device drivers. For performance reasons, however, in version 4.0 and later, these modules (which are often implemented in user mode even on monolithic systems, especially those designed without internal graphics support) run as a kernel-mode subsystem.As of 2007, one other operating system personality, UNIX, is offered as an optionally installed system component on certain versions of Windows Vista and Windows Server 2003 R2. The associated subsystem process is the Subsystem for UNIX-Based Applications (psxss.exe), which was formerly part of a Windows add-on called Windows Services for UNIX. An OS/2 subsystem (os2ss.exe) was supported in older versions of Windows NT, as was a very limited POSIX subsystem (psxss.exe). The POSIX subsystem was supplanted by the UNIX subsystem, hence the identical executable name.In August 2016, Microsoft unveiled the latest Windows subsystem called the Windows Subsystem for Linux. This subsystem, available only on 64-bit Windows 10 version 1607 (Anniversary Update, codenamed Redstone), runs a slimmed down version of Ubuntu 14.04 LTS natively within the operating system without emulation to achieve this. It was marketed as Bash on Windows, because it ran bash, a popular command line interface used on many Linux distributions and macOS, and allows binaries compiled for amd64 to run unmodified within the subsystem. This was intended so that developers could run their tools on Windows without having to emulate them, and thus requires developer mode to be enabled in Windows Settings. It is designed only to run command-line applications, although a reddit user has discovered a way to run GUI applications or even an entire desktop environment with it. Certain applications that strictly rely on the Linux kernel itself will not be able to run because it does not include the Linux kernel.Applications that run on NT are written to one of the OS personalities (usually the Windows API), and not to the native NT API for which documentation is not publicly available (with the exception of routines used in device driver development). An OS personality is implemented via a set of user-mode DLLs (see Dynamic-link library), which are mapped into application processes' address spaces as required, together with an emulation subsystem server process (as described previously). Applications access system services by calling into the OS personality DLLs mapped into their address spaces, which in turn call into the NT run-time library (ntdll.dll), also mapped into the process address space. The NT run-time library services these requests by trapping into kernel mode to either call kernel-mode Executive routines or make Local Procedure Calls (LPCs) to the appropriate user-mode subsystem server processes, which in turn use the NT API to communicate with application processes, the kernel-mode subsystems and each other.XNU is the kernel that Apple Inc. acquired and developed for use in the macOS, iOS, watchOS, and tvOS operating systems and released as free and open source software as part of the Darwin operating system. XNU is an acronym for X is Not Unix.Originally developed by NeXT for the NeXTSTEP operating system, XNU was a hybrid kernel combining version 2.5 of the Mach kernel developed at Carnegie Mellon University with components from 4.3BSD and an object-oriented API for writing drivers called Driver Kit.After Apple acquired NeXT, the Mach component was upgraded to OSFMK 7.3, which is a microkernel. Apple uses a heavily modified OSFMK 7.3 functioning as a hybrid kernel with parts of FreeBSD included. (OSFMK 7.3 includes applicable code from the University of Utah Mach 4 kernel and applicable code from the many Mach 3.0 variants that sprouted off from the original Carnegie Mellon University Mach 3.0 kernel.) The BSD components were upgraded with code from the FreeBSD project and the Driver Kit was replaced with a C++ API for writing drivers called I/O Kit.Like some other modern kernels, XNU is a hybrid, containing features of both monolithic and microkernels, attempting to make the best use of both technologies, such as the message passing capability of microkernels enabling greater modularity[citation needed] and larger portions of the OS to benefit from protected memory,[citation needed] as well as retaining the speed of monolithic kernels for certain critical tasks.XNU runs on ARM as part of iOS,IA-32, and x86-64 based processors."
"34"	" (Learn how and when to remove this template message)In programming languages, a type system is a set of rules that assigns a property called type to the various constructs of a computer program, such as variables, expressions, functions or modules.  These types formalize and enforce the otherwise implicit categories the programmer uses for data structures and components (e.g. string, array of float, function returning boolean). The main purpose of a type system is to reduce possibilities for bugs in computer programs by defining interfaces between different parts of a computer program, and then checking that the parts have been connected in a consistent way. This checking can happen statically (at compile time), dynamically (at run time), or as a combination of static and dynamic checking. Type systems have other purposes as well, such as expressing business rules, enabling certain compiler optimizations, allowing for multiple dispatch, providing a form of documentation, etc.A type system associates a type with each computed value and, by examining the flow of these values, attempts to ensure or prove that no type errors can occur. The given type system in question determines exactly what constitutes a type error, but in general the aim is to prevent operations expecting a certain kind of value from being used with values for which that operation does not make sense (logic errors). Type systems are often specified as part of programming languages, and built into the interpreters and compilers for them; although the type system of a language can be extended by optional tools that perform added kinds of checks using the language's original type syntax and grammar.An example of a simple type system is that of the C language. The portions of a C program are the function definitions.  One function is invoked by another function.  The interface of a function states the name of the function and a list of values that are passed to the function's code.  The code of an invoking function states the name of the invoked, along with the names of variables that hold values to pass to it.  During execution, the values are placed into temporary storage, then execution jumps to the code of the invoked function.  The invoked function's code accesses the values and makes use of them.  If the instructions inside the function are written with the assumption of receiving an integer value, but the calling code passed a floating-point value, then the wrong result will be computed by the invoked function.  The C compiler checks the type declared for each variable sent, against the type declared for each variable in the interface of the invoked function.  If the types do not match, the compiler throws a compile-time error.A compiler may also use the static type of a value to optimize the storage it needs and the choice of algorithms for operations on the value. In many C compilers the float data type, for example, is represented in 32 bits, in accord with the IEEE specification for single-precision floating point numbers. They will thus use floating-point-specific microprocessor operations on those values (floating-point addition, multiplication, etc.).The depth of type constraints and the manner of their evaluation affect the typing of the language. A programming language may further associate an operation with various resolutions for each type, in the case of type polymorphism. Type theory is the study of type systems. The concrete types of some programming languages, such as integers and strings, depend on practical issues of computer architecture, compiler implementation, and language design.Formally, type theory studies type systems. A programming language must have occurrence to type check using the type system whether at compile time or runtime, manually annotated or automatically inferred.  As Mark Manasse concisely put it:Assigning a data type, termed typing, gives meaning to a sequence of bits such as a value in memory or some object such as a variable. The hardware of a general purpose computer is unable to discriminate between for example a memory address and an instruction code, or between a character, an integer, or a floating-point number, because it makes no intrinsic distinction between any of the possible values that a sequence of bits might mean.[note 1] Associating a sequence of bits with a type conveys that meaning to the programmable hardware to form a symbolic system composed of that hardware and some program.A program associates each value with at least one specific type, but it also can occur that one value is associated with many subtypes.  Other entities, such as objects, modules, communication channels, and dependencies can become associated with a type.  Even a type can become associated with a type.  An implementation of a type system could in theory associate identifications called data type (a type of a value), class (a type of an object), and kind (a type of a type, or metatype). These are the abstractions that typing can go through, on a hierarchy of levels contained in a system.When a programming language evolves a more elaborate type system, it gains a more finely grained rule set than basic type checking, but this comes at a price when the type inferences (and other properties) become undecidable, and when more attention must be paid by the programmer to annotate code or to consider computer-related operations and functioning. It is challenging to find a sufficiently expressive type system that satisfies all programming practices in a type safe manner.The more type restrictions that are imposed by the compiler, the more strongly typed a programming language is.  Strongly typed languages often require the programmer to make explicit conversions in contexts where an implicit conversion would cause no harm.  Pascal's type system has been described as too strong because, for example, the size of an array or string is part of its type, making some programming tasks difficult.Haskell is also strongly typed but its types are automatically inferred so that explicit conversions are often (but not always) unnecessary.A programming language compiler can also implement a dependent type or an effect system, which enables even more program specifications to be verified by a type checker. Beyond simple value-type pairs, a virtual region of code is associated with an effect component describing what is being done with what, and enabling for example to throw an error report.  Thus the symbolic system may be a type and effect system, which endows it with more safety checking than type checking alone.Whether automated by the compiler or specified by a programmer, a type system makes program behavior illegal if outside the type-system rules. Advantages provided by programmer-specified type systems include:Advantages provided by compiler-specified type systems include:Type safety contributes to program correctness, but can only guarantee correctness at the cost of making the type checking itself an undecidable problem.[citation needed]  In a type system with automated type checking a program may prove to run incorrectly yet be safely typed, and produce no compiler errors. Division by zero is an unsafe and incorrect operation, but a type checker running at compile time only doesn't scan for division by zero in most languages, and then it is left as a runtime error. To prove the absence of these more-general-than-types defects, other kinds of formal methods, collectively known as program analyses, are in common use. Alternatively, a sufficiently expressive type system, such as in dependently typed languages, can prevent these kinds of errors (for example, expressing the type of non-zero numbers).  In addition software testing is an empirical method for finding errors that the type checker cannot detect.The process of verifying and enforcing the constraints of types—type checking—may occur either at compile-time (a static check) or at run-time. If a language specification requires its typing rules strongly (i.e., more or less allowing only those automatic type conversions that do not lose information), one can refer to the process as strongly typed, if not, as weakly typed. The terms are not usually used in a strict sense.Static type checking is the process of verifying the type safety of a program based on analysis of a program's text (source code). If a program passes a static type checker, then the program is guaranteed to satisfy some set of type safety properties for all possible inputs.Static type checking can be considered a limited form of program verification (see type safety), and in a type-safe language, can be considered also an optimization. If a compiler can prove that a program is well-typed, then it does not need to emit dynamic safety checks, allowing the resulting compiled binary to run faster and to be smaller.Static type checking for Turing-complete languages is inherently conservative. That is, if a type system is both sound (meaning that it rejects all incorrect programs) and decidable (meaning that it is possible to write an algorithm that determines whether a program is well-typed), then it must be incomplete (meaning there are correct programs, which are also rejected, even though they do not encounter runtime errors). For example, consider a program containing the code:if <complex test> then <do something> else <generate type error>Even if the expression <complex test> always evaluates to true at run-time, most type checkers will reject the program as ill-typed, because it is difficult (if not impossible) for a static analyzer to determine that the else branch will not be taken. Conversely, a static type checker will quickly detect type errors in rarely used code paths. Without static type checking, even code coverage tests with 100% coverage may be unable to find such type errors. The tests may fail to detect such type errors, because the combination of all places where values are created and all places where a certain value is used must be taken into account.A number of useful and common programming language features cannot be checked statically, such as downcasting. Thus, many languages will have both static and dynamic type checking; the static type checker verifies what it can, and dynamic checks verify the rest.Many languages with static type checking provide a way to bypass the type checker. Some languages allow programmers to choose between static and dynamic type safety. For example, C# distinguishes between statically-typed and dynamically-typed variables. Uses of the former are checked statically, whereas uses of the latter are checked dynamically. Other languages allow writing code that is not type-safe. For example, in C, programmers can freely cast a value between any two types that have the same size.For a list of languages with static type checking, see the category for statically typed languages.Dynamic type checking is the process of verifying the type safety of a program at runtime. Implementations of dynamically type-checked languages generally associate each runtime object with a type tag (i.e., a reference to a type) containing its type information. This runtime type information (RTTI) can also be used to implement dynamic dispatch, late binding, downcasting, reflection, and similar features.Most type-safe languages include some form of dynamic type checking, even if they also have a static type checker.[citation needed] The reason for this is that many useful features or properties are difficult or impossible to verify statically. For example, suppose that a program defines two types, A and B, where B is a subtype of A. If the program tries to convert a value of type A to type B, which is known as downcasting, then the operation is legal only if the value being converted is actually a value of type B. Thus, a dynamic check is needed to verify that the operation is safe. This requirement is one of the criticisms of downcasting.By definition, dynamic type checking may cause a program to fail at runtime. In some programming languages, it is possible to anticipate and recover from these failures. In others, type-checking errors are considered fatal.Programming languages that include dynamic type checking but not static type checking are often called dynamically typed programming languages. For a list of such languages, see the category for dynamically typed programming languages.Some languages allow both static and dynamic typing (type checking), sometimes called soft typing. For example, Java and some other ostensibly statically typed languages support downcasting types to their subtypes, querying an object to discover its dynamic type, and other type operations that depend on runtime type information. More generally, most programming languages include mechanisms for dispatching over different 'kinds' of data, such as disjoint unions, subtype polymorphism, and variant types. Even when not interacting with type annotations or type checking, such mechanisms are materially similar to dynamic typing implementations. See programming language for more discussion of the interactions between static and dynamic typing.Objects in object-oriented languages are usually accessed by a reference whose static target type (or manifest type) is equal to either the object's run-time type (its latent type) or a supertype thereof. This is conformant with the Liskov substitution principle, which states that all operations performed on an instance of a given type can also be performed on an instance of a subtype. This concept is also known as subsumption. In some languages subtypes may also possess covariant or contravariant return types and argument types respectively.Certain languages, for example Clojure, Common Lisp, or Cython are dynamically type-checked by default, but allow programs to opt into static type checking by providing optional annotations. One reason to use such hints would be to optimize the performance of critical sections of a program. This is formalized by gradual typing. The programming environment DrRacket, a  pedagogic environment based on Lisp, and a precursor of the language Racket was also soft-typed.Conversely, as of version 4.0, the C# language provides a way to indicate that a variable should not be statically type-checked. A variable whose type is dynamic will not be subject to static type checking. Instead, the program relies on runtime type information to determine how the variable may be used.The choice between static and dynamic typing requires certain trade-offs.Static typing can find type errors reliably at compile time, which should increase the reliability of the delivered program. However, programmers disagree over how commonly type errors occur, resulting in further disagreements over the proportion of those bugs that are coded that would be caught by appropriately representing the designed types in code. Static typing advocates[who?] believe programs are more reliable when they have been well type-checked, whereas dynamic-typing advocates[who?] point to distributed code that has proven reliable and to small bug databases.[citation needed] The value of static typing, then, presumably[vague] increases as the strength of the type system is increased. Advocates of dependent typing,[who?] implemented in languages such as Dependent ML and Epigram, have suggested that almost all bugs can be considered type errors, if the types used in a program are properly declared by the programmer or correctly inferred by the compiler.Static typing usually results in compiled code that executes faster. When the compiler knows the exact data types that are in use (which is necessary for static verification, either through declaration or inference) it can produce optimized machine code. Some dynamically typed languages such as Common Lisp allow optional type declarations for optimization for this reason. By contrast, dynamic typing may allow compilers to run faster and interpreters to dynamically load new code, because changes to source code in dynamically typed languages may result in less checking to perform and less code to revisit.[clarification needed] This too may reduce the edit-compile-test-debug cycle.Statically typed languages that lack type inference (such as C and Java) require that programmers declare the types that a method or function must use. This can serve as added program documentation, that is active and dynamic, instead of static. This allows a compiler to prevent it from drifting out of synchrony, and from being ignored by programmers. However, a language can be statically typed without requiring type declarations (examples include Haskell, Scala, OCaml, F#, and to a lesser extent C# and C++), so explicit type declaration is not a necessary requirement for static typing in all languages.Dynamic typing allows constructs that some static type checking would reject as illegal. For example, eval functions, which execute arbitrary data as code, become possible. An eval function is possible with static typing, but requires advanced uses of algebraic data types. Further, dynamic typing better accommodates transitional code and prototyping, such as allowing a placeholder data structure (mock object) to be transparently used in place of a full data structure (usually for the purposes of experimentation and testing).Dynamic typing typically allows duck typing (which enables easier code reuse). Many[specify] languages with static typing also feature duck typing or other mechanisms like generic programming that also enable easier code reuse.Dynamic typing typically makes metaprogramming easier to use. For example, C++ templates are typically more cumbersome to write than the equivalent Ruby or Python code since C++ has stronger rules regarding type definitions (for both functions and variables). This forces a developer to write more boilerplate code for a template than a Python developer would need to. More advanced run-time constructs such as metaclasses and introspection are often harder to use in statically typed languages. In some languages, such features may also be used e.g. to generate new types and behaviors on the fly, based on run-time data. Such advanced constructs are often provided by dynamic programming languages; many of these are dynamically typed, although dynamic typing need not be related to dynamic programming languages.Languages are often colloquially referred to as strongly typed or weakly typed. In fact, there is no universally accepted definition of what these terms mean. In general, there are more precise terms to represent the differences between type systems that lead people to call them strong or weak.A third way of categorizing the type system of a programming language uses the safety of typed operations and conversions. Computer scientists consider a language type-safe if it does not allow operations or conversions that violate the rules of the type system.Some observers use the term memory-safe language (or just safe language) to describe languages that do not allow programs to access memory that has not been assigned for their use. For example, a memory-safe language will check array bounds, or else statically guarantee (i.e., at compile time before execution) that array accesses out of the array boundaries will cause compile-time and perhaps runtime errors.Consider the following program of a language that is both type-safe and memory-safe:In this example, the variable z will have the value 42. Although this may not be what the programmer anticipated, it is a well-defined result. If y were a different string, one that could not be converted to a number (e.g. Hello World), the result would be well-defined as well. Note that a program can be type-safe or memory-safe and still crash on an invalid operation; in fact, if a program encounters an operation that is not type-safe, terminating the program is often the only option.Now consider a similar example in C:In this example z will point to a memory address five characters beyond y, equivalent to three characters after the terminating zero character of the string pointed to by y. This is memory that the program is not expected to access. It may contain garbage data, and it certainly doesn't contain anything useful. As this example shows, C is neither a memory-safe nor a type-safe language.In general, type-safety and memory-safety go hand in hand. For example, a language that supports pointer arithmetic and number-to-pointer conversions (like C) is neither memory-safe nor type-safe, because it allows arbitrary memory to be accessed as if it were valid memory of any type.For more information, see memory safety.Some languages allow different levels of checking to apply to different regions of code. Examples include:Additional tools such as lint and IBM Rational Purify can also be used to achieve a higher level of strictness.It has been proposed, chiefly by Gilad Bracha, that the choice of type system be made independent of choice of language; that a type system should be a module that can be plugged into a language as needed. He believes this is advantageous, because what he calls mandatory type systems make languages less expressive and code more fragile. The requirement that types do not affect the semantics of the language is difficult to fulfill.Optional typing is related to gradual typing, but still distinct from it.[better source needed]The term polymorphism refers to the ability of code (especially, functions or classes) to act on values of multiple types, or to the ability of different instances of the same data structure to contain elements of different types. Type systems that allow polymorphism generally do so in order to improve the potential for code re-use: in a language with polymorphism, programmers need only implement a data structure such as a list or an associative array once, rather than once for each type of element with which they plan to use it. For this reason computer scientists sometimes call the use of certain forms of polymorphism generic programming. The type-theoretic foundations of polymorphism are closely related to those of abstraction, modularity and (in some cases) subtyping.In duck typing, a statement calling a method m on an object does not rely on the declared type of the object; only that the object, of whatever type, must supply an implementation of the method called, when called, at run-time.Duck typing differs from structural typing in that, if the part (of the whole module structure) needed for a given local computation is present at runtime, the duck type system is satisfied in its type identity analysis. On the other hand, a structural type system would require the analysis of the whole module structure at compile time to determine type identity or type dependence.Duck typing differs from a nominative type system in a number of aspects. The most prominent ones are that for duck typing, type information is determined at runtime (as contrasted to compile time), and the name of the type is irrelevant to determine type identity or type dependence; only partial structure information is required for that for a given point in the program execution.Duck typing uses the premise that (referring to a value) if it walks like a duck, and quacks like a duck, then it is a duck (this is a reference to the duck test that is attributed to James Whitcomb Riley). The term may have been coined [citation needed] by Alex Martelli in a 2000 message to the comp.lang.python newsgroup (see Python).While one controlled experiment showed an increase in developer productivity for duck typing in single developer projects, other controlled experiments on API usability show the opposite.Many type systems have been created that are specialized for use in certain environments with certain types of data, or for out-of-band static program analysis. Frequently, these are based on ideas from formal type theory and are only available as part of prototype research systems.Dependent types are based on the idea of using scalars or values to more precisely describe the type of some other value. For example, matrix(3,3){\displaystyle \mathrm {matrix} (3,3)} might be the type of a 3×3{\displaystyle 3\times 3} matrix. We can then define typing rules such as the following rule for matrix multiplication:matrixmultiply:matrix(k,m)×matrix(m,n)<U+2192>matrix(k,n){\displaystyle \mathrm {matrix} _{\mathrm {multiply} }:\mathrm {matrix} (k,m)\times \mathrm {matrix} (m,n)\to \mathrm {matrix} (k,n)}where k{\displaystyle k}, m{\displaystyle m}, n{\displaystyle n} are arbitrary positive integer values. A variant of ML called Dependent ML has been created based on this type system, but because type checking for conventional dependent types is undecidable, not all programs using them can be type-checked without some kind of limits. Dependent ML limits the sort of equality it can decide to Presburger arithmetic.Other languages such as Epigram make the value of all expressions in the language decidable so that type checking can be decidable. However, in general proof of decidability is undecidable, so many programs require hand-written annotations that may be very non-trivial. As this impedes the development process, many language implementations provide an easy way out in the form of an option to disable this condition. This, however, comes at the cost of making the type-checker run in an infinite loop when fed programs that do not type-check, causing the compilation to fail.Linear types, based on the theory of linear logic, and closely related to uniqueness types, are types assigned to values having the property that they have one and only one reference to them at all times. These are valuable for describing large immutable values such as files, strings, and so on, because any operation that simultaneously destroys a linear object and creates a similar object (such as 'str= str + a') can be optimized under the hood into an in-place mutation. Normally this is not possible, as such mutations could cause side effects on parts of the program holding other references to the object, violating referential transparency. They are also used in the prototype operating system Singularity for interprocess communication, statically ensuring that processes cannot share objects in shared memory in order to prevent race conditions. The Clean language (a Haskell-like language) uses this type system in order to gain a lot of speed (compared to performing a deep copy) while remaining safe.Intersection types are types describing values that belong to both of two other given types with overlapping value sets. For example, in most implementations of C the signed char has range -128 to 127 and the unsigned char has range 0 to 255, so the intersection type of these two types would have range 0 to 127. Such an intersection type could be safely passed into functions expecting either signed or unsigned chars, because it is compatible with both types.Intersection types are useful for describing overloaded function types: For example, if int <U+2192> int is the type of functions taking an integer argument and returning an integer, and float <U+2192> float is the type of functions taking a float argument and returning a float, then the intersection of these two types can be used to describe functions that do one or the other, based on what type of input they are given. Such a function could be passed into another function expecting an int <U+2192> int function safely; it simply would not use the float <U+2192> float functionality.In a subclassing hierarchy, the intersection of a type and an ancestor type (such as its parent) is the most derived type. The intersection of sibling types is empty.The Forsythe language includes a general implementation of intersection types. A restricted form is refinement types.Union types are types describing values that belong to either of two types. For example, in C, the signed char has a -128 to 127 range, and the unsigned char has a 0 to 255 range, so the union of these two types would have an overall virtual range of -128 to 255 that may be used partially depending on which union member is accessed. Any function handling this union type would have to deal with integers in this complete range. More generally, the only valid operations on a union type are operations that are valid on both types being unioned. C's union concept is similar to union types, but is not typesafe, as it permits operations that are valid on either type, rather than both. Union types are important in program analysis, where they are used to represent symbolic values whose exact nature (e.g., value or type) is not known.In a subclassing hierarchy, the union of a type and an ancestor type (such as its parent) is the ancestor type. The union of sibling types is a subtype of their common ancestor (that is, all operations permitted on their common ancestor are permitted on the union type, but they may also have other valid operations in common).Existential types are frequently used in connection with record types to represent modules and abstract data types, due to their ability to separate implementation from interface. For example, the type T = <U+2203>X { a: X; f: (X <U+2192> int); } describes a module interface that has a data member named a of type X and a function named f that takes a parameter of the same type X and returns an integer. This could be implemented in different ways; for example:These types are both subtypes of the more general existential type T and correspond to concrete implementation types, so any value of one of these types is a value of type T. Given a value t of type T, we know that t.f(t.a) is well-typed, regardless of what the abstract type X is. This gives flexibility for choosing types suited to a particular implementation while clients that use only values of the interface type—the existential type—are isolated from these choices.In general it's impossible for the typechecker to infer which existential type a given module belongs to. In the above example intT { a: int; f: (int <U+2192> int); } could also have the type <U+2203>X { a: X; f: (int <U+2192> int); }. The simplest solution is to annotate every module with its intended type, e.g.:Although abstract data types and modules had been implemented in programming languages for quite some time, it wasn't until 1988 that John C. Mitchell and Gordon Plotkin established the formal theory under the slogan: Abstract [data] types have existential type. The theory is a second-order typed lambda calculus similar to System F, but with existential instead of universal quantification.Gradual typing is a type system in which variables may be typed either at compile-time (which is static typing) or at run-time (which is dynamic typing), allowing software developers to choose either type paradigm as appropriate, from within a single language.  In particular, gradual typing uses a special type named dynamic to represent statically-unknown types, and gradual typing replaces the notion of type equality with a new relation called consistency that relates the dynamic type to every other type. The consistency relation is symmetric but not transitive.Many static type systems, such as those of C and Java, require type declarations: The programmer must explicitly associate each variable with a specific type. Others, such as Haskell's, perform type inference: The compiler draws conclusions about the types of variables based on how programmers use those variables. For example, given a function f(x, y)  that adds x  and y  together, the compiler can infer that x  and y  must be numbers – since addition is only defined for numbers. Thus, any call to f  elsewhere in the program that specifies a non-numeric type (such as a string or list) as an argument would signal an error.Numerical and string constants and expressions in code can and often do imply type in a particular context. For example, an expression 3.14  might imply a type of floating-point, while [1, 2, 3]  might imply a list of integers – typically an array.Type inference is in general possible, if it is decidable in the type theory in question. Moreover, even if inference is undecidable in general for a given type theory, inference is often possible for a large subset of real-world programs. Haskell's type system, a version of Hindley–Milner, is a restriction of System F<U+03C9> to so-called rank-1 polymorphic types, in which type inference is decidable. Most Haskell compilers allow arbitrary-rank polymorphism as an extension, but this makes type inference undecidable. (Type checking is decidable, however, and rank-1 programs still have type inference; higher rank polymorphic programs are rejected unless given explicit type annotations.)Some languages like Perl 6 or C# have a unified type system. This means that all C# types including primitive types inherit from a single root object. Every type in C# inherits from the Object class. Java has several primitive types that are not objects. Java provides wrapper object types that exist together with the primitive types so developers can use either the wrapper object types or the simpler non-object primitive types.A type-checker for a statically typed language must verify that the type of any expression is consistent with the type expected by the context in which that expression appears. For example, in an assignment statement of the form x := e, the inferred type of the expression e must be consistent with the declared or inferred type of the variable x. This notion of consistency, called compatibility, is specific to each programming language.If the type of e and the type of x are the same, and assignment is allowed for that type, then this is a valid expression. Thus, in the simplest type systems, the question of whether two types are compatible reduces to that of whether they are equal (or equivalent). Different languages, however, have different criteria for when two type expressions are understood to denote the same type. These different equational theories of types vary widely, two extreme cases being structural type systems, in which any two types that describe values with the same structure are equivalent, and nominative type systems, in which no two syntactically distinct type expressions denote the same type (i.e., types must have the same name in order to be equal).In languages with subtyping, the compatibility relation is more complex. In particular, if A is a subtype of B, then a value of type A can be used in a context where one of type B is expected, even if the reverse is not true. Like equivalence, the subtype relation is defined differently for each programming language, with many variations possible. The presence of parametric or ad hoc polymorphism in a language may also have implications for type compatibility."
"35"	"In programming language theory, subtyping (also subtype polymorphism or inclusion polymorphism) is a form of type polymorphism in which a subtype is a datatype that is related to another datatype (the supertype) by some notion of substitutability, meaning that program elements, typically subroutines or functions, written to operate on elements of the supertype can also operate on elements of the subtype. If S is a subtype of T, the subtyping relation is often written S <: T, to mean that any term of type S can be safely used in a context where a term of type T is expected. The precise semantics of subtyping crucially depends on the particulars of what safely used in a context where means in a given programming language. The type system of a programming language essentially defines its own subtyping relation, which may well be trivial [clarification needed].Due to the subtyping relation, a term may belong to more than one type.  Subtyping is therefore a form of type polymorphism. In object-oriented programming the term 'polymorphism' is commonly used to refer solely to this subtype polymorphism,   while the techniques of parametric polymorphism would be considered generic programming.Functional programming languages often allow the subtyping of records. Consequently, simply typed lambda calculus extended with record types is perhaps the simplest theoretical setting in which a useful notion of subtyping may be defined and studied [citation needed]. Because the resulting calculus allows terms to have more than one type, it is no longer a simple type theory. Since functional programming languages, by definition, support function literals, which can also be stored in records, records types with subtyping provide some of the features of object-oriented programming. Typically, functional programming languages also provide some, usually restricted, form of parametric polymorphism. In a theoretical setting, it is desirable to study the interaction of the two features; a common theoretical setting is system F<:. Various calculi that attempt to capture the theoretical properties of object-oriented programming may be derived from system F<:.The concept of subtyping is related to the linguistic notions of hyponymy and holonymy. It is also related to the concept of bounded quantification in mathematical logic. Subtyping should not be confused with the notion of (class or object) inheritance from object-oriented languages; subtyping is a relation between types (interfaces in object-oriented parlance) whereas inheritance is a relation between implementations stemming from a language feature that allows new objects to be created from existing ones. In a number of object-oriented languages, subtyping is called interface inheritance, with inheritance referred to as implementation inheritance.The notion of subtyping in programming languages dates back to the 1960s; it was introduced in Simula derivatives. The first formal treatments of subtyping were given by John C. Reynolds in 1980 who used category theory to formalize implicit conversions, and Luca Cardelli (1985).The concept of subtyping has gained visibility (and synonymy with polymorphism in some circles) with the mainstream adoption of object-oriented programming. In this context, the principle of safe substitution is often called the Liskov substitution principle, after Barbara Liskov who popularized it in a keynote address at a conference on object-oriented programming in 1987. Because it must consider mutable objects, the ideal notion of subtyping defined by Liskov and Jeannette Wing, called behavioral subtyping is considerably stronger than what can be implemented in a type checker. (See Function types below for details.)A simple practical example of subtypes is shown in the diagram, right. The type bird has three subtypes duck, cuckoo and ostrich. Conceptually, each of these is a variety of the basic bird that inherits many bird characteristics but has some specific differences. The UML notation is used in this diagram, with open-headed arrows showing the direction and type of the relationship between the supertype and its subtypes.As a more practical example, a language might allow integer values to be used wherever floating point values are expected (Integer <: Float), or it might define a generic type Number as a common supertype of integers and the reals. In this second case, we only have Integer <: Number and Float <: Number, but Integer and Float are not subtypes of each other.Programmers may take advantage of subtyping to write code in a more abstract manner than would be possible without it. Consider the following example:If integer and real are both subtypes of Number, and an operator of comparison with an arbitrary Number is defined for both types, then values of either type can be passed to this function. However, the very possibility of implementing such an operator highly constrains the Number type (for example, one can't compare an integer with a complex number), and actually only comparing integers with integers and reals with reals makes sense. Rewriting this function so that it would only accept 'x' and 'y' of the same type requires bounded polymorphism.Subtyping in type theory is characterized by the fact that any expression of type A may also be given type B if A<:B; the formal typing rule that codifies this is known as the subsumption rule.Type theorists make a distinction between nominal subtyping, in which only types declared in a certain way may be subtypes of each other, and structural subtyping, in which the structure of two types determines whether or not one is a subtype of the other.  The class-based object-oriented subtyping described above is nominal; a structural subtyping rule for an object-oriented language might say that if objects of type A can handle all of the messages that objects of type B can handle (that is, if they define all the same methods), then A is a subtype of B regardless of whether either inherits from the other.  This so-called duck typing is common in dynamically typed object-oriented languages.  Sound structural subtyping rules for types other than object types are also well known.[citation needed]Implementations of programming languages with subtyping fall into two general classes: inclusive implementations, in which the representation of any value of type A also represents the same value at type B if A<:B, and coercive implementations, in which a value of type A can be automatically converted into one of type B.  The subtyping induced by subclassing in an object-oriented language is usually inclusive; subtyping relations that relate integers and floating-point numbers, which are represented differently, are usually coercive.In almost all type systems that define a subtyping relation, it is reflexive (meaning A<:A for any type A) and transitive (meaning that if A<:B and B<:C then A<:C).  This makes it a preorder on types.Types of records give rise to the concepts of width and depth subtyping. These express two different ways of obtaining a new type of record that allows the same operations as the original record type.Recall that a record is a collection of (named) fields. Since a subtype is a type which allows all operations allowed on the original type, a record subtype should support the same operations on the fields as the original type supported.One kind of way to achieve such support, called width subtyping, adds more fields to the record. More formally, every (named) field appearing in the width supertype will appear in the width subtype. Thus, any operation feasible on the supertype will be supported by the subtype.The second method, called depth subtyping, replaces the various fields with their subtypes. That is, the fields of the subtype are subtypes of the fields of the supertype. Since any operation supported for a field in the supertype is supported for its subtype, any operation feasible on the record supertype is supported by the record subtype. Depth subtyping only makes sense for immutable records: for example, you can assign 1.5 to the 'x' field of a real point (a record with two real fields), but you can't do the same to the 'x' field of an integer point (which, however, is a deep subtype of the real point type) because 1.5 is not an integer (see Variance).Subtyping of records can be defined in System F<:, which combines parametric polymorphism with subtyping of record types and is a theoretical basis for many functional programming languages that support both features.Some systems also support subtyping of labeled disjoint union types (such as algebraic data types).  The rule for width subtyping is reversed: every tag appearing in the width subtype must appear in the width supertype.If T1 <U+2192> T2 is a function type, then a subtype of it is any function S1 <U+2192> S2 with the property that T1 <: S1 and S2 <: T2. The argument type of S1 <U+2192> S2 is said to be contravariant because the subtyping relation is reversed for it, whereas the return type is covariant. Informally, this reversal occurs because the refined type is more liberal in the types it accepts and more conservative in the type it returns. This is what exactly works in Scala: a n-ary function is internally a class that inherits the FunctionN(-A1, -A2, …, -An, +B) trait (which can be seen as a general interface in Java-like languages), where A1, A2, … An are the parameter types, and B is its return type; - before the type means the type is contravariant while + means covariant.In languages that allow side effects, like most object-oriented languages, subtyping is generally not sufficient to guarantee that a function can be safely used in the context of another. Liskov's work in this area focused on behavioral subtyping, which besides the type system safety discussed in this article also requires that subtypes preserve all invariants guaranteed by the supertypes in some contract. This definition of subtyping is generally undecidable, so it cannot be verified by a type checker.The subtyping of mutable references is similar to the treatment of function arguments and return values.  Write-only references (or sinks) are contravariant, like function arguments; read-only references (or sources) are covariant, like return values.  Mutable references which act as both sources and sinks are invariant.In coercive subtyping systems, subtypes are defined by implicit type conversion functions from subtype to supertype.  For each subtyping relationship (S <: T), a coercion function coerce: S <U+2192> T is provided, and any object s of type S is regarded as the object coerceS <U+2192> T(s) of type T.  A coercion function may be defined by composition: if S <: T and T <: U then s may be regarded as an object of type u under the compound coercion (coerceT <U+2192> U ° coerceS <U+2192> T).  The type coercion from a type to itself coerceT <U+2192> T is the identity function idTCoercion functions for records and disjoint union subtypes may be defined componentwise; in the case of width-extended records, type coercion simply discards any components which are not defined in the supertype.  The type coercion for function types may be given by f'(s) = coerceS2 <U+2192> T2(f(coerceT1 <U+2192> S1(t))), reflecting the contravariance of function arguments and covariance of return values.The coercion function is uniquely determined given the subtype and supertype.  Thus, when multiple subtyping relationships are defined, one must be careful to guarantee that all type coercions are coherent.  For instance, if an integer such as 2 : int can be coerced to a floating point number (say, 2.0 : float), then it is not admissible to coerce 2.1 : float to 2 : int, because the compound coercion coercefloat <U+2192> float given by coerceint <U+2192> float ° coercefloat <U+2192> int would then be distinct from the identity coercion idfloat.TextbooksPapers"
"36"	"In programming languages, ad-hoc polymorphism is a kind of polymorphism in which polymorphic functions can be applied to arguments of different types, because a polymorphic function can denote a number of distinct and potentially heterogeneous implementations depending on the type of argument(s) to which it is applied. It is also known as function overloading or operator overloading. The term ad hoc in this context is not intended to be pejorative; it refers simply to the fact that this type of polymorphism is not a fundamental feature of the type system. This is in contrast to parametric polymorphism, in which polymorphic functions are written without mention of any specific type, and can thus apply a single abstract implementation to any number of types in a transparent way. This classification was introduced by Christopher Strachey in 1967.Ad hoc polymorphism is a dispatch mechanism: control moving through one named function is dispatched to various other functions without having to specify the exact function being called. Overloading allows multiple functions taking different types to be defined with the same name; the compiler or interpreter automatically ensures that the right function is called. This way, functions appending lists of integers, lists of strings, lists of real numbers, and so on could be written, and all be called append—and the right append function would be called based on the type of lists being appended. This differs from parametric polymorphism, in which the function would need to be written generically, to work with any kind of list. Using overloading, it is possible to have a function perform two completely different things based on the type of input passed to it; this is not possible with parametric polymorphism. Another way to look at overloading is that a routine is uniquely identified not by its name, but by the combination of its name and the number, order and types of its parameters.This type of polymorphism is common in object-oriented programming languages, many of which allow operators to be overloaded in a manner similar to functions (see operator overloading). Some languages that are not dynamically typed and lack ad hoc  polymorphism (including type classes) have longer function names such as print_int, print_string, etc. This can be seen as advantage (more descriptive) or a disadvantage (overly verbose) depending on one's point of view.An advantage that is sometimes gained from overloading is the appearance of specialization, e.g., a function with the same name can be implemented in multiple different ways, each optimized for the particular data types that it operates on. This can provide a convenient interface for code that needs to be specialized to multiple situations for performance reasons. The downside is that the type system cannot guarantee the consistency of the different implementations.Since overloading is done at compile time, it is not a substitute for late binding as found in subtyping polymorphism.The previous section notwithstanding, there are other ways in which ad hoc polymorphism can work out. Consider for example the Smalltalk language. In Smalltalk, the overloading is done at run time, as the methods (function implementation) for each overloaded message (overloaded function) are resolved when they are about to be executed. This happens at run time, after the program is compiled. Therefore, polymorphism is given by subtyping polymorphism as in other languages, and it is also extended in functionality by ad hoc polymorphism at run time.A closer look will also reveal that Smalltalk provides a slightly different variety of ad hoc polymorphism. Since Smalltalk has a late bound execution model, and since it provides objects the ability to handle messages that are not understood, it is possible to go ahead and implement functionality using polymorphism without explicitly overloading a particular message. This may not be generally recommended practice for everyday programming, but it can be quite useful when implementing proxies.Also, while in general terms common class method and constructor overloading is not considered polymorphism, there are more uniform languages in which classes are regular objects. In Smalltalk, for instance, classes are regular objects. In turn, this means messages sent to classes can be overloaded, and it is also possible to create objects that behave like classes without their classes inheriting from the hierarchy of classes. These are effective techniques which can be used to take advantage of Smalltalk's powerful reflection capabilities. Similar arrangements are also possible in languages such as Self and Newspeak.Imagine an operator + that may be used in the following ways:To handle these six function calls, four different pieces of code are needed—or three, if strings are considered to be lists of characters:Thus, the name + actually refers to three or four completely different functions. This is an example of overloading. (Note that string types used in the last case do not, by themselves, lend themselves to the programmer naturally assuming concatenation, rather than addition, is meant; consider 123 + 456, which might reasonably be expected to yield 579. Overloading can therefore provide different meaning, or semantics, for an operation, as well as differing implementations.)"
"37"	"In programming languages and type theory, parametric polymorphism is a way to make a language more expressive, while still maintaining full static type-safety. Using parametric polymorphism, a function or a data type can be written generically so that it can handle values identically without depending on their type. Such functions and data types are called generic functions and generic datatypes respectively and form the basis of generic programming.For example, a function append that joins two lists can be constructed so that it does not care about the type of elements: it can append lists of integers, lists of real numbers, lists of strings, and so on. Let the type variable a denote the type of elements in the lists. Then append can be typed where [a] denotes the type of lists with elements of type a. We say that the type of append is parameterized by a for all values of a. (Note that since there is only one type variable, the function cannot be applied to just any pair of lists: the pair, as well as the result list, must consist of the same type of elements.) For each place where append is applied, a value is decided for a.Following Christopher Strachey, parametric polymorphism may be contrasted with ad hoc polymorphism, in which a single polymorphic function can have a number of distinct and potentially heterogeneous implementations depending on the type of argument(s) to which it is applied. Thus, ad hoc polymorphism can generally only support a limited number of such distinct types, since a separate implementation has to be provided for each type.Parametric polymorphism was first introduced to programming languages in ML in 1975. Today it exists in Standard ML, OCaml, F#, Ada, Haskell, Mercury, Visual Prolog, Scala, Julia, and others. Java, C#, Visual Basic .NET and Delphi have each introduced generics for parametric polymorphism. Some implementations of type polymorphism are superficially similar to parametric polymorphism while also introducing ad hoc aspects. One example is C++ template specialization.The most general form of polymorphism is higher-rank impredicative polymorphism. Two popular restrictions of this form are restricted rank polymorphism (for example, rank-1 or prenex polymorphism) and predicative polymorphism. Together, these restrictions give predicative prenex polymorphism, which is essentially the form of polymorphism found in ML and early versions of Haskell.In a prenex polymorphic system, type variables may not be instantiated with polymorphic types. This is very similar to what is called ML-style or Let-polymorphism (technically ML's Let-polymorphism has a few other syntactic restrictions). This restriction makes the distinction between polymorphic and non-polymorphic types very important; thus in predicative systems polymorphic types are sometimes referred to as type schemas to distinguish them from ordinary (monomorphic) types, which are sometimes called monotypes. A consequence is that all types can be written in a form that places all quantifiers at the outermost (prenex) position. For example, consider the append function described above, which has type In order to apply this function to a pair of lists, a type must be substituted for the variable a in the type of the function such that the type of the arguments matches up with the resulting function type. In an impredicative system, the type being substituted may be any type whatsoever, including a type that is itself polymorphic; thus append can be applied to pairs of lists with elements of any type—even to lists of polymorphic functions such as append itself. Polymorphism in the language ML and its close relatives is predicative. This is because predicativity, together with other restrictions, makes the type system simple enough that type inference is possible. In languages where explicit type annotations are necessary when applying a polymorphic function, the predicativity restriction is less important; thus these languages are generally impredicative.For some fixed value k, rank-k polymorphism is a system in which a quantifier may not appear to the left of k or more arrows (when the type is drawn as a tree).Type inference for rank-2 polymorphism is decidable, but reconstruction for rank-3 and above is not.Rank-n polymorphism is polymorphism in which quantifiers may appear to the left of arbitrarily many arrows.In a predicative parametric polymorphic system, a type t{\displaystyle \tau } containing a type variable a{\displaystyle \alpha } may not be used in such a way that a{\displaystyle \alpha } is instantiated to a polymorphic type. Predicative type theories include Martin-Löf Type Theory and NuPRL.Impredicative polymorphism (also called first-class polymorphism) is the most powerful form of parametric polymorphism. A definition is said to be impredicative if it is self-referential; in type theory this allows the instantiation of a variable in a type t{\displaystyle \tau } with any type, including polymorphic types, such as t{\displaystyle \tau } itself. An example of this is the System F with the type variable X in the type T=<U+2200>X.X<U+2192>X{\displaystyle T=\forall X.X\to X}, where X could even refer to T itself.In type theory, the most frequently studied impredicative typed <U+03BB>-calculi are based on those of the lambda cube, especially System F.In 1985, Luca Cardelli and Peter Wegner recognized the advantages of allowing bounds on the type parameters. Many operations require some knowledge of the data types, but can otherwise work parametrically. For example, to check whether an item is included in a list, we need to compare the items for equality. In Standard ML, type parameters of the form ’’a are restricted so that the equality operation is available, thus the function would have the type ’’a × ’’a list <U+2192> bool and ’’a can only be a type with defined equality. In Haskell, bounding is achieved by requiring types to belong to a type class; thus the same function has the type Eqa<U+21D2>a<U+2192>[a]<U+2192>Bool{\displaystyle {\scriptstyle Eq\,\alpha \,\Rightarrow \alpha \,\rightarrow \left[\alpha \right]\rightarrow Bool}} in Haskell. In most object-oriented programming languages that support parametric polymorphism, parameters can be constrained to be subtypes of a given type (see Subtype polymorphism and the article on Generic programming)."
"38"	"In type theory, bounded quantification (also bounded polymorphism or constrained genericity) refers to universal or existential quantifiers which are restricted (bounded) to range only over the subtypes of a particular type. Bounded quantification is an interaction of parametric polymorphism with subtyping. Bounded quantification has traditionally been studied in the functional setting of System F<:, but is available in modern object-oriented languages supporting parametric polymorphism (generics) such as Java, C# and Scala.The purpose of bounded quantification is to allow for polymorphic functions to depend on some specific behaviour of objects instead of type inheritance. It assumes a record-based model for object classes, where every class member is a record element and all class members are named functions. Object attributes are represented as functions that take no argument and return an object. The specific behaviour is then some function name along with the types of the arguments and the return type. Bounded quantification allows to considers all objects with such a function. An example would be a polymorphic min function that considers all objects that are comparable to each other.F-bounded quantification or recursively bounded quantification, introduced in 1989, allows for more precise typing of functions that are applied on recursive types. A recursive type is one that includes a function that uses it as a type for some argument or its return value.This kind of type constraint can be expressed in Java with a generic interface. The following example demonstrates how to describe types that can be compared to each other and use this as typing information in polymorphic functions. The Test.min function uses simple bounded quantification and does not preserve the type of the assigned types, in contrast with the Test.Fmin function which uses F-bounded quantification.In mathematical notation, the types of the two functions arewhere"
"39"	"In software engineering, inversion of control (IoC) is a design principle in which custom-written portions of a computer program receive the flow of control from a generic framework. A software architecture with this design inverts control as compared to traditional procedural programming: in traditional programming, the custom code that expresses the purpose of the program calls into reusable libraries to take care of generic tasks, but with inversion of control, it is the framework that calls into the custom, or task-specific, code.Inversion of control is used to increase modularity of the program and make it extensible, and has applications in object-oriented programming and other programming paradigms. The term was used by Michael Mattsson in a thesis, taken from there by Stefano Mazzocchi and popularized by him in 1999 in a now-defunct Apache Software Foundation project Avalon, then further popularized in 2004 by Robert C. Martin and Martin Fowler.The term is related to, but different from, the dependency inversion principle, which concerns itself with decoupling dependencies between high-level and low-level  layers through shared abstractions. The general concept is also related to event-driven programming in that it is often implemented using IoC, so that the custom code is commonly only concerned with the handling of events, whereas the event loop and dispatch of events/messages is handled by the framework or the runtime environment.As an example, with traditional programming, the main function of an application might make function calls into a menu library to display a list of available commands and query the user to select one. The library thus would return the chosen option as the value of the function call, and the main function uses this value to execute the associated command. This style was common in text based interfaces. For example, an email client may show a screen with commands to load new mails, answer the current mail, start a new mail, etc., and the program execution would block until the user presses a key to select a command.With inversion of control, on the other hand, the program would be written using a software framework that knows common behavioral and graphical elements, such as windowing systems, menus, controlling the mouse, and so on. The custom code fills in the blanks for the framework, such as supplying a table of menu items and registering a code subroutine for each item, but it is the framework that monitors the user's actions and invokes the subroutine when a menu item is selected. In the mail client example, the framework could follow both the keyboard and mouse inputs and call the command invoked by the user by either means, and at the same time monitor the network interface to find out if new messages arrive and refresh the screen when some network activity is detected. The same framework could be used as the skeleton for a spreadsheet program or a text editor. Conversely, the framework knows nothing about Web browsers, spreadsheets or text editors; implementing their functionality takes custom code.Inversion of control carries the strong connotation that the reusable code and the problem-specific code are developed independently even though they operate together in an application. Software frameworks, callbacks, schedulers, event loops, dependency injection, and the template method are examples of design patterns that follow the inversion of control principle, although the term is most commonly used in the context of object-oriented programming.Inversion of control serves the following design purposes:Inversion of control is sometimes facetiously referred to as the Hollywood Principle: Don't call us, we'll call you.Inversion of control is not a new term in computer science. Martin Fowler traces the etymology of the phrase back to 1988.Dependency injection is a specific type of IoC using contextualized lookup. A service locator such as the Java Naming and Directory Interface (JNDI) is similar. In an article by Loek Bergman, it is presented as an architectural principle.In an article by Robert C. Martin, the dependency inversion principle and abstraction by layering come together. His reason to use the term inversion is in comparison with traditional software development methods. He describes the uncoupling of services by the abstraction of layers when he is talking about dependency inversion. The principle is used to find out where system borders are in the design of the abstraction layers.In traditional programming, the flow of the business logic is determined by objects that are statically bound to one another. With inversion of control, the flow depends on the object graph that is built up during program execution. Such a dynamic flow is made possible by object interactions that are defined through abstractions. This run-time binding is achieved by mechanisms such as dependency injection or a service locator. In IoC, the code could also be linked statically during compilation, but finding the code to execute by reading its description from external configuration instead of with a direct reference in the code itself.In dependency injection, a dependent object or module is coupled to the object it needs at run time. Which particular object will satisfy the dependency during program execution typically cannot be known at compile time using static analysis. While described in terms of object interaction here, the principle can apply to other programming methodologies besides object-oriented programming.In order for the running program to bind objects to one another, the objects must possess compatible interfaces. For example, class A may delegate behavior to interface I which is implemented by class B; the program instantiates A and B, and then injects B into A.In object-oriented programming, there are several basic techniques to implement inversion of control. These are:In an original article by Martin Fowler, the first three different techniques are discussed. In a description about inversion of control types, the last one is mentioned. Often the contextualized lookup will be accomplished using a service locator.More important than the applied technique, however, is the optimization of the purposes.Most frameworks such as .NET or Enterprise Java display this pattern:This basic outline in Java gives an example of code following the IoC methodology. It is important, however, that in the ServerFacade  a lot of assumptions are made about the data returned by the data access object (DAO).Although all these assumptions might be valid at some time, they couple the implementation of the ServerFacade  to the DAO implementation. Designing the application in the manner of inversion of control would hand over the control completely to the DAO object. The code would then becomeThe example shows that the way the method respondToRequest  is constructed determines if IoC is used. It is the way that parameters are used that define IoC. This resembles the message-passing style that some object-oriented programming languages use."
"40"	"In software engineering, a plain old Java object (POJO) is an ordinary Java object, not bound by any special restriction and not requiring any class path. The term was coined by Martin Fowler, Rebecca Parsons and Josh MacKenzie in September 2000: We wondered why people were so against using regular objects in their systems and concluded that it was because simple objects lacked a fancy name. So we gave them one, and it's caught on very nicely.The term POJO initially denoted a Java object which does not follow any of the major Java object models, conventions, or frameworks; nowadays POJO may be used as an acronym for Plain Old JavaScript Object as well, in which case the term denotes a JavaScript object of similar pedigree.The term continues the pattern of older terms for technologies that do not use fancy new features, such as POTS (Plain Old Telephone Service) in telephony and Pod (Plain Old Documentation) in Perl. The equivalent to POJO on the .NET framework is Plain Old CLR Object (POCO). For PHP, it is Plain Old PHP Object (POPO).The POJO phenomenon has most likely gained widespread acceptance because of the need for a common and easily understood term that contrasts with complicated object frameworks.[citation needed]Ideally speaking, a POJO is a Java object not bound by any restriction other than those forced by the Java Language Specification; i.e. a POJO should not have toHowever, due to technical difficulties and other reasons, many software products or frameworks described as POJO-compliant actually still require the use of prespecified annotations for features such as persistence to work properly. The idea is that if the object (actually class) was a POJO before any annotations were added, and would return to POJO status if the annotations are removed then it can still be considered a POJO. Then the basic object remains a POJO in that it has no special characteristics (such as an implemented interface) that makes it a Specialized Java Object (SJO or (sic) SoJO).A JavaBean is a POJO that is serializable, has a no-argument constructor, and allows access to properties using getter and setter methods that follow a simple naming convention. Because of this convention, simple declarative references can be made to the properties of arbitrary JavaBeans. Code using such a declarative reference does not have to know anything about the type of the bean, and the bean can be used with many frameworks without these frameworks having to know the exact type of the bean. The JavaBeans specification, if fully implemented, slightly breaks the POJO model as the class must implement the Serializable interface to be a true JavaBean.  Many POJO classes still called JavaBeans do not meet this requirement.  Since Serializable is a marker (method-less) interface, this is not much of a burden.The following shows an example of a JavaServer Faces (JSF) component having a bidirectional binding to a POJO's property:The definition of the POJO can be as follows:Because of the JavaBean naming conventions the single someProperty reference can be automatically translated to the getSomeProperty() (or isSomeProperty() if the property is of Boolean type) method for getting a value, and to the setSomeProperty(String) method for setting a value.As designs using POJOs have become more commonly used, systems have arisen that give POJOs the full functionality used in frameworks and more choice about which areas of functionality are actually needed. In this model, the programmer creates nothing more than a POJO. This POJO purely focuses on business logic and has no dependencies on (enterprise) frameworks. Aspect-oriented programming (AOP) frameworks then transparently add cross-cutting concerns like persistence, transactions, security, and so on.Spring was an early implementation of this idea and one of the driving forces behind popularizing this model.An example of an EJB bean being a POJO:The following shows a fully functional EJB bean, demonstrating how EJB3 leverages the POJO model:As given, the bean does not need to extend any EJB class or implement any EJB interface and also does not need to contain any EJB annotations. Instead, the programmer declares in an external XML file which EJB services should be added to the bean:In practice, some people find annotations elegant, while they see XML as verbose, ugly and hard to maintain, yet others find annotations pollute the POJO model. Thus, as an alternative to XML, many frameworks (e.g. Spring, EJB and JPA) allow annotations to be used instead of or in addition to XML. The following shows the same EJB bean as showed above but with an annotation added. In this case the XML file is no longer needed:With the annotation as given above the bean isn't a truly pure POJO anymore, but since annotations are merely passive metadata this has far fewer harmful drawbacks compared to the invasiveness of having to extend classes and/or implement interfaces. Accordingly, the programming model is still very much like the pure POJO model."
"41"	"The Spring Framework is an application framework and inversion of control container for the Java platform. The framework's core features can be used by any Java application, but there are extensions for building web applications on top of the Java EE (Enterprise Edition) platform. Although the framework does not impose any specific programming model, it has become popular in the Java community as an addition to, or even replacement for the Enterprise JavaBeans (EJB) model. The Spring Framework is open source.The first version was written by Rod Johnson, who released the framework with the publication of his book Expert One-on-One J2EE Design and Development in October 2002. The framework was first released under the Apache 2.0 license in June 2003. The first milestone release, 1.0, was released in March 2004, with further milestone releases in September 2004 and March 2005. The Spring 1.2.6 framework won a Jolt productivity award and a JAX (Java API for XML) Innovation Award in 2006. Spring 2.0 was released in October 2006, Spring 2.5 in November 2007, Spring 3.0 in December 2009, Spring 3.1 in December 2011, and Spring 3.2.5 in November 2013. Spring Framework 4.0 was released in December 2013. Notable improvements in Spring 4.0 included support for Java SE (Standard Edition) 8, Groovy 2, some aspects of Java EE 7, and WebSocket.Spring Framework 4.2.0 was released on 31 July 2015 and was immediately upgraded to version 4.2.1, which was released on 01 Sept 2015. It is compatible with Java 6, 7 and 8, with a focus on core refinements and modern web capabilities.Spring Framework 4.3 has been released on 10 June 2016. The 4.3.0.RC1 version is available. It will be the final generation within the general Spring 4 system requirements (Java 6+, Servlet 2.5+), getting prepared for an extended 4.3.x support life until 2019.Spring 5 is announced to be built upon Reactive Streams compatible Reactor Core.The Spring Framework includes several modules that provide a range of services:Central to the Spring Framework is its inversion of control (IoC) container, which provides a consistent means of configuring and managing Java objects using reflection. The container is responsible for managing object lifecycles of specific objects: creating these objects, calling their initialization methods, and configuring these objects by wiring them together.Objects created by the container are also called managed objects or beans. The container can be configured by loading XML (Extensible Markup Language) files or detecting specific Java annotations on configuration classes. These data sources contain the bean definitions that provide the information required to create the beans.Objects can be obtained by means of either dependency lookup or dependency injection. Dependency lookup is a pattern where a caller asks the container object for an object with a specific name or of a specific type. Dependency injection is a pattern where the container passes objects by name to other objects, via either constructors, properties, or factory methods.In many cases one need not use the container when using other parts of the Spring Framework, although using it will likely make an application easier to configure and customize. The Spring container provides a consistent mechanism to configure applications and integrates with almost all Java environments, from small-scale applications to large enterprise applications.The container can be turned into a partially compliant EJB (Enterprise JavaBeans) 3.0 container by means of the Pitchfork project. Some[who?] criticize the Spring Framework for not complying with standards. However, SpringSource doesn't see EJB 3 compliance as a major goal, and claims that the Spring Framework and the container allow for more powerful programming models. You do not create an object, but describe how they should be created, by defining it in the Spring configuration file. You do not call services and components, but tell which services and components must be called, by defining them in the Spring configuration files. This makes the code easy to maintain and easier to test through IoC.The Spring   Framework has its own Aspect-oriented programming (AOP) framework that modularizes cross-cutting concerns in aspects. The motivation for creating a separate AOP framework comes from the belief that it should be possible to provide basic AOP features without too much complexity in either design, implementation, or configuration. The Spring AOP framework also takes full advantage of the Spring container.The Spring AOP framework is proxy pattern-based, and is configured at run time. This removes the need for a compilation step or load-time weaving. On the other hand, interception only allows for public method-execution on existing objects at a join point.Compared to the AspectJ framework, Spring AOP is less powerful, but also less complicated. Spring 1.2 includes support to configure AspectJ aspects in the container. Spring 2.0 added more integration with AspectJ; for example, the pointcut language is reused and can be mixed with Spring AOP-based aspects. Further, Spring 2.0 added a Spring Aspects library that uses AspectJ to offer common Spring features such as declarative transaction management and dependency injection via AspectJ compile-time or load-time weaving. SpringSource also uses AspectJ AOP in other Spring projects such as Spring Roo and Spring Insight, with Spring Security also offering an AspectJ-based aspect library.Spring AOP has been designed to make it able to work with cross-cutting concerns inside the Spring Framework. Any object which is created and configured by the container can be enriched using Spring AOP.The Spring Framework uses Spring AOP internally for transaction management, security, remote access, and JMX.Since version 2.0 of the framework, Spring provides two approaches to the AOP configuration: The Spring team decided not to introduce new AOP-related terminology; therefore, in the Spring reference documentation and API, terms such as aspect, join point, advice, pointcut, introduction, target object (advised object), AOP proxy, and weaving all have the same meanings as in most other AOP frameworks (particularly AspectJ).Spring's data access framework addresses common difficulties developers face when working with databases in applications. Support is provided for all popular data access frameworks in Java: JDBC, iBatis/MyBatis, Hibernate, Java Data Objects (JDO), Java Persistence API (JPA), Oracle TopLink, Apache OJB, and Apache Cayenne, among others.For all of these supported frameworks, Spring provides these featuresAll these features become available when using template classes provided by Spring for each supported framework. Critics have said these template classes are intrusive and offer no advantage over using (for example) the Hibernate API directly.[not in citation given] In response, the Spring developers have made it possible to use the Hibernate and JPA APIs directly. This however requires transparent transaction management, as application code no longer assumes the responsibility to obtain and close database resources, and does not support exception translation.Together with Spring's transaction management, its data access framework offers a flexible abstraction for working with data access frameworks. The Spring Framework doesn't offer a common data access API; instead, the full power of the supported APIs is kept intact. The Spring Framework is the only framework available in Java that offers managed data access environments outside of an application server or container.While using Spring for transaction management with Hibernate, the following beans may have to be configured:Other points of configuration include:Spring's transaction management framework brings an abstraction mechanism to the Java platform. Its abstraction is capable of:In comparison, Java Transaction API (JTA) only supports nested transactions and global transactions, and requires an application server (and in some cases also deployment of applications in an application server).The Spring Framework ships a PlatformTransactionManager for a number of transaction management strategies:Next to this abstraction mechanism the framework also provides two ways of adding transaction management to applications:Together with Spring's data access framework — which integrates the transaction management framework — it is possible to set up a transactional system through configuration without having to rely on JTA or EJB. The transactional framework also integrates with messaging and caching engines.The Spring Framework features its own model–view–controller (MVC) web application framework, which wasn't originally planned. The Spring developers decided to write their own Web framework as a reaction to what they perceived as the poor design of the (then) popular Jakarta Struts Web framework, as well as deficiencies in other available frameworks. In particular, they felt there was insufficient separation between the presentation and request handling layers, and between the request handling layer and the model.Like Struts, Spring MVC is a request-based framework. The framework defines strategy interfaces for all of the responsibilities that must be handled by a modern request-based framework. The goal of each interface is to be simple and clear so that it's easy for Spring MVC users to write their own implementations, if they so choose. MVC paves the way for cleaner front end code. All interfaces are tightly coupled to the Servlet API. This tight coupling to the Servlet API is seen by some as a failure on the part of the Spring developers to offer a high-level abstraction for Web-based applications [citation needed]. However, this coupling makes sure that the features of the Servlet API remain available to developers while offering a high abstraction framework to ease working with said API.The DispatcherServlet class is the front controller of the framework and is responsible for delegating control to the various interfaces during the execution phases of an HTTP request.The most important interfaces defined by Spring MVC, and their responsibilities, are listed below:Each strategy interface above has an important responsibility in the overall framework. The abstractions offered by these interfaces are powerful, so to allow for a set of variations in their implementations, Spring MVC ships with implementations of all these interfaces and together offers a feature set on top of the Servlet API. However, developers and vendors are free to write other implementations. Spring MVC uses the Java java.util.Map interface as a data-oriented abstraction for the Model where keys are expected to be string values.The ease of testing the implementations of these interfaces seems one important advantage of the high level of abstraction offered by Spring MVC. DispatcherServlet is tightly coupled to the Spring inversion of control container for configuring the web layers of applications. However, web applications can use other parts of the Spring Framework—including the container—and choose not to use Spring MVC.Spring's Remote Access framework is an abstraction for working with various RPC (remote procedure call)-based technologies available on the Java platform both for client connectivity and marshalling objects on servers. The most important feature offered by this framework is to ease configuration and usage of these technologies as much as possible by combining inversion of control and AOP.The framework also provides fault-recovery (automatic reconnection after connection failure) and some optimizations for client-side use of EJB remote stateless session beans.Spring provides support for these protocols and products out of the boxApache CXF provides integration with the Spring Framework for RPC-style exporting of objects on the server side.Both client and server setup for all RPC-style protocols and products supported by the Spring Remote access framework (except for the Apache Axis support) is configured in the Spring Core container.There is alternative open-source implementation (Cluster4Spring) of a remoting subsystem included into Spring Framework that is intended to support various schemes of remoting (1-1, 1-many, dynamic services discovering)…Spring Boot is Spring's convention-over-configuration solution for creating stand-alone, production-grade Spring-based Applications that you can just run. It is preconfigured with the Spring's opinionated view of the best configuration and use of the Spring platform and third-party libraries so you can get started with minimum fuss. Most Spring Boot applications need very little Spring configuration. Features:Spring Roo provides an alternative, code-generation based approach at using convention-over-configuration to rapidly build applications in Java. It currently supports Spring Framework, Spring Security and Spring Web Flow. Roo differs from other rapid application development frameworks by focusing on:Spring Batch is a framework for batch processing that provides reusable functions that are essential in processing large volumes of records, including:It also provides more advanced technical services and features that will enable extremely high-volume and high performance batch jobs through optimizations and partitioning techniques. Spring Batch is a framework for batch processing – execution of a series of jobs. In Spring Batch, a job consists of many steps and each step consists of a READ-PROCESS-WRITE task or single operation task (tasklet).The READ-PROCESS-WRITE process consists of these steps: read data from a resource (comma-separated values (CSV), XML, or database), process it, then write it to other resources (CSV, XML, or database). For example, a step may read data from a CSV file, process it, and write it into the database. Spring Batch provides many classes to read/write CSV, XML, and database.For a single operation task (tasklet), it means doing a single task only, like clean up the resources before or after a step is started or completed.And the steps can be chained together to run as a job.Spring Integration is a framework for Enterprise application integration that provides reusable functions essential to messaging or event-driven architectures.Spring Integration supports pipe-and-filter based architectures.The Spring Framework has received some criticism for what some developers perceive to be an over-reliance on XML by Spring's container. Since version 3.0.0, however, developers have been able to specify all or part of an application context through annotations or Java code. Spring Boot makes heavy use of this to minimize the amount of configuration that must be written. Furthermore, the Spring Tool Suite (STS), built on top of Eclipse, provides code-completion, validation, contextual information, and graphical visualizations when editing Spring XML configuration files."
"42"	"Google Guice (pronounced juice) is an open source software framework for the Java platform released by Google under the Apache License.  It provides support for dependency injection using annotations to configure Java objects.  Dependency injection is a design pattern whose core principle is to separate behavior from dependency resolution. Guice allows implementation classes to be bound programmatically to an interface, then injected into constructors, methods or fields using an @Inject annotation.  When more than one implementation of the same interface is needed, the user can create custom annotations that identify an implementation, then use that annotation when injecting it.Being the first generic framework for dependency injection using Java annotations in 2008, Guice won the 18th Jolt Award for best Library, Framework, or Component."
"43"	"Apache License 2.0  WTFPLjspx-bay, commonly referred to as jspx, is a free open source pure Java web RAD framework. Jspx should not be confused with other technologies using the same name like Oracle Application Framework and XML JSP.Jspx extends Java EE servlets to provide an Object-oriented programming model for HTML declarative code. Jspx can be compared to JSF as a web framework. There are many other Java Web frameworks like Apache Wicket that implement such ideas.Jspx development initially started in February 2008 as a trial to provide an easier way to develop rich interactive web applications in Java. In July 2008, jspx was introduced to the Java community through java.net. Initially jspx had very limited features, including support for web form based development only.In December 2008, the project moved to SourceForge, where it has been hosted since.The name was chosen to indicate the next step of JSP technology, despite the fact that jspx is significantly different from JSP in that it does not directly embed Java code in HTML. The suffix X is analogous to ASP.NET pages, which have the extension aspx. The official jspx framework name on sourceforge is jspx-bay. The suffix bay distinguished the framework from an earlier inactive SourceForge project named jspx.On 16 November 2009, the jspx project on SourceForge was purged, and it provides the same content as jspx-bay.Jspx aims at providing easy to use, developer-friendly APIs. Based on the idea that web development is mostly about customizing the HTML that is presented based on user-input, jspx offers an object-oriented view layer interface to HTML. Jspx provides a means of implementing a stateful user interface over a stateless protocol (HTTP). JSF provides similar functionality, but requires that developers learn an entire new set of tags.Jspx is relatively new, and combines many features and advantages from existing frameworks while eliminating what might be considered disadvantages. Jspx had the following design goals:Jspx has the following similarities with ASP.NET:Jspx is different from ASP.NET in the following ways:Jspx is similar to JSF in the following ways:Jspx differs from JSF in the following ways:Jspx can be also compared to many other frameworks, such as Apache Wicket, but jspx uses HTML tags and attributes without an additional XML namespace.As Jspx is a webform-based framework, for each business case there is one development unit. A development unit in a jspx application consists of two parts:In addition, the web.xml file must direct traffic to jspx main servlet controller (RequestHandler).A hello world example can be implemented in many different ways. The following example demonstrates one of them.Note the following about the example above:For the note number 6, the framework is considering using of Dependency Injection to eliminate such limitation and any coupling of HTML and java code.Jspx build 1.0.9 provided new way of linking HTML controls to Java controls in the page controller. The above example showed the need to add getter and setter for each control. This methodology created the following cons:For all these reasons build 1.0.9 is using Java Annotation to link Java objects to HTML. The following example is an alternative to the above one.As noted the size of the code is very much reduced. Also it is noted that the annotation @JspxWebControl is using an attribute name which is an optional attribute. The value of this attribute should be the same as the id of the HTML control. This technique removes the coupling between HTML and Java code.Some consider this new feature an insignificant addition to the framework. They use the JspxBean to link the HTML form to Java Model Object, and do not declare server side controls linked to the HTML controls.JspxBean in build 1.0.9 also has been improved, there is no need to create getter and setter for every JspxBean. Forgetting to add getter and setter was a very common mistake causing the developer to loose the link with the HTML. Dependency Injection is used to inject the JspxBeans without the need for getters and setters.Jspx does not allow Java code inside HTML page. However, in order to satisfy the need of injecting data from the controller; Jspx fully supports Expression Language.Some examples on EL as following:Any framework is evaluated according to different criteria aspects,  the following which jspx needs more improvements.Jspx offers some powerful features like:Jspx tries to minimize external jar dependencies, however there are some essential jars: Jspx had made its first public appearance at Java Developer Conference 2010 (JDC). Java Developer Conference is the largest Java event in MENA, organized by EGJUG.Jspx distribution package includes several files beside the binary jar and the source code. Since the first release on sourceforge the distribution included a demo project as a binary war file and a zipped source code. That project was a simple discrete pages showing different features of Jspx. There was no common business module wrapping these pages, beside it had a poor GUI design. Jspx build 1.1.0 add new demo project that facilitates the easy use of jspx to develop common business case of interacting with DB. The demo is using MySQL. Sql script file is separately downloadable.Some of jspx features are used like Master/Content pages, Ajax, DataTable, Validators and web forms.With Jspx 1.2 there were two new demo projects added. One offline Demo was jspx-demo3, that is demonstrating the use of jspx to create simple asset tracking application. The other demo was an online jspx live demo."
"44"	"In computer programming, a parameter (often called formal parameter or formal argument) is a special kind of variable, used in a subroutine to refer to one of the pieces of data provided as input to the subroutine.[lower-alpha 1] These pieces of data are the values of the arguments (often called actual arguments or actual parameters) with which the subroutine is going to be called/invoked. An ordered list of parameters is usually included in the definition of a subroutine, so that, each time the subroutine is called, its arguments for that call are evaluated, and the resulting values can be assigned to the corresponding parameters.Unlike argument in usual mathematical usage, the argument in computer science is thus the actual input expression passed/supplied to a function, procedure, or routine in the invokation/call statement, whereas the parameter is the variable inside the implementation of the subroutine. For example, if one defines the add subroutine as def add(x, y): return x + y, then x, y are parameters, while if this is called as add(2, 3), then 2, 3 are the arguments. Note that variables (and expressions thereof) from the calling context can be arguments: if the subroutine is called as a = 2; b = 3; add(a, b) then the variables a, b are the arguments, not the values 2, 3. See the Parameters and arguments section for more information.In the most common case, call by value, a parameter acts within the subroutine as a new local variable initialized to the value of the argument (a local (isolated) copy of the argument if the argument is a variable), but in other cases, e.g. call by reference, the argument variable supplied by the caller can be affected by actions within the called subroutine (as discussed in evaluation strategy). The semantics for how parameters can be declared and how the (value of) arguments are passed to the parameters of subroutines are defined by the language, but the details of how this is represented in any particular computer system depend on the calling conventions of that system.The following program in the C programming language defines a function that is named sales_tax and has one parameter named price. The type of price is double (i.e. a double-precision floating point number). The function's return type is also a double.After the function has been defined, it can be invoked as follows:In this example, the function has been invoked with the argument 10.00. When this happens, 10.00 will be assigned to price, and the function begins calculating its result. The steps for producing the result are specified below, enclosed in {}. 0.05 * price indicates that the first thing to do is multiply 0.05 by the value of price, which gives 0.50. return means the function will produce the result of 0.05 * price. Therefore, the final result (ignoring possible round-off errors one encounters with representing decimal fractions in IEEE-754 format) is 0.50.The terms parameter and argument may have different meanings in different programming languages. Sometimes they are used interchangeably, and the context is used to distinguish the meaning.  The term parameter (sometimes called formal parameter) is often used to refer to the variable as found in the function definition, while argument (sometimes called actual parameter) refers to the actual input supplied at function call. For example, if one defines a function as def f(x): ..., then x is the parameter, and if it is called by a = ...; f(a) then a is the argument. A parameter is an (unbound) variable, while the argument can be a value or variable or more complex expression involving values and variables. In case of call by value, what is passed to the function is the value of the argument – for example, f(2) and a = 2; f(a) are equivalent calls – while in call by reference, with a variable as argument, what is passed is a reference to that variable - even though the syntax for the function call could stay the same. The specification for pass-by-reference or pass-by-value would be made in the function declaration and/or definition.Parameters appear in procedure definitions; arguments appear in procedure calls. In the function definition f(x) = x*x the variable x is a parameter; in the function call f(2) the value 2 is the argument of the function. Loosely, a parameter is a type, and an argument is an instance.A parameter is an intrinsic property of the procedure, included in its definition. For example, in many languages, a procedure to add two supplied integers together and calculate the sum would need two parameters, one for each integer. In general, a procedure may be defined with any number of parameters, or no parameters at all. If a procedure has parameters, the part of its definition that specifies the parameters is called its parameter list.By contrast, the arguments are the expressions supplied to the procedure when it is called, usually one expression matching one of the parameters. Unlike the parameters, which form an unchanging part of the procedure's definition, the arguments may vary from call to call. Each time a procedure is called, the part of the procedure call that specifies the arguments is called the argument list.Although parameters are also commonly referred to as arguments, arguments are sometimes thought of as the actual values or references assigned to the parameter variables when the subroutine is called at run-time. When discussing code that is calling into a subroutine, any values or references passed into the subroutine are the arguments, and the place in the code where these values or references are given is the parameter list. When discussing the code inside the subroutine definition, the variables in the subroutine's parameter list are the parameters, while the values of the parameters at runtime are the arguments. For example, in C, when dealing with threads it's common to pass in an argument of type void* and cast it to an expected type:To better understand the difference, consider the following function written in C:The function sum has two parameters, named addend1 and addend2. It adds the values passed into the parameters, and returns the result to the subroutine's caller (using a technique automatically supplied by the C compiler).The code which calls the sum function might look like this:The variables value1 and value2 are initialized with values. value1 and value2 are both arguments to the sum function in this context.At runtime, the values assigned to these variables are passed to the function sum as arguments. In the sum function, the parameters addend1 and addend2 are evaluated, yielding the arguments 40 and 2, respectively. The values of the arguments are added, and the result is returned to the caller, where it is assigned to the variable sumValue.Because of the difference between parameters and arguments, it is possible to supply inappropriate arguments to a procedure. The call may supply too many or too few arguments; one or more of the arguments may be a wrong type; or arguments may be supplied in the wrong order. Any of these situations causes a mismatch between the parameter and argument lists, and the procedure will often return an unintended answer or generate a runtime error.Within the Eiffel software development method and language, the terms argument and parameter have distinct uses established by convention. The term argument is used exclusively in reference to a routine's inputs, and the term parameter is used exclusively in type parameterization for generic classes.Consider the following routine definition:The routine sum takes two arguments addend1 and addend2, which are called the routine's formal arguments.  A call to sum specifies actual arguments, as shown below with value1 and value2.Parameters are also thought of as either formal or actual. Formal generic parameters are used in the definition of generic classes. In the example below, the class HASH_TABLE  is declared as a generic class which has two formal generic parameters, G representing data of interest and K representing the hash key for the data:When a class becomes a client to HASH_TABLE, the formal generic parameters are substituted with actual generic parameters in a generic derivation. In the following attribute declaration, my_dictionary is to be used as a character string based dictionary. As such, both data and key formal generic parameters are substituted with actual generic parameters of type STRING.In strongly typed programming languages, each parameter's type must be specified in the procedure declaration.  Languages using type inference attempt to discover the types automatically from the function's body and usage. Dynamically typed programming languages defer type resolution until run-time. Weakly typed languages perform little to no type resolution, relying instead on the programmer for correctness.Some languages use a special keyword (e.g. void) to indicate that the subroutine has no parameters; in formal type theory, such functions take an empty parameter list (whose type is not void, but rather unit).The exact mechanism for assigning arguments to parameters, called argument passing, depends upon the evaluation strategy used for that parameter (typically call by value), which may be specified using keywords.Some programming languages such as Ada, C++, Clojure, Common Lisp, Fortran 90, Python, Ruby, Tcl, and Windows PowerShell allow for a default argument to be explicitly or implicitly given in a subroutine's declaration. This allows the caller to omit that argument when calling the subroutine. If the default argument is explicitly given, then that value is used if it is not provided by the caller. If the default argument is implicit (sometimes by using a keyword such as Optional) then the language provides a well-known value (such as null, Empty, zero, an empty string, etc.) if a value is not provided by the caller.PowerShell example:Default arguments can be seen as a special case of the variable-length argument list.Some languages allow subroutines to be defined to accept a variable number of arguments. For such languages, the subroutines must iterate through the list of arguments.PowerShell example:Some programming languages—such as Ada and Windows PowerShell—allow subroutines to have named parameters. This allows the calling code to be more self-documenting. It also provides more flexibility to the caller, often allowing the order of the arguments to be changed, or for arguments to be omitted as needed.PowerShell example:In lambda calculus, each function has exactly one parameter. What is thought of as functions with multiple parameters is usually represented in lambda calculus as a function which takes the first argument, and returns a function which takes the rest of the arguments; this is a transformation known as currying. Some programming languages, like ML and Haskell, follow this scheme. In these languages, every function has exactly one parameter, and what may look like the definition of a function of multiple parameters, is actually syntactic sugar for the definition of a function that returns a function, etc. Function application is left-associative in these languages as well as in lambda calculus, so what looks like an application of a function to multiple arguments is correctly evaluated as the function applied to the first argument, then the resulting function applied to the second argument, etc.An output parameter, also known as an out parameter or return parameter, is a parameter used for output, rather than the more usual use for input. Using call by reference parameters, or call by value parameters where the value is a reference, as output parameters is an idiom in some languages, notably C and C++,[lower-alpha 2] while other languages have built-in support for output parameters. Languages with built-in support for output parameters include Ada (see Ada subprograms), Fortran (since Fortran 90; see Fortran intent), various procedural extensions to SQL, such as PL/SQL (see PL/SQL functions) and Transact-SQL, C# and the .NET Framework, and the scripting language TScript (see TScript function declarations).More precisely, one may distinguish three types of parameters or parameter modes: input parameters, output parameters, and input/output parameters; these are often denoted in, out, and in out or inout. An input argument (the argument to an input parameter) must be a value, such as an initialized variable or literal, and must not be redefined or assigned to; an output argument must be an assignable variable, but it need not be initialized, any existing value is not accessible, and must be assigned a value; and an input/output argument must be an initialized, assignable variable, and can optionally be assigned a value. The exact requirements and enforcement vary between languages – for example, in Ada 83 output parameters can only be assigned to, not read, even after assignment (this was removed in Ada 95 to remove the need for an auxiliary accumulator variable). These are analogous to the notion of a value in an expression being an r-value (has a value), an l-value (can be assigned), or an r-value/l-value (has a value and can be assigned), respectively, though these terms have specialized meanings in C.In some cases only input and input/output are distinguished, with output being considered a specific use of input/output, and in other cases only input and output (but not input/output) are supported. The default mode varies between languages: in Fortran 90 input/output is default, while in C# and SQL extensions input is default, and in TScript each parameter is explicitly specified as input or output.Syntactically, parameter mode is generally indicated with a keyword in the function declaration, such as void f(out int x) in C#. Conventionally output parameters are often put at the end of the parameter list to clearly distinguish them, though this is not always followed. TScript uses a different approach, where in the function declaration input parameters are listed, then output parameters, separated by a colon (:) and there is no return type to the function itself, as in this function, which computes the size of a text fragment:Parameter modes are a form of denotational semantics, stating the programmer's intent and allowing compilers to catch errors and apply optimizations – they do not necessarily imply operational semantics (how the parameter passing actually occurs). Notably, while input parameters can be implemented by call by value, and output and input/output parameters by call by reference – and this is a straightforward way to implement these modes in languages without built-in support – this is not always how they are implemented. This distinction is discussed in detail in the Ada '83 Rationale, which emphasizes that the parameter mode is abstracted from which parameter passing mechanism (by reference or by copy) is actually implemented. For instance, while in C# input parameters (default, no keyword) are passed by value, and output and input/output parameters (out and ref) are passed by reference, in PL/SQL input parameters (IN) are passed by reference, and output and input/output parameters (OUT and IN OUT) are by default passed by value and the result copied back, but can be passed by reference by using the NOCOPY compiler hint.A syntactically similar construction to output parameters is to assign the return value to a variable with the same name as the function. This is found in Pascal and Fortran 66 and Fortran 77, as in this Pascal example:This is semantically different in that when called, the function is simply evaluated – it is not passed a variable from the calling scope to store the output in.The primary use of output parameters is to return multiple values from a function, while the use of input/output parameters is to modify state using parameter passing (rather than by shared environment, as in global variables). An important use of returning multiple values is to solve the semipredicate problem of returning both a value and an error status – see Semipredicate problem: Multivalued return.For example, to return two variables from a function in C, one may write:where x is an input parameter and width and height are output parameters, passed by reference.A common use case in C and related languages is for exception handling, where a function places the return value in an output variable, and returns a boolean corresponding to whether the function succeeded or not. An archetypal example is the TryParse method in .NET, especially C#, which parses a string into an integer, returning true on success and false on failure. This has the following signature:and may be used as follows:Similar considerations apply to returning a value of one of several possible types, where the return value can specify the type and then value is stored in one of several output variables.Another use is as a micro-optimization, to avoid assigning a local variable in a function and then needing to copy it when returning. This can be done when output parameters are implemented by call by reference. For example, in C++, instead of the more usual:one might instead write:so the function f does not need to assign space for the object or copy it on returning.Output parameters are often discouraged in modern programming, essentially as being awkward, confusing, and too low-level – commonplace return values are considerably easier to understand and work with. Notably, output parameters involve functions with side effects (modifying the output parameter) and are semantically similar to references, which are more confusing than pure functions and values, and the distinction between output parameters and input/output parameters can be subtle. Further, since in common programming styles most parameters are simply input parameters, output parameters and input/output parameters are unusual and hence susceptible to misunderstanding.Output and input/output parameters prevent function composition, since the output is stored in variables, rather than in the value of an expression. Thus one must initially declare a variable, and then each step of a chain of functions must be a separate statement. For example, in C++ the following function composition:when written with output and input/output parameters instead becomes (for f it is an output parameter, for g an input/output parameter):In the special case of a function with a single output or input/output parameter and no return value, function composition is possible if the output or input/output parameter (or in C/C++, its address) is also returned by the function, in which case the above becomes:There are various alternatives to the use cases of output parameters.For returning multiple values from a function, an alternative is to return a tuple. Syntactically this is clearer if automatic sequence unpacking and parallel assignment can be used, as in Go or Python, such as:For returning a value of one of several types, a tagged union can be used instead; the most common cases are nullable types (option types), where the return value can be null to indicate failure. For exception handling, one can return a nullable type, or raise an exception. For example, in Python one might have either:or, more idiomatically:The micro-optimization of not requiring a local variable and copying the return when using output variables can also be applied to conventional functions and return values by sufficiently sophisticated compilers.The usual alternative to output parameters in C and related languages is to return a single data structure containing all return values. For example, given a structure encapsulating width and height, one can write:In object-oriented languages, instead of using input/output parameters, one can often use call by sharing, passing a reference to an object and then mutating the object, though not changing which object the variable refers to."
"45"	" (Learn how and when to remove this template message)C++11 is a version of the standard for the programming language C++. It was approved by International Organization for Standardization (ISO) on 12 August 2011, replacing C++03, superseded by C++14 on 18 August 2014 and later, by C++17. The name follows the tradition of naming language versions by the publication year of the specification, though it was formerly named C++0x because it was expected to be published before 2010.Although one of the design goals was to prefer changes to the libraries over changes to the core language,  C++11 does make several additions to the core language. Areas of the core language that were significantly improved include multithreading support, generic programming support, uniform initialization, and performance. Significant changes were also made to the C++ Standard Library, incorporating most of the C++ Technical Report 1 (TR1) libraries, except the library of mathematical special functions.C++11 was published as ISO/IEC 14882:2011 in September 2011 and is available for a fee. The working draft most similar to the published C++11 standard is N3337, dated 16 January 2012; it has only editorial corrections from the C++11 standard.The design committee attempted to stick to a number of goals in designing C++11:Attention to beginners is considered important, because most computer programmers will always be such, and because many beginners never widen their knowledge, limiting themselves to work in aspects of the language in which they specialize.One function of the C++ committee is the development of the language core. Areas of the core language that were significantly improved include multithreading support, generic programming support, uniform initialization, and performance.These language features primarily exist to provide some kind of performance benefit, either of memory or of computational speed.[citation needed]In C++03 (and before), temporaries (termed rvalues, as they often lie on the right side of an assignment) were intended to never be modifiable — just as in C — and were considered to be indistinguishable from const T& types; nevertheless, in some cases, temporaries could have been modified, a behavior that was even considered to be a useful loophole. C++11 adds a new non-const reference type called an rvalue reference, identified by T&&. This refers to temporaries that are permitted to be modified after they are initialized, for the purpose of allowing move semantics.A chronic performance problem with C++03 is the costly and unneeded deep copies that can happen implicitly when objects are passed by value. To illustrate the issue, consider that an std::vector<T> is, internally, a wrapper around a C-style array with a size.  If an std::vector<T> temporary is created or returned from a function, it can be stored only by creating a new std::vector<T> and copying all the rvalue's data into it.  Then the temporary and all its memory is destroyed. (For simplicity, this discussion neglects the return value optimization.)In C++11, a move constructor of std::vector<T> that takes an rvalue reference to an std::vector<T> can copy the pointer to the internal C-style array out of the rvalue into the new std::vector<T>, then set the pointer inside the rvalue to null.  Since the temporary will never again be used, no code will try to access the null pointer, and because the pointer is null, its memory is not deleted when it goes out of scope.  Hence, the operation not only forgoes the expense of a deep copy, but is safe and invisible.Rvalue references can provide performance benefits to existing code without needing to make any changes outside the standard library.  The type of the returned value of a function returning an std::vector<T> temporary does not need to be changed explicitly to std::vector<T> && to invoke the move constructor, as temporaries are considered rvalues automatically.  (However, if std::vector<T> is a C++03 version without a move constructor, then the copy constructor will be invoked with an const std::vector<T>&, incurring a significant memory allocation.)For safety reasons, some restrictions are imposed.  A named variable will never be considered to be an rvalue even if it is declared as such. To get an rvalue, the function template std::move() should be used.  Rvalue references can also be modified only under certain circumstances, being intended to be used primarily with move constructors.Due to the nature of the wording of rvalue references, and to some modification to the wording for lvalue references (regular references), rvalue references allow developers to provide perfect function forwarding. When combined with variadic templates, this ability allows for function templates that can perfectly forward arguments to another function that takes those particular arguments. This is most useful for forwarding constructor parameters, to create factory functions that will automatically call the correct constructor for those particular arguments. This is seen in the emplace_back set of the C++ standard library methods.C++ has always had the concept of constant expressions. These are expressions such as 3+4 that will always yield the same results, at compile time and at run time. Constant expressions are optimization opportunities for compilers, and compilers frequently execute them at compile time and hardcode the results in the program. Also, in several places, the C++ specification requires using constant expressions. Defining an array requires a constant expression, and enumerator values must be constant expressions.However, a constant expression has never been allowed to contain a function call or object constructor. So a piece of code as simple as this is invalid:This was not valid in C++03, because get_five() + 7 is not a constant expression. A C++03 compiler has no way of knowing if get_five() actually is constant at runtime. In theory, this function could affect a global variable, call other non-runtime constant functions, etc.C++11 introduced the keyword constexpr, which allows the user to guarantee that a function or object constructor is a compile-time constant. The above example can be rewritten as follows:This allows the compiler to understand, and verify, that get_five() is a compile-time constant.Using constexpr on a function imposes some limits on what that function can do. First, the function must have a non-void return type. Second, the function body cannot declare variables or define new types. Third, the body may contain only declarations, null statements and a single return statement. There must exist argument values such that, after argument substitution, the expression in the return statement produces a constant expression.Before C++11, the values of variables could be used in constant expressions only if the variables are declared const, have an initializer which is a constant expression, and are of integral or enumeration type. C++11 removes the restriction that the variables must be of integral or enumeration type if they are defined with the constexpr keyword:Such data variables are implicitly const, and must have an initializer which must be a constant expression.To construct constant expression data values from user-defined types, constructors can also be declared with constexpr. A constexpr constructor's function body can contain only declarations and null statements, and cannot declare variables or define types, as with a constexpr function. There must exist argument values such that, after argument substitution, it initializes the class's members with constant expressions. The destructors for such types must be trivial.The copy constructor for a type with any constexpr constructors should usually also be defined as a constexpr constructor, to allow objects of the type to be returned by value from a constexpr function. Any member function of a class, such as copy constructors, operator overloads, etc., can be declared as constexpr, so long as they meet the requirements for constexpr functions. This allows the compiler to copy objects at compile time, perform operations on them, etc.If a constexpr function or constructor is called with arguments which aren't constant expressions, the call behaves as if the function were not constexpr, and the resulting value is not a constant expression. Likewise, if the expression in the return statement of a constexpr function does not evaluate to a constant expression for a given invocation, the result is not a constant expression.In C++03, a class or struct must follow a number of rules for it to be considered a plain old data (POD) type. Types that fit this definition produce object layouts that are compatible with C, and they could also be initialized statically. The C++03 standard has restrictions on what types are compatible with C or can be statically initialized despite there being no technical reason a compiler couldn't accept the program; if someone were to create a C++03 POD type and add a non-virtual member function, this type would no longer be a POD type, could not be statically initialized, and would be incompatible with C despite no change to the memory layout.C++11 relaxed several of the POD rules, by dividing the POD concept into two separate concepts: trivial and standard-layout.A type that is trivial can be statically initialized. It also means that it is valid to copy data around via memcpy, rather than having to use a copy constructor. The lifetime of a trivial type begins when its storage is defined, not when a constructor completes.A trivial class or struct is defined as one that:Constructors are trivial only if there are no virtual member functions of the class and no virtual base classes. Copy/move operations also require all non-static data members to be trivial.A type that is standard-layout means that it orders and packs its members in a way that is compatible with C. A class or struct is standard-layout, by definition, provided:A class/struct/union is considered POD if it is trivial, standard-layout, and all of its non-static data members and base classes are PODs.By separating these concepts, it becomes possible to give up one without losing the other. A class with complex move and copy constructors may not be trivial, but it could be standard-layout and thus interoperate with C. Similarly, a class with public and private non-static data members would not be standard-layout, but it could be trivial and thus memcpy-able.In C++03, the compiler must instantiate a template whenever a fully specified template is encountered in a translation unit. If the template is instantiated with the same types in many translation units, this can dramatically increase compile times.  There is no way to prevent this in C++03, so C++11 introduced extern template declarations, analogous to extern data declarations.C++03 has this syntax to oblige the compiler to instantiate a template:C++11 now provides this syntax:which tells the compiler not to instantiate the template in this translation unit.These features exist for the primary purpose of making the language easier to use. These can improve type safety, minimize code repetition, make erroneous code less likely, etc.C++03 inherited the initializer-list feature from C. A struct or array is given a list of arguments in braces, in the order of the members' definitions in the struct. These initializer-lists are recursive, so an array of structs or struct containing other structs can use them.This is very useful for static lists, or initializing a struct to some value. C++ also provides constructors to initialize an object, but they are often not as convenient as the initializer list. However, C++03 allows initializer-lists only on structs and classes that conform to the Plain Old Data (POD) definition; C++11 extends initializer-lists, so they can be used for all classes including standard containers like std::vector.C++11 binds the concept to a template, called std::initializer_list. This allows constructors and other functions to take initializer-lists as parameters. For example:This allows SequenceClass to be constructed from a sequence of integers, such as:This constructor is a special kind of constructor, called an initializer-list-constructor. Classes with such a constructor are treated specially during uniform initialization (see below)The class std::initializer_list<> is a first-class C++11 standard library type. However, they can be initially constructed statically by the C++11 compiler only via use of the {} syntax. The list can be copied once constructed, though this is only a copy-by-reference. An initializer list is constant; its members cannot be changed once the initializer list is created, nor can the data in those members be changed.Because initializer_list is a real type, it can be used in other places besides class constructors. Regular functions can take typed initializer lists as arguments. For example:Standard containers can also be initialized in these ways:C++03 has a number of problems with initializing types. Several ways to do this exist, and some produce different results when interchanged. The traditional constructor syntax, for example, can look like a function declaration, and steps must be taken to ensure that the compiler's most vexing parse rule will not mistake it for such. Only aggregates and POD types can be initialized with aggregate initializers (using SomeType var = {/*stuff*/};).C++11 provides a syntax that allows for fully uniform type initialization that works on any object. It expands on the initializer list syntax:The initialization of var1 behaves exactly as though it were aggregate-initialization. That is, each data member of an object, in turn, will be copy-initialized with the corresponding value from the initializer-list. Implicit type conversion will be used where needed. If no conversion exists, or only a narrowing conversion exists, the program is ill-formed. The initialization of var2 invokes the constructor.One can also do this:Uniform initialization does not replace constructor syntax, which is still needed at times. If a class has an initializer list constructor (TypeName(initializer_list<SomeType>);), then it takes priority over other forms of construction, provided that the initializer list conforms to the sequence constructor's type. The C++11 version of std::vector has an initializer list constructor for its template type. Thus this code:will call the initializer list constructor, not the constructor of std::vector that takes a single size parameter and creates the vector with that size. To access the latter constructor, the user will need to use the standard constructor syntax directly.In C++03 (and C), to use a variable, its type must be specified explicitly. However, with the advent of template types and template metaprogramming techniques, the type of something, particularly the well-defined return value of a function, may not be easily expressed. Thus, storing intermediates in variables is difficult, possibly needing knowledge of the internals of a given metaprogramming library.C++11 allows this to be mitigated in two ways. First, the definition of a variable with an explicit initialization can use the auto keyword. This creates a variable of the specific type of the initializer:The type of some_strange_callable_type is simply whatever the particular template function override of std::bind returns for those particular arguments. This type is easily determined procedurally by the compiler as part of its semantic analysis duties, but is not easy for the user to determine upon inspection.The type of other_variable is also well-defined, but it is easier for the user to determine. It is an int, which is the same type as the integer literal.Further, the keyword decltype can be used to determine the type of expression at compile-time. For example:This is more useful in conjunction with auto, since the type of auto variable is known only to the compiler. However, decltype can also be very useful for expressions in code that makes heavy use of operator overloading and specialized types.auto is also useful for reducing the verbosity of the code. For instance, instead of writingthe programmer can use the shorterwhich can be further compacted since myvec implements begin/end iterators:This difference grows as the programmer begins to nest containers, though in such cases typedefs are a good way to decrease the amount of code.The type denoted by decltype can be different from the type deduced by auto.C++11 extends the syntax of the for statement to allow for easy iteration over a range of elements:This form of for, called the “range-based for”, will iterate over each element in the list. It will work for C-style arrays, initializer lists, and any type that has begin() and end() functions defined for it that return iterators. All the standard library containers that have begin/end pairs will work with the range-based for statement.C++11 provides the ability to create anonymous functions, called lambda functions. These are defined as follows:The return type (-> int in this example) can be omitted as long as all return expressions return the same type. A lambda can optionally be a closure.Standard C function declaration syntax was perfectly adequate for the feature set of the C language. As C++ evolved from C, it kept the basic syntax and extended it where needed. However, as C++ grew more complex, it exposed several limits, especially regarding template function declarations. For example, in C++03 this is disallowed:The type Ret is whatever the addition of types Lhs and Rhs will produce. Even with the aforementioned C++11 functionality of decltype, this is not possible:This is not valid C++ because lhs and rhs have not yet been defined; they will not be valid identifiers until after the parser has parsed the rest of the function prototype.To work around this, C++11 introduced a new function declaration syntax, with a trailing-return-type:This syntax can be used for more mundane function declarations and definitions:Use of the keyword “auto” in this case is only part of the syntax and does not perform automatic type deduction.In C++03, constructors of a class are not allowed to call other constructors in an initializer list of that class. Each constructor must construct all of its class members itself or call a common member function, as follows:Constructors for base classes cannot be directly exposed to derived classes; each derived class must implement constructors even if a base class constructor would be appropriate. Non-constant data members of classes cannot be initialized at the site of the declaration of those members. They can be initialized only in a constructor.C++11 provides solutions to all of these problems.C++11 allows constructors to call other peer constructors (termed delegation).  This allows constructors to utilize another constructor's behavior with a minimum of added code. Delegation has been used in other languages e.g., Java, Objective-C.This syntax is as follows:Notice that, in this case, the same effect could have been achieved by making new_number a defaulting parameter.  The new syntax, however, allows the default value (42) to be expressed in the implementation rather than the interface — a benefit to maintainers of library code since default values for function parameters are “baked in” to call sites, whereas constructor delegation allows the value to be changed without recompilation of the code using the library.This comes with a caveat: C++03 considers an object to be constructed when its constructor finishes executing, but C++11 considers an object constructed once any constructor finishes execution. Since multiple constructors will be allowed to execute, this will mean that each delegating constructor will be executing on a fully constructed object of its own type. Derived class constructors will execute after all delegation in their base classes is complete.For base-class constructors, C++11 allows a class to specify that base class constructors will be inherited. Thus, the C++11 compiler will generate code to perform the inheritance and the forwarding of the derived class to the base class. This is an all-or-nothing feature: either all of that base class's constructors are forwarded or none of them are. Also, an inherited constructor will be shadowed if it matches the signature of a constructor of the derived class, and restrictions exist for multiple inheritance: class constructors cannot be inherited from two classes that use constructors with the same signature.The syntax is as follows:For member initialization, C++11 allows this syntax:Any constructor of the class will initialize value with 5, if the constructor does not override the initialization with its own. So the above empty constructor will initialize value as the class definition states, but the constructor that takes an int will initialize it to the given parameter.It can also use constructor or uniform initialization, instead of the assignment initialization shown above.In C++03, it is possible to accidentally create a new virtual function, when one intended to override a base class function. For example:Suppose the Derived::some_func is intended to replace the base class version. But instead, because it has a different signature, it creates a second virtual function. This is a common problem, particularly when a user goes to modify the base class.C++11 provides syntax to solve this problem.The override special identifier means that the compiler will check the base class(es) to see if there is a virtual function with this exact signature. And if there is not, the compiler will indicate an error.C++11 also adds the ability to prevent inheriting from classes or simply preventing overriding methods in derived classes. This is done with the special identifier final. For example:In this example, the virtual void f() final; statement declares a new virtual function, but it also prevents derived classes from overriding it. It also has the effect of preventing derived classes from using that particular function name and parameter combination.Note that neither override nor final are language keywords. They are technically identifiers for declarator attributes:For the purposes of this section and this section alone, every occurrence of “0” is meant as “a constant expression which evaluates to 0, which is of type int”. In reality, the constant expression can be of any integral type.Since the dawn of C in 1972, the constant 0 has had the double role of constant integer and null pointer constant. The ambiguity inherent in the double meaning of 0 was dealt with in C by using the preprocessor macro NULL, which commonly expands to either ((void*)0) or 0. C++ forbids implicit conversion from void * to other pointer types, thus removing the benefit of casting 0 to void *. As a consequence, only 0 is allowed as a null pointer constant. This interacts poorly with function overloading:If NULL is defined as 0 (which is usually the case in C++), the statement foo(NULL); will call foo(int), which is almost certainly not what the programmer intended, and not what a superficial reading of the code suggests.C++11 corrects this by introducing a new keyword to serve as a distinguished null pointer constant: nullptr. It is of type nullptr_t, which is implicitly convertible and comparable to any pointer type or pointer-to-member type. It is not implicitly convertible or comparable to integral types, except for bool. While the original proposal specified that an rvalue of type nullptr_t should not be convertible to bool, the core language working group decided that such a conversion would be desirable, for consistency with regular pointer types. The proposed wording changes were unanimously voted into the Working Paper in June 2008.For backwards compatibility reasons, 0 remains a valid null pointer constant.In C++03, enumerations are not type-safe. They are effectively integers, even when the enumeration types are distinct. This allows the comparison between two enum values of different enumeration types. The only safety that C++03 provides is that an integer or a value of one enum type does not convert implicitly to another enum type. Further, the underlying integral type is implementation-defined; code that depends on the size of the enumeration is thus non-portable. Lastly, enumeration values are scoped to the enclosing scope. Thus, it is not possible for two separate enumerations in the same scope to have matching member names.C++11 allows a special classification of enumeration that has none of these issues. This is expressed using the enum class (enum struct is also accepted as a synonym) declaration:This enumeration is type-safe. Enum class values are not implicitly converted to integers. Thus, they cannot be compared to integers either (the expression Enumeration::Val4 == 101 gives a compile error).The underlying type of enum classes is always known. The default type is int; this can be overridden to a different integral type as can be seen in this example:With old-style enumerations the values are placed in the outer scope. With new-style enumerations they are placed within the scope of the enum class name. So in the above example, Val1 is undefined, but Enum2::Val1 is defined.There is also a transitional syntax to allow old-style enumerations to provide explicit scoping, and the definition of the underlying type:In this case the enumerator names are defined in the enumeration's scope (Enum3::Val1), but for backwards compatibility they are also placed in the enclosing scope.Forward-declaring enums are also possible in C++11. Formerly, enum types could not be forward-declared because the size of the enumeration depends on the definition of its members. As long as the size of the enumeration is specified either implicitly or explicitly, it can be forward-declared:C++03's parser defines “>>” as the right shift operator or stream extraction operator in all cases. However, with nested template declarations, there is a tendency for the programmer to neglect to place a space between the two right angle brackets, thus causing a compiler syntax error.C++11 improves the specification of the parser so that multiple right angle brackets will be interpreted as closing the template argument list where it is reasonable. This can be overridden by using parentheses around parameter expressions using the “>”, “>=” or “>>” binary operators:C++98 added the explicit keyword as a modifier on constructors to prevent single-argument constructors from being used as implicit type conversion operators. However, this does nothing for actual conversion operators. For example, a smart pointer class may have an operator bool() to allow it to act more like a primitive pointer: if it includes this conversion, it can be tested with if (smart_ptr_variable) (which would be true if the pointer was non-null and false otherwise). However, this allows other, unintended conversions as well. Because C++ bool is defined as an arithmetic type, it can be implicitly converted to integral or even floating-point types, which allows for mathematical operations that are not intended by the user.In C++11, the explicit keyword can now be applied to conversion operators. As with constructors, it prevents using those conversion functions in implicit conversions. However, language contexts that specifically need a boolean value (the conditions of if-statements and loops, and operands to the logical operators) count as explicit conversions and can thus use a bool conversion operator.For example, this feature solves cleanly the safe bool issue.In C++03, it is possible to define a typedef only as a synonym for another type, including a synonym for a template specialization with all actual template arguments specified. It is not possible to create a typedef template. For example:This will not compile.C++11 adds this ability with this syntax:The using syntax can be also used as type aliasing in C++11:In C++03, there are restrictions on what types of objects can be members of a union. For example, unions cannot contain any objects that define a non-trivial constructor or destructor. C++11 lifts some of these restrictions.If a union member has a non trivial special member function, the compiler will not generate the equivalent member function for the union and it must be manually defined.This is a simple example of a union permitted in C++11:The changes will not break any existing code since they only relax current rules.These features allow the language to do things that were formerly impossible, exceedingly verbose, or needed non-portable libraries.In C++11, templates can take variable numbers of template parameters. This also allows the definition of type-safe variadic functions.C++03 offers two kinds of string literals. The first kind, contained within double quotes, produces a null-terminated array of type const char. The second kind, defined as L, produces a null-terminated array of type const wchar_t, where wchar_t is a wide-character of undefined size and semantics. Neither literal type offers support for string literals with UTF-8, UTF-16, or any other kind of Unicode encodings.The definition of the type char has been modified to explicitly express that it's at least the size needed to store an eight-bit coding of UTF-8, and large enough to contain any member of the compiler's basic execution character set. It was formerly defined as only the latter in the C++ standard itself, then relying on the C standard to guarantee at least 8 bits.C++11 supports three Unicode encodings: UTF-8, UTF-16, and UTF-32. Along with the formerly noted changes to the definition of char, C++11 adds two new character types: char16_t and char32_t. These are designed to store UTF-16 and UTF-32 respectively.Creating string literals for each of these encodings can be done thusly:The type of the first string is the usual const char[]. The type of the second string is const char16_t[] (note lower case 'u' prefix). The type of the third string is const char32_t[] (upper case 'U' prefix).When building Unicode string literals, it is often useful to insert Unicode codepoints directly into the string. To do this, C++11 allows this syntax:The number after the \u is a hexadecimal number; it does not need the usual 0x prefix. The identifier \u represents a 16-bit Unicode codepoint; to enter a 32-bit codepoint, use \U and a 32-bit hexadecimal number. Only valid Unicode codepoints can be entered. For example, codepoints on the range U+D800–U+DFFF are forbidden, as they are reserved for surrogate pairs in UTF-16 encodings.It is also sometimes useful to avoid escaping strings manually, particularly for using literals of XML files, scripting languages, or regular expressions. C++11 provides a raw string literal:In the first case, everything between the ( and the ) is part of the string. The  and \ characters do not need to be escaped. In the second case, the delimiter( starts the string, and it ends only when )delimiter is reached. The string delimiter can be any string up to 16 characters in length, including the empty string. This string cannot contain spaces, control characters, (, ), or the \ character. Using this delimiter string allows the user to have ) characters within raw string literals. For example, Rdelimiter((a-z))delimiter is equivalent to (a-z).Raw string literals can be combined with the wide literal or any of the Unicode literal prefixes:C++03 provides a number of literals. The characters 12.5 are a literal that is resolved by the compiler as a type double with the value of 12.5. However, the addition of the suffix f, as in 12.5f, creates a value of type float that contains the value 12.5. The suffix modifiers for literals are fixed by the C++ specification, and C++03 code cannot create new literal modifiers.By contrast, C++11 enables the user to define new kinds of literal modifiers that will construct objects based on the string of characters that the literal modifies.Transformation of literals is redefined into two distinct phases: raw and cooked. A raw literal is a sequence of characters of some specific type, while the cooked literal is of a separate type. The C++ literal 1234, as a raw literal, is this sequence of characters '1', '2', '3', '4'. As a cooked literal, it is the integer 1234. The C++ literal 0xA in raw form is '0', 'x', 'A', while in cooked form it is the integer 10.Literals can be extended in both raw and cooked forms, with the exception of string literals, which can be processed only in cooked form. This exception is due to the fact that strings have prefixes that affect the specific meaning and type of the characters in question.All user-defined literals are suffixes; defining prefix literals is not possible.  All suffixes starting with any character except underscore (_) are reserved by the standard. Thus, all user-defined literals must have suffixes starting with an underscore (_).User-defined literals processing the raw form of the literal are defined via a literal operator, which is written as operator . An example follows:The assignment statement OutputType some_variable = 1234_mysuffix; executes the code defined by the user-defined literal function. This function is passed 1234 as a C-style string, so it has a null terminator.An alternative mechanism for processing integer and floating point raw literals is via a variadic template:This instantiates the literal processing function as operator  _tuffix<'1', '2', '3', '4'>(). In this form, there is no null character terminating the string. The main purpose for doing this is to use C++11's constexpr keyword to ensure that the compiler will transform the literal entirely at compile time, assuming OutputType is a constexpr-constructible and copyable type, and the literal processing function is a constexpr function.For numeric literals, the type of the cooked literal is either unsigned long long for integral literals or long double for floating point literals. (Note: There is no need for signed integral types because a sign-prefixed literal is parsed as an expression containing the sign as a unary prefix operator and the unsigned number.) There is no alternative template form:In accord with the formerly mentioned new string prefixes, for string literals, these are used:There is no alternative template form. Character literals are defined similarly.C++11 standardizes support for multithreaded programming.There are two parts involved: a memory model which allows multiple threads to co-exist in a program and library support for interaction between threads. (See this article's section on threading facilities.)The memory model defines when multiple threads may access the same memory location, and specifies when updates by one thread become visible to other threads.In a multi-threaded environment, it is common for every thread to have some unique variables. This already happens for the local variables of a function, but it does not happen for global and static variables.A new thread-local storage duration (in addition to the existing static, dynamic and automatic) is indicated by the storage specifier thread_local.Any object which could have static storage duration (i.e., lifetime spanning the entire execution of the program) may be given thread-local duration instead. The intent is that like any other static-duration variable, a thread-local object can be initialized using a constructor and destroyed using a destructor.In C++03, the compiler provides, for classes that do not provide them for themselves, a default constructor, a copy constructor, a copy assignment operator (operator=), and a destructor. The programmer can override these defaults by defining custom versions. C++ also defines several global operators (such as operator new) that work on all classes, which the programmer can override.However, there is very little control over creating these defaults. Making a class inherently non-copyable, for example, requires declaring a private copy constructor and copy assignment operator and not defining them. Attempting to use these functions is a violation of the One Definition Rule (ODR). While a diagnostic message is not required, violations may result in a linker error.In the case of the default constructor, the compiler will not generate a default constructor if a class is defined with any constructors. This is useful in many cases, but it is also useful to be able to have both specialized constructors and the compiler-generated default.C++11 allows the explicit defaulting and deleting of these special member functions. For example, this type explicitly declares that it is using the default constructor:Alternatively, certain features can be explicitly disabled. For example, this type is non-copyable:The = delete specifier can be used to prohibit calling any function, which can be used to disallow calling a member function with particular parameters. For example:An attempt to call f() with an int will be rejected by the compiler, instead of performing a silent conversion to double. This can be generalized to disallow calling the function with any type other than double as follows:In C++03, the largest integer type is long int. It is guaranteed to have at least as many usable bits as int. This resulted in long int having size of 64 bits on some popular implementations and 32 bits on others. C++11 adds a new integer type long long int to address this issue. It is guaranteed to be at least as large as a long int, and have no fewer than 64 bits. The type was originally introduced by C99 to the standard C, and most C++ compilers supported it as an extension already.C++03 provides two methods to test assertions: the macro assert and the preprocessor directive #error. However, neither is appropriate for use in templates: the macro tests the assertion at execution-time, while the preprocessor directive tests the assertion during preprocessing, which happens before instantiation of templates. Neither is appropriate for testing properties that are dependent on template parameters.The new utility introduces a new way to test assertions at compile-time, using the new keyword static_assert. The declaration assumes this form:Here are some examples of how static_assert can be used:When the constant expression is false the compiler produces an error message. The first example is similar to the preprocessor directive #error, although the preprocessor does only support integral types. In contrast, in the second example the assertion is checked at every instantiation of the template class Check.Static assertions are useful outside of templates also. For instance, a given implementation of an algorithm might depend on the size of a long long being larger than an int, something the standard does not guarantee. Such an assumption is valid on most systems and compilers, but not all.In C++03, the sizeof operator can be used on types and objects. But it cannot be used to do this:This should return the size of OtherType. C++03 disallows this, so it is a compile error. C++11 allows it. It is also allowed for the alignof operator introduced in C++11.C++11 allows variable alignment to be queried and controlled with alignof and alignas.The alignof operator takes the type and returns the power of 2 byte boundary on which the type instances must be allocated (as a std::size_t).  When given a reference type alignof returns the referenced type's alignment; for arrays it returns the element type's alignment.The alignas specifier controls the memory alignment for a variable. The specifier takes a constant or a type; when supplied a type alignas(T) is shorthand for alignas(alignof(T)).  For example, to specify that a char array should be properly aligned to hold a float:Prior C++ standards provided for programmer-driven garbage collection via set_new_handler, but gave no definition of object reachability for the purpose of automatic garbage collection. C++11 defines conditions under which pointer values are safely derived from other values. An implementation may specify that it operates under strict pointer safety, in which case pointers that are not derived according to these rules can become invalid.C++11 provides a standardized syntax for compiler/tool extensions to the language. Such extensions were traditionally specified using #pragma directive or vendor-specific keywords (like __attribute__ for GNU and __declspec for Microsoft). With the new syntax, added information can be specified in a form of an attribute enclosed in double square brackets. An attribute can be applied to various elements of source code:In the example above, attribute attr1 applies to the type of variable i, attr2 and attr3 apply to the variable itself, attr4 applies to the if statement and vendor::attr5 applies to the return statement. In general (but with some exceptions), an attribute specified for a named entity is placed after the name, and before the entity otherwise, as shown above, several attributes may be listed inside one pair of double square brackets, added arguments may be provided for an attribute, and attributes may be scoped by vendor-specific attribute namespaces.It is recommended that attributes have no language semantic meaning and do not change the sense of a program when ignored. Attributes can be useful for providing information that, for example, helps the compiler to issue better diagnostics or optimize the generated code.C++11 provides two standard attributes itself: noreturn to specify that a function does not return, and carries_dependency to help optimizing multi-threaded code by indicating that function arguments or return value carry a dependency.[clarification needed]A number of new features were introduced in the C++11 standard library. Many of these could have been implemented under the old standard, but some rely (to a greater or lesser extent) on new C++11 core features.A large part of the new libraries was defined in the document C++ Standards Committee's Library Technical Report (called TR1), which was published in 2005. Various full and partial implementations of TR1 are currently available using the namespace std::tr1. For C++11 they were moved to namespace std. However, as TR1 features were brought into the C++11 standard library, they were upgraded where appropriate with C++11 language features that were not available in the initial TR1 version. Also, they may have been enhanced with features that were possible under C++03, but were not part of the original TR1 specification.C++11 offers a number of new language features that the currently existing standard library components can benefit from. For example, most standard library containers can benefit from Rvalue reference based move constructor support, both for quickly moving heavy containers around and for moving the contents of those containers to new memory locations. The standard library components were upgraded with new C++11 language features where appropriate. These include, but are not necessarily limited to:Further, much time has passed since the prior C++ standard. Much code using the standard library has been written. This has revealed parts of the standard libraries that could use some improving. Among the many areas of improvement considered were standard library allocators. A new scope-based model of allocators was included in C++11 to supplement the prior model.While the C++03 language provides a memory model that supports threading, the primary support for actually using threading comes with the C++11 standard library.A thread class (std::thread) is provided, which takes a function object (and an optional series of arguments to pass to it) to run in the new thread. It is possible to cause a thread to halt until another executing thread completes, providing thread joining support via the std::thread::join() member function. Access is provided, where feasible, to the underlying native thread object(s) for platform-specific operations by the std::thread::native_handle() member function.For synchronization between threads, appropriate mutexes (std::mutex, std::recursive_mutex, etc.) and condition variables (std::condition_variable and std::condition_variable_any) are added to the library. These are accessible via Resource Acquisition Is Initialization (RAII) locks (std::lock_guard and std::unique_lock) and locking algorithms for easy use.For high-performance, low-level work, communicating between threads is sometimes needed without the overhead of mutexes. This is done using atomic operations on memory locations. These can optionally specify the minimum memory visibility constraints needed for an operation.  Explicit memory barriers may also be used for this purpose.The C++11 thread library also includes futures and promises for passing asynchronous results between threads, and std::packaged_task for wrapping up a function call that can generate such an asynchronous result. The futures proposal was criticized because it lacks a way to combine futures and check for the completion of one promise inside a set of promises.Further high-level threading facilities such as  thread pools have been remanded to a future C++ technical report. They are not part of C++11, but their eventual implementation is expected to be built entirely on top of the thread library features.The new std::async facility provides a convenient method of running tasks and tying them to a std::future. The user can choose whether the task is to be run asynchronously on a separate thread or synchronously on a thread that waits for the value. By default, the implementation can choose, which provides an easy way to take advantage of hardware concurrency without oversubscription, and provides some of the advantages of a thread pool for simple usages.Tuples are collections composed of heterogeneous objects of pre-arranged dimensions. A tuple can be considered a generalization of a struct's member variables.The C++11 version of the TR1 tuple type benefited from C++11 features like variadic templates. To implement reasonably, the TR1 version required an implementation-defined maximum number of contained types, and substantial macro trickery. By contrast, the implementation of the C++11 version requires no explicit implementation-defined maximum number of types. Though compilers will have an internal maximum recursion depth for template instantiation (which is normal), the C++11 version of tuples will not expose this value to the user.Using variadic templates, the declaration of the tuple class looks as follows:An example of definition and use of the tuple type:It’s possible to create the tuple proof without defining its contents, but only if the tuple elements' types possess default constructors.  Moreover, it’s possible to assign a tuple to another tuple: if the two tuples’ types are the same, each element type must possess a copy constructor; otherwise, each element type of the right-side tuple must be convertible to that of the corresponding element type of the left-side tuple or that the corresponding element type of the left-side tuple has a suitable constructor.Just like std::make_pair for std::pair, there exists std::make_tuple to automatically create std::tuples using type deduction and auto helps to declare such a tuple. std::tie creates tuples of lvalue references to help unpack tuples. std::ignore also helps here. See the example:Relational operators are available (among tuples with the same number of elements), and two expressions are available to check a tuple’s characteristics (only during compilation):Including hash tables (unordered associative containers) in the C++ standard library is one of the most recurring requests. It was not adopted in C++03 due to time constraints only. Although hash tables are less efficient than a balanced tree in the worst case (in the presence of many collisions), they perform better in many real applications.Collisions are managed only via linear chaining because the committee didn't consider it to be opportune to standardize solutions of open addressing that introduce quite a lot of intrinsic problems (above all when erasure of elements is admitted). To avoid name clashes with non-standard libraries that developed their own hash table implementations, the prefix “unordered” was used instead of “hash”.The new library has four types of hash tables, differentiated by whether or not they accept elements with the same key (unique keys or equivalent keys), and whether they map each key to an associated value. They correspond to the four existing binary-search-tree-based associative containers, with an unordered_ prefix.The new classes fulfill all the requirements of a container class, and have all the methods needed to access elements: insert, erase, begin, end.This new feature didn't need any C++ language core extensions (though implementations will take advantage of various C++11 language features), only a small extension of the header <functional> and the introduction of headers <unordered_set> and <unordered_map>. No other changes to any existing standard classes were needed, and it doesn’t depend on any other extensions of the standard library.The new library, defined in the new header <regex>, is made of a couple of new classes:The function std::regex_search is used for searching, while for ‘search and replace’ the function std::regex_replace is used which returns a new string. The algorithms std::regex_search and std::regex_replace take a regular expression and a string and write the occurrences found in the struct std::match_results.Here is an example of the use of std::match_results:Note the use of double backslashes, because C++ uses backslash as an escape character. The C++11 raw string feature could be used to avoid the problem.The library <regex> requires neither alteration of any existing header (though it will use them where appropriate) nor an extension of the core language. In POSIX C, regular expressions are also available the C POSIX library#regex.h.C++11 provides std::unique_ptr, and improvements to std::shared_ptr and std::weak_ptr from TR1. std::auto_ptr is deprecated.The C standard library provides the ability to generate pseudorandom numbers via the function rand. However, the algorithm is delegated entirely to the library vendor. C++ inherited this functionality with no changes, but C++11 provides a new method for generating pseudorandom numbers.C++11's random number functionality is split into two parts: a generator engine that contains the random number generator's state and produces the pseudorandom numbers; and a distribution, which determines the range and mathematical distribution of the outcome. These two are combined to form a random number generator object.Unlike the C standard rand, the C++11 mechanism will come with three base generator engine algorithms:C++11 also provides a number of standard distributions:The generator and distributions are combined as in this example:A wrapper reference is obtained from an instance of the template class reference_wrapper. Wrapper references are similar to normal references (‘&’) of the C++ language. To obtain a wrapper reference from any object the function template ref is used (for a constant reference cref is used).Wrapper references are useful above all for function templates, where references to parameters rather than copies are needed:This new utility was added to the existing  <utility> header and didn't need further extensions of the C++ language.Polymorphic wrappers for function objects are similar to function pointers in semantics and syntax, but are less tightly bound and can indiscriminately refer to anything which can be called (function pointers, member function pointers, or functors) whose arguments are compatible with those of the wrapper.An example can clarify its characteristics:The template class function was defined inside the header <functional>, without needing any change to the C++ language.Metaprogramming consists of creating a program that creates or modifies another program (or itself). This can happen during compilation or during execution. The C++ Standards Committee has decided to introduce a library that allows metaprogramming during compiling via templates.Here is an example of a meta-program, using the C++03 standard: a recursion of template instances for calculating integer exponents:Many algorithms can operate on different types of data; C++'s templates support generic programming and make code more compact and useful. Nevertheless, it is common for algorithms to need information on the data types being used. This information can be extracted during instantiation of a template class using type traits.Type traits can identify the category of an object and all the characteristics of a class (or of a struct). They are defined in the new header <type_traits>.In the next example there is the template function ‘elaborate’ that, depending on the given data types, will instantiate one of the two proposed algorithms (algorithm.do_it).Via type traits, defined in header <type_traits>, it’s also possible to create type transformation operations (static_cast and const_cast are insufficient inside a template).This type of programming produces elegant and concise code; however the weak point of these techniques is the debugging: uncomfortable during compilation and very difficult during program execution.Determining the return type of a template function object at compile-time is not intuitive, particularly if the return value depends on the parameters of the function. As an example:Instantiating the class template Calculus<Clear>, the function object of calculus will have always the same return type as the function object of Clear. However, given class Confused below:Attempting to instantiate Calculus<Confused> will cause the return type of Calculus to not be the same as that of class Confused. The compiler may generate warnings about the conversion from int to double and vice versa.TR1 introduces, and C++11 adopts, the template class std::result_of that allows one to determine and use the return type of a function object for every declaration. The object CalculusVer2 uses the std::result_of object to derive the return type of the function object:In this way in instances of function object of CalculusVer2<Confused> there are no conversions, warnings, or errors.The only change from the TR1 version of std::result_of is that the TR1 version allowed an implementation to fail to be able to determine the result type of a function call. Due to changes to C++ for supporting decltype, the C++11 version of std::result_of no longer needs these special cases; implementations are required to compute a type in all cases.For compatibility with C, from C99, these were added:Heading for a separate TR:Postponed:The term sequence point was removed, being replaced by specifying that either one operation is sequenced before another, or that two operations are unsequenced.The former use of the keyword export was removed. The keyword itself remains, being reserved for potential future use.Dynamic exception specifications are deprecated. Compile-time specification of non-exception-throwing functions is available with the noexcept keyword, which is useful for optimization.std::auto_ptr is deprecated, having been superseded by std::unique_ptr.Function object base classes (std::unary_function, std::binary_function), adapters to pointers to functions and adapters to pointers to members, and binder classes are all deprecated."
"46"	"In computer programming, variadic templates are templates that take a variable number of arguments.Variadic templates are supported by C++ (since the C++11 standard), and the D programming language.The variadic template feature of C++ was designed by Douglas Gregor and Jaakko Järvi  and was later standardized in C++11. Prior to C++11, templates (classes and functions) could only take a fixed number of arguments, which had to be specified when a template was first declared. C++11 allows template definitions to take an arbitrary number of arguments of any type.The above template class tuple will take any number of typenames as its template parameters.  Here, an instance of the above template class is instantiated with three type arguments:The number of arguments can be zero, so tuple<> some_instance_name; will also work.If the variadic template should only allow a positive number of arguments, then this definition can be used:Variadic templates may also apply to functions, thus not only providing a type-safe add-on to variadic functions (such as printf), but also allowing a function called with printf-like syntax to process non-trivial objects.The ellipsis (...) operator has two roles. When it occurs to the left of the name of a parameter, it declares a parameter pack. Using the parameter pack, the user can bind zero or more arguments to the variadic template parameters. Parameter packs can also be used for non-type parameters. By contrast, when the ellipsis operator occurs to the right of a template or function call argument, it unpacks the parameter packs into separate arguments, like the args... in the body of printf below. In practice, the use of an ellipsis operator in the code causes the whole expression that precedes the ellipsis to be repeated for every subsequent argument unpacked from the argument pack, with the expressions separated by commas.The use of variadic templates is often recursive. The variadic parameters themselves are not readily available to the implementation of a function or class. Therefore, the typical mechanism for defining something like a C++11 variadic printf replacement would be as follows:This is a recursive template. Notice that the variadic template version of printf calls itself, or (in the event that args... is empty) calls the base case.There is no simple mechanism to iterate over the values of the variadic template. However, there are several ways to translate the argument pack into a single argument that can be evaluated separately for each parameter. Usually this will rely on function overloading, or — if the function can simply pick one argument at a time — using a dumb expansion marker:which can be used as follows:which will expand to something like:The use of this pass function is necessary, since the expansion of the argument pack proceeds by separating the function call arguments by commas, which are not equivalent to the comma operator. Therefore, some_function(args)...; will never work. Moreover, the solution above will only work when the return type of some_function is not void. Furthermore, the some_function calls will be executed in an unspecified order, because the order of evaluation of function arguments is undefined. To avoid the unspecified order, brace-enclosed initializer lists can be used, which guarantee strict left-to-right order of evaluation. An initializer list requires a non-void return type, but the comma operator can be used to yield 1 for each expansion element.Instead of executing a function, a lambda expression may be specified and executed in place, which allows executing arbitrary sequences of statements in-place.However, in this particular example, a lambda function is not necessary. A more ordinary expression can be used instead:Another way is to use overloading with termination versions of functions. This is more universal, but requires a bit more code and more effort to create. One function receives one argument of some type and the argument pack, whereas the other receives neither. (If both had the same list of initial parameters, the call would be ambiguous — a variadic parameter pack alone cannot disambiguate a call.) For example:If args... contains at least one argument, it will redirect to the second version — a parameter pack can be empty, in which case it will simply redirect to the termination version, which will do nothing.Variadic templates can also be used in an exception specification, a base class list, or the initialization list of a constructor. For example, a class can specify the following:The unpack operator will replicate the types for the base classes of ClassName, such that this class will be derived from each of the types passed in. Also, the constructor must take a reference to each base class, so as to initialize the base classes of ClassName.With regard to function templates, the variadic parameters can be forwarded. When combined with universal references (see above), this allows for perfect forwarding:This unpacks the argument list into the constructor of TypeToConstruct. The std::forward<Args>(params) syntax perfectly forwards arguments as their proper types, even with regard to rvalue-ness, to the constructor. The unpack operator will propagate the forwarding syntax to each parameter. This particular factory function automatically wraps the allocated memory in a std::shared_ptr for a degree of safety with regard to memory leaks.Additionally, the number of arguments in a template parameter pack can be determined as follows:The expression SomeStruct<Type1, Type2>::size will yield 2, while SomeStruct<>::size will give 0.The definition of variadic templates in D is similar to their C++ counterpart:Likewise, any argument can precede the argument list:Variadic arguments are very similar to constant array in their usage. They can be iterated upon, accessed by an index, have a length property, and can be sliced. Operations are interpreted at compile time, which means operands can't be runtime value (such as function parameters).Anything which is known at compile time can be passed as a variadic arguments. It makes variadic arguments similar to template alias arguments, but more powerful, as they also accept basic types (char, short, int...).Here is an example that print the string representation of the variadic parameters. StringOf and StringOf2 produce equal results.Outputs:Variadic templates are often used to create a sequence of aliases, named AliasSeq. The definition of an AliasSeq is actually very straightforward:This structure allows one to manipulate a list of variadic arguments that will auto-expand. The arguments must either be symbols or values known at compile time. This includes values, types, functions or even non-specialized templates. This allows any operation you would expect:For articles on variadic constructs other than templates"
"47"	"In class-based object-oriented programming, a constructor (abbreviation: ctor) is a special type of subroutine called to create an object. It prepares the new object for use, often accepting arguments that the constructor uses to set required member variables.A constructor resembles an instance method, but it differs from a method in that it has no explicit return type, it is not implicitly inherited and it usually has different rules for scope modifiers. Constructors often have the same name as the declaring class. They have the task of initializing the object's data members and of establishing the invariant of the class, failing if the invariant is invalid. A properly written constructor leaves the resulting object in a valid state. Immutable objects must be initialized in a constructor.Most languages allow overloading the constructor in that there can be more than one constructor for a class, with differing parameters. Some languages take consideration of some special types of constructors. Constructors, which concretely use a single class to create objects and return a new instance of the class, are abstracted by factories, which also create objects but can do so in various ways, using multiple classes or different allocation schemes such as an object pool.Constructors that can take at least one argument are termed as parameterized constructors. For example:When an object is declared in a parameterized constructor, the initial values have to be passed as arguments to the constructor function. The normal way of object declaration may not work. The constructors can be called explicitly or implicitly. The method of calling the constructor implicitly is also called the shorthand method.If the programmer does not supply a constructor for an instantiable class, most languages will provide a default constructor.The behavior of the default constructor is language dependent. It may initialize data members to zero or other same values, or it may do nothing at all.Some languages (Java, C#, VB .NET) will default construct arrays of class types to contain null references. Languages without null references may not allow default construction of arrays of non default constructible objects, or require explicit initialization at the time of the creation (C++):Copy constructors define the actions performed by the compiler when copying class objects. A copy constructor has one formal parameter that is the type of the class (the parameter may be a reference to an object). It is used to create a copy of an existing object of the same class. Even though both classes are the same, it counts as a conversion constructor.While copy constructors are usually abbreviated copy ctor or cctor, they have nothing to do with class constructors used in .NET using the same abbreviation.Conversion constructors provide a means for a compiler to implicitly create an object belonging to one class based on an object of a different type. These constructors are usually invoked implicitly to convert arguments or operands to an appropriate type, but they may also be called explicitly.In C++, move constructors take a value reference to an object of the class, and are used to implement ownership transfer of the parameter object's resources.In Java, C# and VB .NET the constructor creates objects in a special memory structure called heap for reference types. Value types (such as int, double etc.), are created in a sequential structure called stack. VB .NET and C# allow use of new to create objects of value types. However, in those languages even use of new for value types creates objects only on stack.In C++, when constructor is invoked without new the objects are created on stack. When objects are created using new they are created on heap. They must be deleted implicitly by a destructor or explicitly by a call to operator delete.In Java, constructors differ from other methods in that:Java constructors perform the following tasks in the following order:Java permit users to call one constructor in another constructor using this() keyword. But this() must be first statement. Java provides access to the superclass's constructor through the super keyword.A constructor taking zero number of arguments is called a no-arguments or no-arg constructor.As of ES6, JavaScript has direct constructors like many other programming languages. They are written as suchThis can be instantiated as suchThe equivalent of this before ES6, was creating a function that instantiates an object as suchThis is instantiated the same way as above. In Visual Basic .NET, constructors use a method declaration with the name New.Example C# constructor:In C#, a static constructor is a static data initializer.  Static constructors are also called class constructors. Since the actual method generated has the name .cctor they are often also called cctors.Static constructors allow complex static variable initialization. Static constructors are called implicitly when the class is first accessed. Any call to a class (static or constructor call), triggers the static constructor execution. Static constructors are thread safe and implement a singleton pattern. When used in a generic programming class, static constructors are called at every new generic instantiation one per type. Static variables are instantiated as well.In C++, the name of the constructor is the name of the class. It returns nothing. It can have parameters like any member function. Constructor functions are usually declared in the public section, but can also be declared in the protected and private sections, if the user wants to restrict access to them.The constructor has two parts. First is the initializer list which follows the parameter list and before the method body. It starts with a colon and entries are comma-separated. The initializer list is not required, but offers the opportunity to provide values for data members and avoid separate assignment statements. The initializer list is required if you have const or reference type data members, or members that do not have parameterless constructor logic. Assignments occur according to the order in which data members are declared (even if the order in the initializer list is different). The second part is the body, which is a normal method body enclosed in curly brackets.C++ allows more than one constructor. The other constructors must have different parameters. Additionally constructors which contain parameters which are given default values, must adhere to the restriction that not all parameters are given a default value. This is a situation which only matters if there is a default constructor. The constructor of a base class (or base classes) can also be called by a derived class. Constructor functions are not inherited and their addresses cannot be referenced. When memory allocation is required, the new and delete operators are called implicitly.A copy constructor has a parameter of the same type passed as const reference, for example Vector(const Vector& rhs). If it is not provided explicitly, the compiler uses the copy constructor for each member variable or simply copies values in case of primitive types. The default implementation is not efficient if the class has dynamically allocated members (or handles to other resources), because it can lead to double calls to delete (or double release of resources) upon destruction.Example invocations:On returning objects from functions or passing objects by value, the objects copy constructor will be called implicitly, unless return value optimization applies.C++ implicitly generates a default copy constructor which will call the copy constructors for all base classes and all member variables unless the programmer provides one, explicitly deletes the copy constructor (to prevent cloning) or one of the base classes or member variables copy constructor is deleted or not accessible (private). Most cases calling for a customized copy constructor (e.g. reference counting, deep copy of pointers) also require customizing the destructor and the copy assignment operator. This is commonly referred to as the Rule of three.In F#, a constructor can include any let or do statements defined in a class. let statements define private fields and do statements execute code. Additional constructors can be defined using the new keyword.In Eiffel, the routines which initialize new objects are called creation procedures. Creation procedures have the following traits:Although object creation involves some subtleties, the creation of an attribute with a typical declaration x: T as expressed in a creation instruction create x.make consists of the following sequence of steps:In the first snippet below, class POINT is defined. The procedure make is coded after the keyword feature.The keyword create introduces a list of procedures which can be used to initialize instances. In this case the list includes default_create, a procedure with an empty implementation inherited from class ANY, and the make procedure coded within the class.In the second snippet, a class which is a client to POINT has a declarations my_point_1 and my_point_2 of type POINT.In procedural code, my_point_1 is created as the origin (0.0, 0.0). Because no creation procedure is specified, the procedure default_create inherited from class ANY is used. This line could have been coded create my_point_1.default_create . Only procedures named as creation procedures can be used in an instruction with the create keyword. Next is a creation instruction for my_point_2, providing initial values for the my_point_2's coordinates. The third instruction makes an ordinary instance call to the make procedure to reinitialize the instance attached to my_point_2 with different values.CFML uses a method named 'init' as a constructor method.Cheese.cfcCreate instance of a cheese.Since ColdFusion 10, CFML has also supported specifying the name of the constructor method:In Object Pascal, the constructor is similar to a factory method. The only syntactic difference to regular methods is the keyword constructor in front of the name (instead of procedure or function). It can have any name, though the convention is to have Create as prefix, such as in CreateWithFormatting. Creating an instance of a class works like calling a static method of a class: TPerson.Create('Peter').In Perl programming language version 5, by default, constructors are factory methods, that is, methods that create and return the object, concretely meaning create and return a blessed reference. A typical object is a reference to a hash, though rarely references to other types are used too.  By convention the only constructor is named new, though it is allowed to name it otherwise, or to have multiple constructors.  For example, a Person class may have a constructor named new as well as a constructor new_from_file which reads a file for Person attributes, and new_from_person which uses another Person object as a template.With the Moose object system for Perl, most of this boilerplate can be left out, a default new is created, attributes can be specified, as well as whether they can be set, reset, or are required.  In addition, any extra constructor functionality can be included in a BUILD method which the Moose generated constructor will call, after it has checked the arguments.  A BUILDARGS method can be specified to handle constructor arguments not in hashref / key => value form.In both cases the Person class is instiated like this:In PHP version 5 and above, the constructor is a method named __construct() (notice that it's a double underscore), which the keyword new automatically calls after creating the object. It is usually used to automatically perform initializations such as property initializations. Constructors can also accept arguments, in which case, when the new statement is written, you also need to send the constructor arguments for the parameters.In Python, constructors are defined by one or both of __new__ and __init__ methods. A new instance is created by calling the class as if it were a function, which calls the __new__ and __init__ methods. If a constructor method is not defined in the class, the next one found in the class's Method Resolution Order will be called.In the typical case, only the __init__ method need be defined. (The most common exception is for immutable objects.)Classes normally act as factories for new instances of themselves, that is, a class is a callable object (like a function), with the call being the constructor, and calling the class returns an instance of that class. However the __new__ method is permitted to return something other than an instance of the class for specialised purposes. In that case, the __init__ is not invoked.In Ruby, constructors are created by defining a method called initialize. This method is executed to initialize each new instance."
"48"	"The syntax of the Java programming language is the set of rules defining how a Java program is written and interpreted.The syntax is mostly derived from C and C++. Unlike C++, in Java there are no global functions or variables, but there are data members which are also regarded as global variables. All code belongs to classes and all values are objects. The only exception is the primitive types, which are not represented by a class instance for performance reasons (though can be automatically converted to objects and vice versa via autoboxing). Some features like operator overloading or unsigned integer types are omitted to simplify the language and to avoid possible programming mistakes.The Java syntax has been gradually extended in the course of the eight major JDK releases support capabilities such as generic programming and function literals (called lambda expressions in Java).An identifier is the name of an element in the code. There are certain standard naming conventions to follow when selecting names for elements. Identifiers in Java are case-sensitive.An identifier can contain:An identifier cannot:Integer literals are of int type by default unless long type is specified by appending L or l suffix to the literal, e.g. 367L. Since Java SE 7, it is possible to include underscores between the digits of a number to increase readability; for example, a number 145608987 can be written as 145_608_987.Variables are identifiers associated with values. They are declared by writing the variable's type and name, and are optionally initialized in the same statement by assigning a value.Multiple variables of the same type can be declared and initialized in one statement using comma as a delimiter.The separators { and } signify a code block and a new scope. Class members and the body of a method are examples of what can live inside these braces in various contexts.Inside of method bodies, braces may be used to create new scopes, as follows:Java has three kinds of comments: traditional comments, end-of-line comments and documentation comments.Traditional comments, also known as block comments, start with /* and end with */, they may span across multiple lines. This type of comment was derived from C and C++.End-of-line comments start with // and extend to the end of the current line. This comment type is also present in C++ and in modern C.Documentation comments in the source files are processed by the Javadoc tool to generate documentation. This type of comment is identical to traditional comments, except it starts with /** and follows conventions defined by the Javadoc tool. Technically, these comments are a special kind of traditional comment and they are not specifically defined in the language specification.Java applications consist of collections of classes. Classes exist in packages but can also be nested inside other classes.Every Java application must have an entry point. This is true of both graphical interface applications and console applications. The entry point is the main method. There can be more than one class with a main method, but the main class is always defined externally (for example, in a manifest file). The method must be static and is passed command-line arguments as an array of strings. Unlike C++ or C#, it never returns a value and must return void.Packages are a part of a class name and they are used to group and/or distinguish named entities from other ones. Another purpose of packages is to govern code access together with access modifiers. For example, java.io.InputStream is a fully qualified class name for the class InputStream which is located in the package java.io.A package is declared at the start of the file with the package declaration:Classes with the public modifier must be placed in the files with the same name and java extension and put into nested folders corresponding to the package name. The above class myapplication.mylibrary.MyClass will have the following path: myapplication/mylibrary/MyClass.java.A type import declaration allows a named type to be referred to by a simple name rather than the full name that includes the package. Import declarations can be single type import declarations or import-on-demand declarations. Import declarations must be placed at the top of a code file after the package declaration.Import-on-demand declarations are mentioned in the code. A type import imports all the types of the package. A static import imports members of the package.This type of declaration has been available since J2SE 5.0. Static import declarations allow access to static members defined in another class, interface, annotation, or enum; without specifying the class name:Import-on-demand declarations allow to import all the fields of the type:Enum constants may also be used with static import. For example, this enum is in the package called screen:It is possible to use static import declarations in another class to retrieve the enum constants:Operators in Java are similar to those in C++. However, there is no delete operator due to garbage collection mechanisms in Java, and there are no operations on pointers since Java does not support them. Another difference is that Java has an unsigned right shift operator (>>>), while C's right shift operator's signedness is type-dependent. Operators in Java cannot be overloaded.if statements in Java are similar to those in C and use the same syntax:if statement may include optional else block, in which case it becomes an if-then-else statement:Like C, else-if construction does not involve any special keywords, it is formed as a sequence of separate if-then-else statements:Also, note that the ?: operator can be used in place of simple if statement, for exampleSwitch statements in Java can use byte, short, char, and int (note: not long) primitive data types or their corresponding wrapper types. Starting with J2SE 5.0, it is possible to use enum types. Starting with Java SE 7, it is possible to use Strings. Other reference types cannot be used in switch statements.Possible values are listed using case labels. These labels in Java may contain only constants (including enum constants and string constants). Execution will start after the label corresponding to the expression inside the brackets. An optional default label may be present to declare that the code following it will be executed if none of the case labels correspond to the expression.Code for each label ends with the break keyword. It is possible to omit it causing the execution to proceed to the next label, however, a warning will usually be reported during compilation.Iteration statements are statements that are repeatedly executed when a given condition is evaluated as true. Since J2SE 5.0, Java has four forms of such statements.In the while loop, the test is done before each iteration.In the do ... while loop, the test is done after each iteration. Consequently, the code is always executed at least once.for loops in Java include an initializer, a condition and a counter expression. It is possible to include several expressions of the same kind using comma as delimiter (except in the condition). However, unlike C, the comma is just a delimiter and not an operator.Like C, all three expressions are optional. The following loop is infinite:Enhanced for loops have been available since J2SE 5.0. This type of loop uses built-in iterators over arrays and collections to return each item in the given collection. Every element is returned and reachable in the context of the code block. When the block is executed, the next item is returned until there are no items remaining. Unlike C#, this kind of loop does not involve a special keyword, but instead uses a different notation style.Labels are given points in code used by break and continue statements. Note that the Java goto keyword cannot be used to jump to specific points in the code.The break statement breaks out of the closest loop or switch statement. Execution continues in the statement after the terminated statement, if any.It is possible to break out of the outer loop using labels:The continue statement discontinues the current iteration of the current control statement and begins the next iteration. The following while loop in the code below reads characters by calling getChar(), skipping the statements in the body of the loop if the characters are spaces:Labels can be specified in continue statements and break statements:The return statement is used to end method execution and to return a value. A value returned by the method is written after the return keyword. If the method returns anything but void, it must use the return statement to return some value.return statement ends execution immediately, except for one case: if the statement is encountered within a try block and it is complemented by a finally, control is passed to the finally block.Exceptions are managed within try ... catch blocks.The statements within the try block are executed, and if any of them throws an exception, execution of the block is discontinued and the exception is handled by the catch block. There may be multiple catch blocks, in which case the first block with an exception variable whose type matches the type of the thrown exception is executed.Java SE 7 also introduced multi-catch clauses besides uni-catch clauses. This type of catch clauses allows Java to handle different types of exceptions in a single block provided they are not subclasses of each other.If no catch block matches the type of the thrown exception, the execution of the outer block (or method) containing the try ... catch statement is discontinued, and the exception is passed up and outside the containing block (or method). The exception is propagated upwards through the call stack until a matching catch block is found within one of the currently active methods. If the exception propagates all the way up to the top-most main method without a matching catch block being found, a textual description of the exception is written to the standard output stream.The statements within the finally block are always executed after the try and catch blocks, whether or not an exception was thrown and even if a return statement was reached. Such blocks are useful for providing clean-up code that is guaranteed to always be executed.The catch and finally blocks are optional, but at least one or the other must be present following the try block.try-with-resources statements are a special type of try-catch-finally statements introduced as an implementation of the dispose pattern in Java SE 7. In a try-with-resources statement the try keyword is followed by initialization of one or more resources that are released automatically when the try block execution is finished. Resources must implement java.lang.AutoCloseable. try-with-resources statements are not required to have a catch or finally block unlike normal try-catch-finally statements.The throw statement is used to throw an exception and end the execution of the block or method. The thrown exception instance is written after the throw statement.Java has built-in tools for multi-thread programming. For the purposes of thread synchronization the synchronized statement is included in Java language.To make a code block synchronized, it is preceded by the synchronized keyword followed by the lock object inside the brackets. When the executing thread reaches the synchronized block, it acquires a mutual exclusion lock, executes the block, then releases the lock. No threads may enter this block until the lock is released. Any non-null reference type may be used as the lock.assert statements have been available since J2SE 1.4. These types of statements are used to make assertions in the source code, which can be turned on and off during execution for specific classes or packages. To declare an assertion the assert keyword is used followed by a conditional expression. If it evaluates to false when the statement is executed, an exception is thrown. This statement can include a colon followed by another expression, which will act as the exception's detail message.Primitive types in Java include integer types, floating-point numbers, UTF-16 code units and a boolean type. There are no unsigned types in Java except char type, which is used to represent UTF-16 code units. The lack of unsigned types is offset by introducing unsigned right shift operation (>>>), which is not present in C++. Nevertheless, criticisms have been levelled about the lack of compatibility with C and C++ this causes.char does not necessarily correspond to a single character. It may represent a part of a surrogate pair, in which case Unicode code point is represented by a sequence of two char values.This language feature was introduced in J2SE 5.0. Boxing is the operation of converting a value of a primitive type into a value of a corresponding reference type, which serves as a wrapper for this particular primitive type. Unboxing is the reverse operation of converting a value of a reference type (previously boxed) into a value of a corresponding primitive type. Neither operation requires an explicit conversion.Example:Reference types include class types, interface types, and array types. When the constructor is called, an object is created on the heap and a reference is assigned to the variable. When a variable of an object gets out of scope, the reference is broken and when there are no references left, the object gets marked as garbage. The garbage collector then collects and destroys it some time afterwards.A reference variable is null when it does not reference any object.Arrays in Java are created at runtime, just like class instances. Array length is defined at creation and cannot be changed.In Java, multi-dimensional arrays are represented as arrays of arrays. Technically, they are represented by arrays of references to other arrays.Due to the nature of the multi-dimensional arrays, sub-arrays can vary in length, so multi-dimensional arrays are not bound to be rectangular unlike C:Classes are fundamentals of an object-oriented language such as Java. They contain members that store and manipulate data. Classes are divided into top-level and nested. Nested classes are classes placed inside another class that may access the private members of the enclosing class. Nested classes include member classes (which may be defined with the static modifier for simple nesting or without it for inner classes), local classes and anonymous classes.Non-static members of a class define the types of the instance variables and methods, which are related to the objects created from that class. To create these objects, the class must be instantiated by using the new operator and calling the class constructor.Members of both instances and static classes are accessed with the . operator.Accessing an instance member Instance members can be accessed through the name of a variable.Accessing a static class member Static members are accessed by using the name of the class or any other type. This does not require the creation of a class instance. Static members are declared using the static modifier.Modifiers are keywords used to modify declarations of types and type members. Most notably there is a sub-group containing the access modifiers.The access modifiers, or inheritance modifiers, set the accessibility of classes, methods, and other members. Members marked as public can be reached from anywhere. If a class or its member does not have any modifiers, default access is assumed.The following table shows whether code within a class has access to the class or method depending on the accessing class location and the modifier for the accessed class or class member:A constructor is a special method called when an object is initialized. Its purpose is to initialize the members of the object. The main differences between constructors and ordinary methods are that constructors are called only when an instance of the class is created and never return anything. Constructors are declared as common methods, but they are named after the class and no return type is specified:Initializers are blocks of code that are executed when a class or an instance of a class is created. There are two kinds of initializers, static initializers and instance initializers.Static initializers initialize static fields when the class is created. They are declared using the static keyword:A class is created only once. Therefore, static initializers are not called more than once. On the contrary, instance initializers are automatically called before the call to a constructor every time an instance of the class is created. Unlike constructors instance initializers cannot take any arguments and generally they cannot throw any checked exceptions (except in several special cases). Instance initializers are declared in a block without any keywords:Since Java has a garbage collection mechanism, there are no destructors. However, every object has a finalize() method called prior to garbage collection, which can be overridden to implement finalization.All the statements in Java must reside within methods. Methods are similar to functions except they belong to classes. A method has a return value, a name and usually some parameters initialized when it is called with some arguments. Similar to C++, methods returning nothing have return type declared as void. Unlike in C++, methods in Java are not allowed to have default argument values and methods are usually overloaded instead.A method is called using . notation on an object, or in the case of a static method, also on the name of a class.The throws keyword indicates that a method throws an exception. All checked exceptions must be listed in a comma-separated list.This language feature was introduced in J2SE 5.0. The last argument of the method may be declared as a variable arity parameter, in which case the method becomes a variable arity method (as opposed to fixed arity methods) or simply varargs method. This allows one to pass a variable number of values, of the declared type, to the method as parameters - including no parameters. These values will be available inside the method as an array.Fields, or class variables, can be declared inside the class body to store data.Fields can be initialized directly when declared.Classes in Java can only inherit from one class. A class can be derived from any class that is not marked as final. Inheritance is declared using the extends keyword. A class can reference itself using the this keyword and its direct superclass using the super keyword.If a class does not specify its superclass, it implicitly inherits from java.lang.Object class. Thus all classes in Java are subclasses of Object class.If the superclass does not have specified a constructor without parameters the subclass must especify in its constructors what constructor of the superclass to use. For example:Unlike C++, all non-final methods in Java are virtual and can be overridden by the inheriting classes.An Abstract Class is a class that is incomplete, or to be considered incomplete. Normal classes may have abstract methods, that is, methods that are declared but not yet implemented, only if they are abstract classes. A class C has abstract methods if any of the following is true:Output:This language feature was introduced in J2SE 5.0. Technically enumerations are a kind of class containing enum constants in its body. Each enum constant defines an instance of the enum type. Enumeration classes cannot be instantiated anywhere except in the enumeration class itself.Enum constants are allowed to have constructors, which are called when the class is loaded:Enumerations can have class bodies, in which case they are treated like anonymous classes extending the enum class:Interfaces are data structures that contain member definitions and not actual implementation. They are useful to define a contract between members in different types that have different implementations. Every interface is implicitly abstract. The only modifier allowed to use with interfaces apart from access modifiers is strictfp, which has the same effect as for classes.An interface is implemented by a class using the implements keyword. It is allowed to implement more than one interface, in which case they are written after implements keyword in a comma-separated list. Class implementing an interface must override all its methods, otherwise it must be declared as abstract.Interfaces can inherit from other interfaces just like classes. Unlike classes it is allowed to inherit from multiple interfaces. However, it is possible that several interfaces have a field with the same name, in which case it becomes a single ambiguous member, which cannot be accessed.Annotations in Java are a way to embed metadata into code. This language feature was introduced in J2SE 5.0.Java has a set of predefined annotation types, but it is allowed to define new ones. An annotation type declaration is a special type of an interface declaration. They are declared in the same way as the interfaces, except the interface keyword is preceded by the @ sign. All annotations are implicitly extended from java.lang.annotation.Annotation and cannot be extended from anything else.Annotations may have the same declarations in the body as the common interfaces, in addition they are allowed to include enums and annotations. The main difference is that abstract method declarations must not have any parameters or throw any exceptions. Also they may have a default value, which is declared using the default keyword after the method name:Annotations may be used in any kind of declaration, whether it is package, class (including enums), interface (including annotations), field, method, parameter, constructor, or local variable. Also they can be used with enum constants. Annotations are declared using the @ sign preceding annotation type name, after which element-value pairs are written inside brackets. All elements with no default value must be assigned a value.Besides the generic form, there are two other forms to declare an annotation, which are shorthands. Marker annotation is a short form, it is used when no values are assigned to elements:The other short form is called single element annotation. It is used with annotations types containing only one element or in the case when multiple elements are present, but only one elements lacks a default value. In single element annotation form the element name is omitted and only value is written instead:Generics, or parameterized types, or parametric polymorphism is one of the major features introduced in J2SE 5.0. Before generics were introduced, it was required to declare all the types explicitly. With generics it became possible to work in a similar manner with different types without declaring the exact types. The main purpose of generics is to ensure type safety and to detect runtime errors during compilation. Unlike C#, information on the used parameters is not available at runtime due to type erasure.Classes can be parameterized by adding a type variable inside angle brackets (< and >) following the class name. It makes possible the use of this type variable in class members instead of actual types. There can be more than one type variable, in which case they are declared in a comma-separated list.It is possible to limit a type variable to a subtype of some specific class or declare an interface that must be implemented by the type. In this case the type variable is appended by the extends keyword followed by a name of the class or the interface. If the variable is constrained by both class and interface or if there are several interfaces, the class name is written first, followed by interface names with &  sign used as the delimiter.When a variable of a parameterized type is declared or an instance is created, its type is written exactly in the same format as in the class header, except the actual type is written in the place of the type variable declaration.Since Java SE 7, it is possible to use a diamond (<>) in place of type arguments, in which case the latter will be inferred. The following code in Java SE 7 is equivalent to the code in the previous example:When declaring a variable for a parameterized type, it is possible to use wildcards instead of explicit type names. Wildcards are expressed by writing ? sign instead of the actual type. It is possible to limit possible types to the subclasses or superclasses of some specific class by writing the extends keyword or the super keyword correspondingly followed by the class name.Usage of generics may be limited to some particular methods, this concept applies to constructors as well. To declare a parameterized method, type variables are written before the return type of the method in the same format as for the generic classes. In the case of constructor, type variables are declared before the constructor name.Interfaces can be parameterized in the similar manner as the classes."
"49"	" typedef is a reserved keyword in the C and C++ programming languages. It is used to create an alias name for another data type. As such, it is often used to simplify the syntax of declaring complex data structures consisting of struct and union types, but is just as common in providing specific descriptive type names for integer data types of varying lengths. The C standard library and POSIX reserve the suffix '_t', for example as in size_t and time_t.The syntax for a creating a typedef is: typedef typedeclaration;Some examples:  creates Length as a synonym for int.  creates PFI as a synonym for a pointer to a function of two char * arguments that returns an int.A typedef declaration may be used to indicate the meaning of a variable within the programming context, e.g., it may be include the expression of a unit of measurement or counts. The generic declarations in the following code,may be expressed by declaring context specific types:Both sections of code execute identically. However, the use of typedef declarations in the second code block makes it clear that the two variables, while represented by the same data type int, represent different or incompatible data. The definition in congratulate() of your_score indicates to the programmer that current_speed (or any other variable not declared as a points) should not be passed as an argument. This would not be as apparent if both were declared as variables of int datatype.  However, the indication is for the programmer only; the C/C++ compiler considers both variables to be of type int and does not flag type mismatch warnings or errors for wrong argument types for congratulate(points your_score) in the code snippet below:Although the compiler considers km_per_hour to be equivalent to int in the above code, the two cannot be used interchangeably when the type is changed via a prefix of unsigned, signed, or long.A typedef may be used to simplify the declaration of a compound type (struct, union) or pointer type.  For example, in the following snippet:the data type struct MyStruct is defined. To declare a variable of this type in C, the struct key word is required (in C++, it may be omitted):A typedef may be used to eliminate the need for the keyword struct  in C.  For example, the following declarationmay be used to define an object of type newtype:The structure declaration and definition may instead be combined into a single statement:Or it may be used as follows:In C++, in contrast to C, the keywords struct, class, and enum are optional in variable declarations that are separate from the definitions, as long as there is no ambiguity to another identifier:As such, MyStruct can be used wherever newtype can be used.  However, the reverse is not true; for instance, the constructor methods for MyStruct cannot be named newtype.A notorious example where even C++ needs the struct keyword is POSIX' stat system call that uses a struct of the same name in its arguments:Here both C as well as C++ need the struct keyword in the parameter definition.We can use the typedef to define a new pointer type. For example,Above, intptr is a new alias with the pointer type int*. The definition, intptr ptr;, defines a variable ptr with the type int*. So, ptr is a pointer which can point to a memory with int type.Using typedef to define a new pointer type may sometimes lead to confusion. For example:Above, intptr cliff, allen; means defining 2 variables with int* type for both. This is because a type defined by typedef is a type, not an expansion. In other words, intptr, which is the int* type, decorates both cliff and allen. For intptr cliff2, *allen2;, the intptr type decorates the cliff2 and *allen2. So, intptr cliff2, *allen2; is equivalent to 2 separate definitions, intptr cliff2; and intptr *allen2. intptr *allen2 means that allen2 is a pointer pointing to a memory with int* type. Shortly, allen2 has the type, int**.Typedefs can also simplify definitions or declarations for structure pointer types. Consider this:Using typedef, the above code can be rewritten like this:In C, one can declare multiple variables of the same type in a single statement, even mixing structure with pointer or non-pointers. However, one would need to prefix an asterisk to each variable to designate it as a pointer.  In the following, a programmer might assume that errptr was indeed a Node *, but a typographical error means that errptr is a Node. This can lead to subtle syntax errors.By defining the typedef Node *, it is assured that all variables are structure pointer types, or say, that each variable is a pointer type pointing to a structure type.Consider the following code, which does not use a typedef:This code can be rewritten with a typedef as follows:Here, MathFunc is the new alias for the type. A MathFunc is a pointer to a function that returns an integer and takes as arguments a float followed by an integer.When a function returns a function pointer, it can be even more confusing without typedef. The following is the function prototype of signal(3) from FreeBSD:The function declaration above is cryptic as it does not clearly show what the function accepts as arguments, or the type that it returns. A novice programmer may even assume that the function accepts a single int as its argument and returns nothing, but in reality it also needs a function pointer and returns another function pointer. It can be written more cleanly:A typedef can also be used to simplify the definition of array types. For example,Here, arrType is the new alias for the char type, which is an array type with 6 elements. For arrType *pArr;, pArr is a pointer pointing to the memory of the char type.A typedef is created using type definition syntax but can be used as if it were created using type cast syntax. (Type casting changes a data type.)  For instance, in each line after the first line of:funcptr is used on the left-hand side to declare a variable and is used on the right-hand side to cast a value.  Thus, the typedef can be used by programmers who do not wish to figure out how to convert definition syntax to type cast syntax.Note that, without the typedef, it is generally not possible to use definition syntax and cast syntax interchangeably.  For example:Some people[who?] are opposed to the extensive use of typedefs. Most arguments center on the idea that typedefs simply hide the actual data type of a variable. For example, Greg Kroah-Hartman, a Linux kernel hacker and documenter, discourages their use for anything except function prototype declarations. He argues that this practice not only unnecessarily obfuscates code, it can also cause programmers to accidentally misuse large structures thinking them to be simple types.Others argue that the use of typedefs can make code easier to maintain.  K&R states that there are two reasons for using a typedef.  First, it provides a means to make a program more portable.  Instead of having to change a type everywhere it appears throughout the program's source files, only a single typedef statement needs to be changed.  Second, a typedef can make a complex definition or declaration easier to understand.In C++ type names can be very complicated and typedef provides a mechanism to assign a simple name to the type. Consider:andC++03 does not provide templated typedefs.  For instance, to have stringpair<T> represent std::pair<std::string, T> for every type T one cannot use:However, if one is willing to accept stringpair<T>::type in lieu of stringpair<T> then it is possible to achieve the desired result via a typedef within an otherwise unused templated class or struct:In C++11, templated typedefs are added with the following syntax, which requires the using keyword rather than the typedef keyword. (See template aliases.)In many statically typed functional languages, like Haskell, Miranda, OCaml, etc., one can define type synonyms, which are the same as typedefs in C. An example in Haskell:This example has defined a type synonym PairOfInts as an integer type.In Seed7 the definition of a constant type is used to introduce a synonym for a type:In Swift, typedef is called typealias:C# also contains a feature which is similar to the using syntax in C++.In D the keyword alias allows to create type or partial type synonyms."
"50"	"Generics are a facility of generic programming that were added to the Java programming language in 2004 within version J2SE 5.0. They were designed to extend Java's type system to allow “a type or method to operate on objects of various types while providing compile-time type safety”. The aspect compile-time type safety was not fully achieved, since it was shown in 2016 that it is not guaranteed in all cases.The Java collections framework supports generics to specify the type of objects stored in a collection instance.In 1998, Gilad Bracha, Martin Odersky, David Stoutamire and Philip Wadler created Generic Java, an extension to the Java language to support generic types. Generic Java was incorporated in Java with the addition of wildcards.According to Java Language Specification:The following block of Java code illustrates a problem that exists when not using generics. First, it declares an ArrayList of type Object. Then, it adds a String to the ArrayList. Finally, it attempts to retrieve the added String and cast it to an Integer.Although the code is compiled without error, it throws a runtime exception (java.lang.ClassCastException) when executing the third line of code. This type of problem can be avoided by using generics and is the primary motivation for using generics.Using generics, the above code fragment can be rewritten as follows:The type parameter String within the angle brackets declares the ArrayList to be constituted of String (a descendant of the ArrayList's generic Object constituents). With generics, it is no longer necessary to cast the third line to any particular type, because the result of v.get(0) is defined as String by the code generated by the compiler.Compiling the third line of this fragment with J2SE 5.0 (or later) will yield a compile-time error because the compiler will detect that v.get(0) returns String instead of Integer. For a more elaborate example, see reference.Here is a small excerpt from the definition of the interfaces List and Iterator in package java.util:A type argument for a parameterized type is not limited to a concrete class or interface. Java allows the use of type wildcards to serve as type arguments for parameterized types. Wildcards are type arguments in the form <?>; optionally with an upper or lower bound. Given that the exact type represented by a wildcard is unknown, restrictions are placed on the type of methods that may be called on an object that uses parameterized types.Here is an example where the element type of a Collection<E> is parameterized by a wildcard:Since we don’t know what the element type of c stands for, we cannot add objects to it. The add() method takes arguments of type E, the element type of the Collection<E> generic interface. When the actual type argument is ?, it stands for some unknown type. Any method argument value we pass to the add() method would have to be a subtype of this unknown type. Since we don't know what type that is, we cannot pass anything in. The sole exception is null; which is a member of every type.To specify the upper bound of a type wildcard, the extends keyword is used to indicate that the type argument is a subtype of the bounding class. So List<? extends Number> means that the given list contains objects of some unknown type which extends the Number class. For example, the list could be List<Float> or List<Number>. Reading an element from the list will return a Number. Adding null elements is, again, also allowed.The use of wildcards above adds flexibility since there is not any inheritance relationship between any two parameterized types with concrete type as type argument. Neither List<Number> nor List<Integer> is a subtype of the other; even though Integer is a subtype of Number. So, any method that takes List<Number> as a parameter does not accept an argument of List<Integer>. If it did, it would be possible to insert a Number that is not an Integer into it; which violates type safety. Here is an example that demonstrates how type safety would be violated if List<Integer> were a subtype of List<Number>:The solution with wildcards works because it disallows operations that would violate type safety:To specify the lower bounding class of a type wildcard, the super keyword is used. This keyword indicates that the type argument is a supertype of the bounding class. So, List<? super Number> could represent List<Number> or List<Object>. Reading from a list defined as List<? super Number> returns elements of type Object. Adding to such a list requires either elements of type Number, any subtype of Number or null (which is a member of every type).The mnemonic PECS (Producer Extends, Consumer Super) from the book Effective Java by Joshua Bloch gives an easy way to remember when to use wildcards (corresponding to covariance and contravariance) in Java.Here is an example of a generic Java class, which can be used to represent individual entries (key to value mappings) in a map:This generic class could be used in the following ways, for example:It outputs:Java SE 7 and above allow the programmer to substitute an empty pair of angle brackets (<>, called the diamond operator) for a pair of angle brackets containing the one or more type parameters that a sufficiently-close context implies. Thus, the above code example using Entry can be rewritten as:Here is an example of a generic method using the generic class above:Note: If we remove the first <Type> in the above method, we will get compilation error (cannot find symbol 'Type') since it represents the declaration of the symbol.In many cases the user of the method need not indicate the type parameters, as they can be inferred:The parameters can be explicitly added if needed:The use of primitive types is not allowed, and boxed versions must be used instead:There is also the possibility to create generic methods based on given parameters.In such cases you can't use primitive types either, e.g.:Although exceptions themselves cannot be generic, generic parameters can appear in a throws clause:Generics are checked at compile-time for type-correctness. The generic type information is then removed in a process called type erasure. For example, List<Integer> will be converted to the non-generic type List, which ordinarily contains arbitrary objects. The compile-time check guarantees that the resulting code is type-correct.Because of type erasure, type parameters cannot be determined at run-time.  For example, when an ArrayList is examined at runtime, there is no general way to determine whether, before type erasure, it was an ArrayList<Integer> or an ArrayList<Float>. Many people are dissatisfied with this restriction. There are partial approaches. For example, individual elements may be examined to determine the type they belong to; for example, if an ArrayList contains an Integer, that ArrayList may have been parameterized with Integer (however, it may have been parameterized with any parent of Integer, such as Number or Object).Demonstrating this point, the following code outputs Equal:Another effect of type erasure is that a generic class cannot extend the Throwable class in any way, directly or indirectly:The reason why this is not supported is due to type erasure:Due to type erasure, the runtime will not know which catch block to execute, so this is prohibited by the compiler.Java generics differ from C++ templates. Java generics generate only one compiled version of a generic class or function regardless of the number of parameterizing types used. Furthermore, the Java run-time environment does not need to know which parameterized type is used because the type information is validated at compile-time and is not included in the compiled code. Consequently, instantiating a Java class of a parameterized type is impossible because instantiation requires a call to a constructor, which is unavailable if the type is unknown.For example, the following code cannot be compiled:Because there is only one copy per generic class at runtime, static variables are shared among all the instances of the class, regardless of their type parameter. Consequently, the type parameter cannot be used in the declaration of static variables or in static methods.Project Valhalla is an experimental project to incubate improved Java generics and language features, for future versions potentially from Java 10 onwards. Potential enhancements include:"
"51"	"In computer programming, lazy initialization is the tactic of delaying the creation of an object, the calculation of a value, or some other expensive process until the first time it is needed. It is a kind of lazy evaluation that refers specifically to the instantiation of objects or other resources.This is typically accomplished by augmenting an accessor method (or property getter) to check whether a private member, acting as a cache, has already been initialized.  If it has, it is returned straight away. If not, a new instance is created, placed into the member variable, and returned to the caller just-in-time for its first use. If objects have properties that are rarely used, this can improve startup speed. Mean average program performance may be slightly worse in terms of memory (for the condition variables) and execution cycles (to check them), but the impact of object instantiation is spread in time (amortized) rather than concentrated in the startup phase of a system, and thus median response times can be greatly improved.In multithreaded code, access to lazy-initialized objects/state must be synchronized to guard against race conditions.In a software design pattern view, lazy initialization is often used together with a factory method pattern. This combines three ideas:The following is an example of a class with Lazy initialization implemented in Actionscript:Basic Usage:In C, lazy evaluation would normally be implemented inside a single function, or a single source file, using static variables.In a function:Using a single source file instead allows the state to be shared between multiple functions, while still hiding it from non-related functions.fruit.h:fruit.c:main.c:In .NET 4.0 Microsoft has included a Lazy class that can be used to do lazy loading. Below is some dummy code that does lazy loading of Class FruitHere is a dummy example in C#.The Fruit class itself doesn't do anything here, The class variable _typesDictionary is a Dictionary/Map used to store Fruit instances by typeName.A fairly straightforward 'fill-in-the-blanks' example of a Lazy Initialization design pattern, except that this uses an enumeration for the typeHere is an example in C++.Here is an example in Java.OutputHere is an example in JavaScript.OutputHere is an example of lazy initialization in PHP 5:Here is an example in Python.Here is an example in Ruby, of lazily initializing an authentication token from a remote service like Google. The way that @auth_token is cached is also an example of memoization.Here is an example in Smalltalk, of a typical accessor method to return the value of a variable using lazy initialization.The 'non-lazy' alternative is to use an initialization method that is run when the object is created and then use a simpler accessor method to fetch the value.Note that lazy initialization can also be used in non-object-oriented languages.Scala has built-in support for lazy variable initiation.Output:"
"52"	"In computer programming, an entry point is where control is transferred from the operating system to a computer program, at which place the processor enters a program or a code fragment and execution begins. In some operating systems or programming languages, the initial entry is not part of the program but of the runtime library, in which case the runtime library initializes the program and then the runtime library enters the program. In other cases, the program may call the runtime library before doing anything when it is entered for the first time, and, after the runtime library returns, the actual code of the program begins to execute. This marks the transition from load time (and dynamic link time, if present) to run time.In simple layouts, programs begin their execution at the beginning, which is common in scripting languages, simple binary executable formats, and boot loaders. In other cases, the entry point is at some other fixed point, which is some memory address than can be an absolute address or relative address (offset).Alternatively, execution of a program can begin at a named point, either with a conventional name defined by the programming language or operating system, or at a caller-specified name. In many programming languages, notably C, this named point is a function called main; as a result, the entry point is often called the main function.Entry points apply both to source code and to executable files. However, in day-to-day software development, programmers specify the entry points only in source code, which makes them much better known. Entry points in executable files depend on the application binary interface (ABI) of the actual operating system, and are generated by the compiler or linker (if not fixed by the ABI). Non-executable object files may also have entry points, which are used later by the linker when generating entry points of an executable file.In most of today's popular programming languages and operating systems, a computer program usually only has a single entry point.In C, C++, D, Rust and Kotlin programs this is a function named main; in Java it is a static method named main (although the class must be specified at the invocation time), and in C# it is a static method named Main.In major operating systems, the standard executable format has a single entry point. In the Executable and Linkable Format (ELF), used in Unix and Unix-like systems such as Linux, the entry point is specified in the e_entry field of the ELF header. In the GNU Compiler Collection (gcc), the entry point used by the linker is the _start symbol. Similarly, in the Portable Executable format, used in Microsoft Windows, the entry point is specified by the AddressOfEntryPoint field, which is inherited from COFF. In COM files, the entry point is at the fixed offset of 0100h.One notable modern exception to the single-entry-point paradigm is Android.  Unlike applications on most other operating systems, Android applications do not have a single entry point –  there is no main function, for example.  Instead of a single entry point, they have essential components (which include activities and services) which the system can instantiate and run as needed.An occasionally used technique is the fat binary, which consists of several executables for different targets packaged in a single binary. Most commonly, this is implemented by a single overall entry point, which is compatible with all targets and branches to the target-specific entry point. Alternative techniques include storing separate executables in separate forks, each with its own entry point, which is then selected by the operating system.Historically, and in some contemporary legacy systems, such as VMS and OS/400, computer programs have a multitude of entry points, each corresponding to the different functionalities of the program. The usual way to denote entry points, as used system-wide in VMS and in PL/I and MACRO programs, is to append them at the end of the name of the executable image, delimited by a dollar sign ($), e.g. directory.exe$make.The Apple I computer also used this to some degree. For example, an alternative entry point in Apple I's BASIC would keep the BASIC program useful when the reset button was accidentally pushed.[clarification needed]In general, programs can exit at any time in an unstructured way, by returning to the operating system or crashing. Scripting languages typically end by reaching the end of the program, but for binaries the control must return to the operating system or it will simply run off the end of the process's memory, either executing whatever code is there or (in modern operating systems) resulting in a memory access violation and termination by the operating system.Usually, there is not a single exit point specified in a program. However, in other cases runtimes ensure that programs always terminate in a structured way via a single exit point, which is guaranteed unless the runtime itself crashes; this allows cleanup code to be run, such as atexit handlers. This can be done by either requiring that programs terminate by returning from the main function, by calling a specific exit function, or by the runtime catching exceptions or operating system signals.In many programming languages, the main function is where a program starts its execution. It enables high-level organization of the program's functionality, and typically has access to the command arguments given to the program when it was executed.The main function is generally the first programmer-written function that runs when a program starts, and is invoked directly from the system-specific initialization contained in the runtime environment (crt0 or equivalent). However, some languages can execute user-written functions before main runs, such as the constructors of C++ global objects.In other languages, notably scripting languages, execution simply begins at the start of the program.A non-exhaustive list of programming languages follows, describing their way of defining the main entry point:In APL, when a workspace is loaded, the contents of quad LX (latent expression) variable is interpreted as an APL expression and executed.In C and C++, the function prototype of the main function looks like one of the following:The parameters argc, argument count, and argv, argument vector, respectively give the number and values of the program's command-line arguments. The names of argc and argv may be any valid identifier in C, but it is common convention to use these names. In C++, the names are to be taken literally, and the void in the parameter list is to be omitted, if strict conformance is desired. Other platform-dependent formats are also allowed by the C and C++ standards, except that in C++ the return type must always be int; for example, Unix (though not POSIX.1) and Windows have a third argument giving the program's environment, otherwise accessible through getenv in stdlib.h:Darwin-based operating systems, such as macOS, have a fourth parameter containing arbitrary OS-supplied information, such as the path to the executing binary:The value returned from the main function becomes the exit status of the process, though the C standard only ascribes specific meaning to two values: EXIT_SUCCESS (traditionally 0) and EXIT_FAILURE. The meaning of other possible return values is implementation-defined. In case a return value is not defined by the programmer, an implicit return 0; at the end of the main() function is inserted by the compiler; this behavior is required by the C++ standard.It is guaranteed that argc is non-negative and that argv[argc] is a null pointer. By convention, the command-line arguments specified by argc and argv include the name of the program as the first element if argc is greater than 0; if a user types a command of rm file, the shell will initialise the rm process with argc = 2 and argv = {rm, file, NULL}.  As argv is the name that processes appear under in ps, top etc., some programs, such as daemons or those running within an interpreter or virtual machine (where argv would be the name of the host executable), may choose to alter their argv to give a more descriptive argv, usually by means of the exec system call.The main() function is special; normally every C and C++ program must define it exactly once.If declared, main() must be declared as if it has external linkage; it cannot be declared static or inline.In C++, main() must be in the global namespace (i.e. ::main), cannot be overloaded, and cannot be a member function, although the name is not otherwise reserved, and may be used for member functions, classes, enumerations, or non-member functions in other namespaces. In C++ (unlike C) main() cannot be called recursively and cannot have its address taken.When executing a program written in C#, the CLR searches for a static method marked with the .entrypoint IL directive, which takes either no arguments, or a single argument of type string[], and has a return type of void or int, and executes it.Command-line arguments are passed in args, similar to how it is done in Java. For versions of Main() returning an integer, similar to both C and C++, it is passed back to the environment as the exit status of the process.Clean is a functional programming language based on graph rewriting. The initial node is called Start and is of type *World -> *World if it changes the world or some fixed type if the program only prints the result after reducing Start.Or even simplerOne tells the compiler which option to use to generate the executable file.ANSI Common Lisp does not define a main function; instead, the code is read and evaluated from top to bottom in a source file. However, the following code will emulate a main function.In D, the function prototype of the main function looks like one of the following:Command-line arguments are passed in args, similar to how it is done in C# or Java. For versions of main() returning an integer, similar to both C and C++, it is passed back to the environment as the exit status of the process.FORTRAN does not have a main subroutine or function. Instead a PROGRAM statement as the first line can be used to specify that a program unit is a main program, as shown below. The PROGRAM statement cannot be used for recursive calls.Some versions of Fortran, such as those on the IBM System/360 and successor mainframes, do not support the PROGRAM statement. Many compilers from other software manufacturers will allow a fortran program to be compiled without a PROGRAM statement. In these cases, whatever module that has any non-comment statement where no SUBROUTINE, FUNCTION or BLOCK DATA statement occurs, is considered to be the Main program.Using GNAT, the programmer is not required to write a function called main; a source file containing a single subprogram can be compiled to an executable. The binder will however create a package ada_main, which will contain and export a C-style main function.In Go programming language, program execution starts with the main function of the package mainThere is no way to access arguments or a return code outside of the standard library in Go. These can be accessed via os.Args and os.Exit respectively, both of which are included in the os package.A Haskell program must contain a name called main bound to a value of type IO t, for some type t; which is usually IO (). IO is a monad, which organizes side-effects in terms of purely functional code. The main value represents the side-effects-ful computation done by the program. The result of the computation represented by main is discarded; that is why main usually has type IO (), which indicates that the type of the result of the computation is (), the unit type, which contains no information.Command line arguments are not given to main; they must be fetched using another IO action, such as System.Environment.getArgs.Java programs start executing at the main method, which has the following method heading:Command-line arguments are passed in args. As in C and C++, the name main() is special. Java's main methods do not return a value directly, but one can be passed by using the System.exit() method.Unlike C, the name of the program is not included in args, because the name of the program is exactly the name of the class that contains the main method called, so it is already known. Also unlike C, the number of arguments need not be included, since arrays in Java have a field that keeps track of how many elements there are.Another aspect unique to Java is that the main function must be included within a class, and then called manually by the runtime. This is because in Java everything has to be contained within a class. For instance, a hello world program in Java may look like so:To run this program, one must call java HelloWorld in the directory where the compiled class file (which itself must be named HelloWorld.class) exists. Alternatively, executable JAR files use a manifest file to specify the entry point in a manner that is filesystem-independent from the user's perspective.In FMSLogo, the procedures when loaded do not execute. To make them execute, it is necessary to use this code:Note that the variable startup is used for the startup list of actions, but the convention is that this calls another procedure that runs the actions. That procedure may be of any name.OCaml has no main function. Programs are evaluated from top to bottom.Command-line arguments are available in an array named Sys.argv and the exit status is 0 by default.Example:In Pascal, the main procedure is the only unnamed procedure in the program. Because Pascal programs have the procedures and functions in a more rigorous top-down order than C, C++ or Java programs, the main procedure is usually the last procedure in the program. Pascal does not have a special meaning for the name main or any similar name.Command-line arguments are counted in ParamCount and accessible as strings by ParamStr(n), with n between 0 and ParamCount.Note that unit or module based versions of Pascal start the main module with the PROGRAM keyword, while other separately compiled modules start with UNIT (UCSD/Borland) or MODULE (ISO). The unnamed function in modules is often module initialization, and run before the main program starts.In Perl, there is no main function. Statements are executed from top to bottom.Command-line arguments are available in the special array @ARGV. Unlike C, @ARGV does not contain the name of the program, which is $0.PHP does not have a main function. Starting from the first line of a PHP script, any code not encapsulated by a function header is executed as soon as it is seen.In Pike syntax is similar to that of C and C++.  The execution begins at main.  The argc variable keeps the number of arguments passed to the program.  The argv variable holds the value associated with the arguments passed to the program.Example:Python programs are evaluated top-to-bottom, as is usual in scripting languages: the entry point is the start of the source code. Since definitions must precede use, programs are typically structured with definitions at the top and the code to execute at the bottom (unindented), similar to code for a one-pass compiler, such as in Pascal.Alternatively, a program can be structured with an explicit main function containing the code to be executed when a program is executed directly, but which can also be invoked by importing the program as a module and calling the function. This can be done by the following idiom, which relies on the internal variable __name__ being set to __main__ when a program is executed, but not when it is imported as a module (in which case it is instead set to the module name); there are many variants of this structure:In this idiom, the call to the named entry point main is explicit, and the interaction with the operating system (receiving the arguments, calling system exit) are done explicitly by library calls, which are ultimately handled by the Python runtime. This contrast with C, where these are done implicitly by the runtime, based on convention.The QB64 language has no main function, the code that is not within a function, or subrutine is executed first, from top to bottom:Command line arguments (if any) can be read using the COMMAND$ function:In Ruby, there is no distinct main function. The code written without additional class .. end, module .. end enclosures is executed directly, step by step, in context of special main object. This object can be referenced using:and contain the following properties:Methods defined without additional classes/modules are defined as private methods of the main object, and, consequently, as private methods of almost any other object in Ruby:Number and values of command-line arguments can be determined using the single ARGV constant array:Note that first element of ARGV, ARGV, contains the first command-line argument, not the name of program executed, as in C. The name of program is available using $0 or $PROGRAM_NAME.Similar to Python, one could use:In Visual Basic, when a project contains no forms, the startup object may be the Main() procedure. The Command$ function can be optionally used to access the argument portion of the command line used to launch the program:In Xojo, there are two different project types, each with a different main entry point. Desktop (GUI) applications start with the App.Open event of the project's Application object. Console applications start with the App.Run event of the project's ConsoleApplication object. In both instances, the main function is automatically generated, and cannot be removed from the project."
"53"	"Ceylon is an object-oriented, strongly statically typed programming language with an emphasis on immutability, created by Red Hat. Ceylon programs run on the Java virtual machine (JVM), and can be compiled to JavaScript. The language design focuses on source code readability, predictability, toolability, modularity, and metaprogrammability.Important features of Ceylon include:The name Ceylon is an oblique reference to Java, in that Java and Sri Lanka, formerly known as Ceylon, are islands known for growth and export of coffee and tea.In August 2017, Ceylon was donated to the Eclipse Foundation.Ceylon is heavily influenced by Java's syntax, but adds many new features.One of the most novel aspects of Ceylon is its type system. Ceylon foregoes Java's primitive types and boxing in favor of a type system composed entirely of first-class objects. While this may cause boxing overhead in some situations, it makes the type system more uniform.Ceylon allows for union and intersection types, in a similar fashion to TypeScript, Whiley and Flow.Union types, written A|B, allow a variable to have more than one type. The following example shows a Ceylon function which may take either an integer or a string:Intersection types, written A&B, are the theoretical foundation of flow-sensitive typing:The condition is Integer input narrows the type of input to <Integer|String> & Integer, which distributes to Integer&Integer | String&Integer, which, as String and Integer are disjoint types, is equivalent to Integer&Integer | Nothing (Nothing is the empty bottom type), which simplifies to just Integer.Union and intersection types are used to provide null safety. The top type of the Ceylon type hierarchy is the class Anything, which has two subclasses: Object, the superclass of all normal classes and all interfaces, and Null, with the only instance null. Since Object and Null are disjoint types, most regular types like Integer or List<String> are not nullable; a nullable type is the union Integer|Null, abbreviated Integer?.Intersection types can be used to get a non-optional type out of a possibly-optional type, such as a type parameter. For example, the signature of a function that removes null elements from a stream of values could be:When removeNulls is called with a stream of Integer|Null elements, the result will be a stream of <Integer|Null> & Object elements, which simplifies to Integer.Similarly to many modern languages, Ceylon supports first class functions and higher order functions, including function types and anonymous functionsSimilar to Java and many other languages, and with a similar mechanism as algebraic types, Ceylon supports enumerated types, otherwise known as enums. This is implemented in Ceylon with a pattern of limiting the instances of an abstract class at declaration to a limited set of objects (in this case, singleton instances). Another way to implement this pattern is with the new constructor feature in Ceylon 1.2 where the objects are implemented as different named constructor declarations.Ceylon is strongly and statically typed, but also has support for type inference. The value keyword is used to infer the type of a variable, and the function keyword is used to infer the type of a function. The following two definition pairs are each equivalent:However, to make single-pass type inference possible, type inference is only allowed for non-toplevel and unshared declarations.By default the starter (ceylon run) runs the shared run() function of a module:but any other shared function without parameters can be used as main calling the program with the—run parameter, like this:ceylon run --compile=force --run hello defaultVersions of Ceylon released:All parts of Ceylon are available under open source licenses, mostly the Apache License. Part of the source code is licensed under LGPL."
"54"	"Dashcode was a software application created by Apple Inc. that was included with Mac OS X Leopard and facilitates the development of widgets for Dashboard. It was first included on new MacBooks shipping around the time of May 24, 2006, as part of the Xcode developer tools.Dashcode, Version 3.0 (328), was included as part of Apple's Xcode developer tools on the Mac OS X Snow Leopard DVD as an optional install.The last iteration of Dashcode, Version 3.0.5 for Xcode 4, is still available to developer account holders as an optional install from Downloads for Apple Developers (Apple Developer ID required).Steve Jobs mentioned Dashcode as a new feature to be included in Leopard during his 2006 WWDC keynote speech.  Although not installed by default as part of an Xcode installation, the DVDs handed out at the WWDC did contain a version of Dashcode.  Although the version number was in fact lower than that of the MacBook build, the WWDC build of Dashcode contained several additional templates, as well as some interface and functionality improvements.  This WWDC build launched on both Mac OS X v10.4 and the WWDC build of Mac OS X 10.5 (Leopard), but was unusable on 10.4 (crashes soon after startup).On December 20, 2006, Apple released a public beta of Dashcode.  When announcing this release, Apple stated the beta had been scaled back for compatibility with Mac OS X v10.4.  This beta expired on July 15, 2007.Dashcode Version 2.0 (151) is included as part of Apple's iOS SDK. This allows for the creation of Web apps for the iOS version of Safari.Dashcode Version 3.0.2 (336) is installed with Xcode on OS X Lion. It is not known if this will allow for the local installation of Dashcode-created web apps, as such an ability will allow iOS to run a software layer akin to Mac OS X's Dashboard, which runs on a local installation. Currently, iOS maintains a separation between native code and web code, in that way native applications can access data from the Internet, web content can't be accessed by native applications save for Safari; likewise, web content (including web apps) can be run inside the Safari browser, but cannot have access to the filesystem or other internals of iOS and cannot be installed on the operating system in the same way as native code.Native code software for iOS is currently developed using the Xcode suite, particularly an iPhone-centric version of Interface Builder packaged with the iOS SDK."
"55"	" The iOS SDK (Software Development Kit) (formerly iPhone SDK) is a software development kit developed by Apple Inc. The kit allows for the development of mobile apps on Apple's iOS operating system.While originally developing iPhone prior to its unveiling in 2007, Apple's then-CEO Steve Jobs did not intend to let third-party developers build native apps for iOS, instead directing them to make web applications for the Safari web browser. However, backlash from developers prompted the company to reconsider, with Jobs announcing in October 2007 that Apple would have a software development kit available for developers by February 2008. The SDK was released on March 6, 2008.The SDK is a free download for users of Mac personal computers. It is not available for Microsoft Windows PCs. The SDK contains sets giving developers access to various functions and services of iOS devices, such as hardware and software attributes. It also contains an iPhone simulator to mimic the look and feel of the device on the computer while developing. New versions of the SDK accompany new versions of iOS. In order to test applications, get technical support, and distribute apps through App Store, developers are required to subscribe to the Apple Developer Program.Combined with Xcode, the iOS SDK helps developers write iOS apps using officially-supported programming languages, including Swift and Objective-C. Other companies have also created tools that allow for the development of native iOS apps using their respective programming languages.While originally developing iPhone prior to its unveiling in 2007, Apple's then-CEO Steve Jobs did not intend to let third-party developers build native apps for the iOS operating system, instead directing them to make web applications for the Safari web browser. However, backlash from developers prompted the company to reconsider, with Jobs announcing on October 17, 2007 that Apple would have a software development kit (SDK) available for developers by February 2008. The SDK was released on March 6, 2008.The iOS SDK is a free download for Mac users. It is not available for Microsoft Windows personal computers. To test the application, get technical support, and distribute applications through App Store, developers are required to subscribe to the Apple Developer Program.The SDK contents are separated into the following sets:The SDK also contains an iPhone simulator, a program used to simulate the look and feel of iPhone on the developer's computer.New SDK versions accompany new iOS versions.The iOS SDK, combined with Xcode, helps developers write iOS applications using officially-supported programming languages, including Swift and Objective-C.In 2008, Sun Microsystems announced plans to release a Java Virtual Machine (JVM) for iOS, based on the Java Platform, Micro Edition version of Java. This would enable Java applications to run on iPhone and iPod Touch. Soon after the announcement, developers familiar with the SDK's terms of agreement believed that by not allowing third-party applications to run in the background (answer a phone call and still run the application, for example), and not allowing an application to download code from another source, nor allowing an application to interact with a third-party application, Sun's development efforts could be hindered without Apple's cooperation. Sun also worked with a third-party company called Innaworks in attempts to get Java on iPhone. Despite the apparent lack of interest from Apple, a firmware leak of the 2007 iPhone release revealed an ARM chip with a processor with Jazelle support for embedded Java execution.Novell announced in September 2009 that they had successfully developed MonoTouch, a software framework that let developers write native iPhone applications in the C# and .NET programming languages, while still maintaining compatibility with Apple's requirements.iOS does not support Adobe Flash, and although Adobe has two versions of its software – Flash and Flash Lite – Apple views neither as suitable for the iPhone, claiming that full Flash is too slow to be useful and Flash Lite to be not capable of being used with the Web.In October 2009, Adobe announced that an upcoming update to its Creative Suite would feature a component to let developers build native iPhone apps using the company's Flash development tools. The software was officially released as part of the company's Creative Suite 5 collection of professional applications.In April 2010, Apple made controversial changes to its iPhone Developer Agreement, requiring developers to use only approved programming languages in order to publish apps on App Store, and banning applications that used third-party development tools. After developer backlash and news of a potential antitrust investigation, Apple again revised its agreement in September, allowing the use of third-party development tools."
"56"	"An Intermediate representation (IR) is the data structure or code used internally by a compiler or virtual machine to represent source code. An IR is designed to be conducive for further processing, such as optimization and translation. A good IR must be accurate – capable of representing the source code without loss of information – and independent of any particular source or target language. An IR may take one of several forms: an in-memory data structure, or a special tuple- or stack-based code readable by the program. In the latter case it is also called an intermediate language.A canonical example is found in most modern compilers, where the linear human-readable text representing a program is transformed into an intermediate graph structure that allows flow analysis and re-arrangement before creating a sequence of actual CPU instructions. Use of an intermediate representation such as this allows compiler systems like the GNU Compiler Collection and LLVM to be used by many different source languages to generate code for many different target architectures.An intermediate language is the language of an abstract machine designed to aid in the analysis of computer programs. The term comes from their use in compilers, where the source code of a program is translated into a form more suitable for code-improving transformations before being used to generate object or machine code for a target machine. The design of an intermediate language typically differs from that of a practical machine language in three fundamental ways:A popular format for intermediate languages is three-address code.The term is also used to refer to languages used as intermediates by some high-level programming languages which do not output object or machine code themselves, but output the intermediate language only. This intermediate language is submitted to a compiler for such language, which then outputs finished object or machine code. This is usually done to ease the process of optimization or to increase portability by using an intermediate language that has compilers for many processors and operating systems, such as C. Languages used for this fall in complexity between high-level languages and low-level languages, such as assembly languages.Though not explicitly designed as an intermediate language, C's nature as an abstraction of assembly and its ubiquity as the de facto system language in Unix-like and other operating systems has made it a popular intermediate language: Eiffel, Sather, Esterel, some dialects of Lisp (Lush, Gambit), Haskell (Glasgow Haskell Compiler), Squeak's Smalltalk-subset Slang, Cython, Seed7, SystemTap, Vala, and others make use of C as an intermediate language. Variants of C have been designed to provide C's features as a portable assembly language, including C-- and the C Intermediate Language.Any language targeting a virtual machine or p-code machine can be considered an intermediate language:The GNU Compiler Collection (GCC) uses several intermediate languages internally to simplify portability and cross-compilation. Among these languages areThe LLVM compiler framework is based on the LLVM IR intermediate language, of which the compact, binary serialized representation is also referred to as bitcode and has been productized by Apple.The ILOC intermediate language is used in classes on compiler design as a simple target language.Static analysis tools often use an intermediate representation. For instance, radare2 is a toolbox for binary files analysis and reverse-engineering. It uses the intermediate languages ESIL et REIL to analyze binary files."
"57"	"Blocks are a non-standard extension added by Apple Inc. to Clang's implementations of the C, C++, and Objective-C programming languages that uses a lambda expression-like syntax to create closures within these languages. Blocks are supported for programs developed for Mac OS X 10.6+ and iOS 4.0+, although third-party runtimes allow use on Mac OS X 10.5 and iOS 2.2+ and non-Apple systems.Apple designed blocks with the explicit goal of making it easier to write programs for the Grand Central Dispatch threading architecture, although it is independent of that architecture and can be used in much the same way as closures in other languages. Apple has implemented blocks both in their own branch of the GNU Compiler Collection and in the upstream Clang LLVM compiler front end. Language runtime library support for blocks is also available as part of the LLVM project. The Khronos group uses blocks syntax to enqueue kernels from within kernels as of version 2.0 of OpenCL.Like function definitions, blocks can take arguments, and declare their own variables internally. Unlike ordinary C function definitions, their value can capture state from their surrounding context. A block definition produces an opaque value which contains both a reference to the code within the block and a snapshot of the current state of local stack variables at the time of its definition. The block may be later invoked in the same manner as a function pointer. The block may be assigned to variables, passed to functions, and otherwise treated like a normal function pointer, although the application programmer (or the API) must mark the block with a special operator (Block_copy) if it's to be used outside the scope in which it was defined.Given a block value, the code within the block can be executed at any later time by calling it, using the same syntax that would be used for calling a function.A simple example capturing mutable state in the surrounding scope is an integer range iterator:Blocks bear a superficial resemblance to GCC's extension of C to support lexically scoped nested functions. However, GCC's nested functions, unlike blocks, must not be called after the containing scope has exited, as that would result in undefined behavior.GCC-style nested functions currently use dynamic creation of executable thunks on most architectures when taking the address of the nested function.  On most architectures (including X86), these thunks are created on the stack, which requires marking the stack executable.  Executable stacks  are generally considered to be a potential security hole.  Blocks do not require the use of executable thunks, so they do not share this weakness. On the other hand, blocks introduces a completely new type for the pointer, while pointers to nested functions in GCC are regular function pointers and can be used directly with existing code."
"58"	" (Learn how and when to remove this template message)This page is intended to list all current compilers, compiler generators, interpreters, translators, tool foundations, assemblers, automatable command line interfaces (shells), etc.This list is incomplete. A more extensive list of source-to-source compilers can be found here.Liogo NET Compiler http://liogo.sourceforge.net/The Real LOGO Compiler http://lhogho.sourceforge.net/HaskellWiki maintains a list of Haskell implementations. Many of them are compilers.Production quality, open source compilers.Research compilers are mostly not robust or complete enough to handle real, large applications. They are used mostly for fast prototyping new language features and new optimizations in research areas."
"59"	"Code::Blocks is a free, open-source cross-platform IDE that supports multiple compilers including GCC, Clang and Visual C++. It is developed in C++ using wxWidgets as the GUI toolkit. Using a plugin architecture, its capabilities and features are defined by the provided plugins. Currently, Code::Blocks is oriented towards C, C++, and Fortran. It has a custom build system and optional Make support.Code::Blocks is being developed for Windows, Linux, and macOS and has been ported to FreeBSD,OpenBSD and Solaris.After releasing two release candidate versions, 1.0rc1 on July 25, 2005 and 1.0rc2 on October 25, 2005, instead of making a final release, the project developers started adding many new features, with the final release being repeatedly postponed. Instead, there were nightly builds of the latest SVN version made available on a daily basis.[citation needed]The first stable release was on February 28, 2008, with the version number changed to 8.02. The versioning scheme was changed to that of Ubuntu, with the major and minor number representing the year and month of the release. Version 17.12 is the latest stable release; however for the most up-to-date version the user can download the relatively stable nightly build or download the source code from SVN.Jennic Limited distributes a version of Code::Blocks customized to work with its microcontrollers.Code::Blocks supports multiple compilers, including GCC, MinGW, Digital Mars, Microsoft Visual C++, Borland C++, LLVM Clang, Watcom, LCC and the Intel C++ compiler. Although the IDE was designed for the C++ language, there is some support for other languages, including Fortran and D. A plug-in system is included to support other programming languages.The IDE features syntax highlighting and code folding (through its Scintilla editor component), C++ code completion, class browser, a hex editor and many other utilities. Opened files are organized into tabs. The code editor supports font and font size selection and personalized syntax highlighting colours.The Code::Blocks debugger has full breakpoint support. It also allows the user to debug their program by having access to the local function symbol and argument display, user-defined watches, call stack, disassembly, custom memory dump, thread switching, CPU registers and GNU Debugger Interface.As of version 13.12 Code::Blocks comes with a GUI designer called wxSmith. It is a derivative port of wxWidgets version 2.9.4. To make a complete wxWidgets application, the appropriate wxWidgets SDK must be installed.Some of Code::Blocks features are targeted at users migrating from other IDE's - these include Dev-C++, Microsoft Visual C++ project import (MSVC 7 & 10), and Dev-C++ Devpak support.Code::Blocks uses a custom build system, which stores its information in XML-based project files. It can optionally use external makefiles, which simplifies interfacing with projects using the GNU or qmake build systems."
"60"	"Qt Creator is a cross-platform C++, JavaScript and QML integrated development environment which is part of the SDK for the Qt GUI application development framework. It includes a visual debugger and an integrated GUI layout and forms designer. The editor's features include syntax highlighting and autocompletion. Qt Creator uses the C++ compiler from the GNU Compiler Collection on Linux and FreeBSD. On Windows it can use MinGW or MSVC with the default install and can also use Microsoft Console Debugger when compiled from source code. Clang is also supported.Development of what would eventually become Qt Creator had begun by 2007 or earlier under transitional names Workbench and later Project Greenhouse. It debuted during the later part of the Qt 4 era, starting with the release of Qt Creator, version 1.0 in March 2009 and subsequently bundled with Qt 4.5 in SDK 2009.3.This was at a time when the standalone Qt Designer application was still the widget layout tool of choice for developers. There is no indication that Creator had layout capability at this stage. The record is somewhat muddied on this point (perhaps due to changes in ownership or the emphasis on Qt Quick), but the integration of Qt Designer under Qt Creator is first mentioned at least as early as Qt 4.7 (ca. late 2011). Currently (in the Qt 5 era) it is simply stated that [Qt Designer's] functionality is now included as part of [sic] Qt Creator IDE.Qt Creator includes a project manager that can use a variety of project formats such as .pro, CMake, Autotools and others. A project file can contain information such as what files are included into the project, custom build steps and settings for running the applications.Qt Creator includes a code editor and integrates Qt Designer for designing and building graphical user interfaces (GUIs) from Qt widgets.The code editor in Qt Creator supports syntax highlighting for various languages. In addition to that, the code editor can parse code in C++ and QML languages and as a result code completion, context-sensitive help, semantic navigation are provided.Qt Designer is a tool for designing and building graphical user interfaces (GUIs) from Qt widgets. It is possible to compose and customize the widgets or dialogs and test them using different styles and resolutions directly in the editor. Widgets and forms created with Qt Designer are integrated with programmed code, using the Qt signals and slots mechanism.Qt Quick Designer is a tool for developing animations by using a declarative programming language QML.Qt Creator provides support for building and running Qt applications for desktop environments (Windows, Linux, FreeBSD and Mac OS), mobile devices (Android, BlackBerry, iOS, Maemo, and MeeGo) and embedded Linux devices. Build settings allow to switch between build targets, different Qt versions and build configurations. For mobile device targets, Qt Creator can generate an installation package, install it to a mobile device that is attached to the development computer and run it there. Installation packages can be published on the Ovi Store.Qt Creator is integrated with a set of tools, such as version control systems and Qt Simulator. The following version control systems are supported:Qt Simulator is a tool for testing Qt applications that are intended for mobile devices in an environment similar to that of the device.Qt Creator does not include a debugger for native code. It provides a debugger plugin that acts as an interface between the Qt Creator core and external native debuggers to debug the C++ language. Qt Creator displays the raw information provided by the native debuggers in a simplified manner. Debuggers supported are:"
"61"	"In computer science, reference counting is a technique of storing the number of references, pointers, or handles to a resource such as an object, block of memory, disk space or other resource.It may also refer, more specifically, to a garbage collection algorithm that uses these reference counts to deallocate objects which are no longer referenced.[not verified in body]As a collection algorithm, reference counting tracks, for each object, a count of the number of references to it held by other objects. If an object's reference count reaches zero, the object has become inaccessible, and can be destroyed.When an object is destroyed, any objects referenced by that object also have their reference counts decreased. Because of this, removing a single reference can potentially lead to a large number of objects being freed. A common modification allows reference counting to be made incremental: instead of destroying an object as soon as its reference count becomes zero, it is added to a list of unreferenced objects, and periodically (or as needed) one or more items from this list are destroyed.Simple reference counts require frequent updates. Whenever a reference is destroyed or overwritten, the reference count of the object it references is decremented, and whenever one is created or copied, the reference count of the object it references is incremented.Reference counting is also used in disk operating systems and distributed systems, where full non-incremental tracing garbage collection is too time consuming because of the size of the object graph and slow access speed.[citation needed]The main advantage of the reference counting over tracing garbage collection is that objects are reclaimed as soon as they can no longer be referenced, and in an incremental fashion, without long pauses for collection cycles and with clearly defined lifetime of every object. In real-time applications or systems with limited memory, this is important to maintain responsiveness. Reference counting is also among the simplest forms of memory management to implement. It also allows for effective management of non-memory resources such as operating system objects, which are often much scarcer than memory (tracing GC systems use finalizers for this[citation needed], but the delayed reclamation may cause problems).  Weighted reference counts are a good solution for garbage collecting a distributed system.Tracing garbage collection cycles are triggered too often if the set of live objects fills most of the available memory[citation needed]; it requires extra space to be efficient[citation needed]. Reference counting performance does not deteriorate as the total amount of free space decreases.Reference counts are also useful information to use as input to other runtime optimizations. For example, systems that depend heavily on immutable objects such as many functional programming languages can suffer an efficiency penalty due to frequent copies.[citation needed] However, if the compiler (or runtime system) knows that a particular object has only one reference (as most do in many systems), and that the reference is lost at the same time that a similar new object is created (as in the string append statement str <U+2190> str + a), it can replace the operation with a mutation on the original object.Reference counting in naive form has two main disadvantages over the tracing garbage collection, both of which require additional mechanisms to ameliorate:In addition to these, if the memory is allocated from a free list, reference counting suffers from poor locality. Reference counting alone cannot move objects to improve cache performance, so high performance collectors implement a tracing garbage collector as well. Most implementations (such as the ones in PHP and Objective-C) suffer from poor cache performance since they do not implement copying objects.When dealing with garbage collection schemes, it is often helpful to think of the reference graph, which is a directed graph where the vertices are objects and there is an edge from an object A to an object B if A holds a reference to B. We also have a special vertex or vertices representing the local variables and references held by the runtime system, and no edges ever go to these nodes, although edges can go from them to other nodes.In this context, the simple reference count of an object is the in-degree of its vertex. Deleting a vertex is like collecting an object. It can only be done when the vertex has no incoming edges, so it does not affect the out-degree of any other vertices, but it can affect the in-degree of other vertices, causing their corresponding objects to be collected as well if their in-degree also becomes 0 as a result.The connected component containing the special vertex contains the objects that can't be collected, while other connected components of the graph only contain garbage. If a reference-counting garbage collection algorithm is implemented, then each of these garbage components must contain at least one cycle; otherwise, they would have been collected as soon as their reference count (i.e., the number of incoming edges) dropped to zero.Incrementing and decrementing reference counts every time a reference is created or destroyed can significantly impede performance. Not only do the operations take time, but they damage cache performance and can lead to pipeline bubbles. Even read-only operations like calculating the length of a list require a large number of reads and writes for reference updates with naive reference counting.One simple technique is for the compiler to combine a number of nearby reference updates into one. This is especially effective for references which are created and quickly destroyed. Care must be taken, however, to put the combined update at the right position so that a premature free be avoided.The Deutsch-Bobrow method of reference counting capitalizes on the fact that most reference count updates are in fact generated by references stored in local variables. It ignores these references, only counting references in data structures, but before an object with reference count zero can be deleted, the system must verify with a scan of the stack and registers that no other reference to it still exists.Another technique devised by Henry Baker involves deferred increments, in which references which are stored in local variables do not immediately increment the corresponding reference count, but instead defer this until it is necessary. If such a reference is destroyed quickly, then there is no need to update the counter. This eliminates a large number of updates associated with short-lived references (such as the above list-length-counting example). However, if such a reference is copied into a data structure, then the deferred increment must be performed at that time. It is also critical to perform the deferred increment before the object's count drops to zero, resulting in a premature free.A dramatic decrease in the overhead on counter updates was obtained by Levanoni and Petrank. They introduce the update coalescing method which coalesces many of the redundant reference count updates. Consider a pointer that in a given interval of the execution is updated several times. It first points to an object O1, then to an object O2, and so forth until at the end of the interval it points to some object On. A reference counting algorithm would typically execute rc(O1)--, rc(O2)++, rc(O2)--, rc(O3)++, rc(O3)--, ..., rc(On)++. But most of these updates are redundant. In order to have the reference count properly evaluated at the end of the interval it is enough to perform rc(O1)-- and rc(On)++. The rest of the updates are redundant.Levanoni and Petrank showed in 2001 how to use such update coalescing in a reference counting collector. When using update coalescing with an appropriate treatment of new objects, more than 99% of the counter updates are eliminated for typical Java benchmarks. In addition, the need for atomic operations during pointer updates on parallel processors is eliminated. Finally, they presented an enhanced algorithm that may run concurrently with multithreaded applications employing only fine synchronization.Blackburn and McKinley's ulterior reference counting method in 2003 combines deferred reference counting with a copying nursery, observing that the majority of pointer mutations occur in young objects. This algorithm achieves throughput comparable with the fastest generational copying collectors with the low bounded pause times of reference counting.Perhaps the most obvious way to handle reference cycles is to design the system to avoid creating them. A system may explicitly forbid reference cycles; file systems with hard links often do this. Judicious use of weak (non-counted) references may also help avoid retain cycles; the Cocoa framework, for instance, recommends using strong references for parent-to-child relationships and weak references for child-to-parent relationships.Systems may also be designed to tolerate or correct the cycles they create in some way. Developers may design code to explicitly tear down the references in a data structure when it is no longer needed, though this has the cost of requiring them to manually track that data structure's lifetime. This technique can be automated by creating an owner object that does the tearing-down when it is destroyed; for instance, a Graph object's destructor could delete the edges of its GraphNodes, breaking the reference cycles in the graph. Cycles may even be ignored in systems with short lives and a small amount of cyclic garbage, particularly when the system was developed using a methodology of avoiding cyclic data structures wherever possible, typically at the expense of efficiency.Computer scientists have also discovered ways to detect and collect reference cycles automatically, without requiring changes in the data structure design. One simple solution is to periodically use a tracing garbage collector to reclaim cycles; since cycles typically constitute a relatively small amount of reclaimed space, the collector can be run much less often than with an ordinary tracing garbage collector.Bacon describes a cycle-collection algorithm for reference counting with similarities to tracing collectors, including the same theoretical time bounds. It is based on the observation that a cycle can only be isolated when a reference count is decremented to a nonzero value. All objects which this occurs on are put on a roots list, and then periodically the program searches through the objects reachable from the roots for cycles. It knows it has found a cycle that can be collected when decrementing all the reference counts on a cycle of references brings them all down to zero. An enhanced version of this algorithm by Paz et al. is able to run concurrently with other operations and improve its efficiency by using the update coalescing method of Levanoni and Petrank.Although it is possible to augment simple reference counts in a variety of ways, often a better solution can be found by performing reference counting in a fundamentally different way. Here we describe some of the variants on reference counting and their benefits and drawbacks.In weighted reference counting, each reference is assigned a weight, and each object tracks not the number of references referring to it, but the total weight of the references referring to it. The initial reference to a newly created object has a large weight, such as 216. Whenever this reference is copied, half of the weight goes to the new reference, and half of the weight stays with the old reference. Since the total weight does not change, the object's reference count does not need to be updated.Destroying a reference decrements the total weight by the weight of that reference. When the total weight becomes zero, all references have been destroyed. If an attempt is made to copy a reference with a weight of 1, the reference has to get more weight by adding to the total weight and then adding this new weight to the reference, and then splitting it. An alternative in this situation is to create an indirection reference object, the initial reference to which is created with a large weight which can then be split.The property of not needing to access a reference count when a reference is copied is particularly helpful when the object's reference count is expensive to access, for example because it is in another process, on disk, or even across a network. It can also help increase concurrency by avoiding many threads locking a reference count to increase it. Thus, weighted reference counting is most useful in parallel, multiprocess, database, or  distributed applications.The primary problem with simple weighted reference counting is that destroying a reference still requires accessing the reference count, and if many references are destroyed this can cause the same bottlenecks we seek to avoid. Some adaptations of weighted reference counting seek to avoid this by attempting to give weight back from a dying reference to one which is still active.Weighted reference counting was independently devised by Bevan and Watson & Watson. in 1987.In indirect reference counting, it is necessary to keep track of whom the reference was obtained from.  This means that two references are kept to the object: a direct one which is used for invocations; and an indirect one which forms part of a diffusion tree, such as in the Dijkstra-Scholten algorithm, which allows a garbage collector to identify dead objects.  This approach prevents an object from being discarded prematurely.Microsoft's Component Object Model (COM) and WinRT makes pervasive use of reference counting. In fact, two of the three methods that all COM objects must provide (in the IUnknown interface) increment or decrement the reference count.  Much of the Windows Shell and many Windows applications (including MS Internet Explorer, MS Office, and countless third-party products) are built on COM, demonstrating the viability of reference counting in large-scale systems.One primary motivation for reference counting in COM is to enable interoperability across different programming languages and runtime systems. A client need only know how to invoke object methods in order to manage object life cycle; thus, the client is completely abstracted from whatever memory allocator the implementation of the COM object uses. As a typical example, a Visual Basic program using a COM object is agnostic towards whether that object was allocated (and must later be deallocated) by a C++ allocator or another Visual Basic component.C++ does not perform reference-counting by default, fulfilling its philosophy of not adding functionality that might incur overheads where the user has not explicitly requested it. Objects that are shared but not owned can be accessed via a reference, raw pointer, or iterator (a conceptual generalisation of pointers).However, by the same token, C++ provides native ways for users to opt-into such functionality: C++11 provides reference counted smart pointers, via the std::shared_ptr class, enabling automatic shared memory-management of dynamically allocated objects. Programmers can use this in conjunction with weak pointers (via std::weak_ptr) to break cyclic dependencies. Objects that are dynamically allocated but not intended to be shared can have their lifetime automatically managed using a std::unique_ptr. In addition, C++11's move semantics further reduce the extent to which reference counts need to be modified by removing the deep copy normally used when a function returns an object, as it allows for a simple copy of the pointer of said object.Apple's Cocoa and Cocoa Touch frameworks (and related frameworks, such as Core Foundation) use manual reference counting, much like COM. Traditionally this was accomplished by the programmer manually sending retain and release messages to objects, but Automatic Reference Counting, a Clang compiler feature that automatically inserts these messages as needed, was added in iOS 5 and Mac OS X 10.7.Mac OS X 10.5 introduced a tracing garbage collector as an alternative to reference counting, but it was deprecated in OS X 10.8 and is expected to be removed in a future version. iOS has never supported a tracing garbage collector.One language that uses reference counting for garbage collection is Delphi. Delphi is mostly not a garbage collected language, in that user-defined types must still be manually allocated and deallocated. It does provide automatic collection, however, for a few built-in types, such as strings, dynamic arrays, and interfaces, for ease of use and to simplify the generic database functionality. It is up to the programmer to decide whether to use the built-in types or not; Delphi programmers have complete access to low-level memory management like in C/C++. So all potential cost of Delphi's reference counting can, if desired, be easily circumvented.Some of the reasons reference counting may have been preferred to other forms of garbage collection in Delphi include:The GObject object-oriented programming framework implements reference counting on its base types, including weak references.  Reference incrementing and decrementing uses atomic operations for thread safety.  A significant amount of the work in writing bindings to GObject from high-level languages lies in adapting GObject reference counting to work with the language's own memory management system.The Vala programming language uses GObject reference counting as its primary garbage collection system, along with copy-heavy string handling.Perl also uses reference counting, without any special handling of circular references, although (as in Cocoa and C++ above), Perl does support weak references, which allows programmers to avoid creating a cycle.PHP uses a reference counting mechanism for its internal variable management. Since PHP 5.3, it implements the algorithm from Bacon's above mentioned paper. PHP allows you to turn on and off the cycle collection with user-level functions. It also allows you to manually force the purging mechanism to be run.Python also uses reference counting and offers cycle detection as well (and can reclaim them).Squirrel also uses reference counting and offers cycle detection as well. This tiny language is relatively unknown outside the video game industry; however, it is a concrete example of how reference counting can be practical and efficient (especially in realtime environments).[citation needed]Tcl 8 uses reference counting for memory management of values (Tcl Obj structs[disambiguation needed]). Since Tcl's values are immutable, reference cycles are impossible to form and no cycle detection scheme is needed. Operations that would replace a value with a modified copy are generally optimized to instead modify the original when its reference count indicates it to be unshared. The references are counted at a data structure level, so the problems with very frequent updates discussed above do not arise.Xojo also uses reference counting, without any special handling of circular references, although (as in Cocoa and C++ above), Xojo does support weak references, which allows programmers to avoid creating a cycle.Many file systems maintain a count of the number of references to any particular block or file, for example the inode link count on Unix-style file systems. When the count falls to zero, the file can be safely deallocated. In addition, while references can still be made from directories, some Unixes allow that the referencing can be solely made by live processes, and there can be files that do not exist in the file system hierarchy.This article is based on material taken from  the Free On-line Dictionary of Computing prior to 1 November 2008 and incorporated under the relicensing terms of the GFDL, version 1.3 or later."
"62"	" (Learn how and when to remove this template message)This is a comparison of the programming languages Java and C++.The differences between the programming languages C++ and Java can be traced to their heritage, as they have different design goals.C++ language was designed for systems and applications programming (a.k.a., infrastructure programming), extending the procedural programming language C, which was designed for efficient execution. To C, C++ added support for object-oriented programming, exception handling, lifetime-based resource management (RAII), generic programming, template metaprogramming, and the C++ Standard Library which includes generic containers and algorithms (STL), and many other general purpose facilities.Java is a general-purpose, concurrent, class-based, object-oriented programming language that is designed to minimize implementation dependencies. It relies on a Java virtual machine to be secure and highly portable. It is bundled with an extensive library designed to provide a full abstraction of the underlying platform. Java is a statically typed object-oriented language that uses a syntax similar (but incompatible) to C++. It includes a documentation system called Javadoc.The different goals in the development of C++ and Java resulted in different principles and design trade-offs between the languages. The differences are as follows:It can also be done using the internal API sun.misc.Unsafe but that usage is highly discouraged and will be replaced by a public API in an upcoming Java version.A rich amount of third-party libraries exist for GUI and other functions like: Adaptive Communication Environment (ACE), Crypto++, various XMPP Instant Messaging (IM) libraries,OpenLDAP, Qt, gtkmm.Both C++ and Java provide facilities for generic programming, templates and generics, respectively. Although they were created to solve similar kinds of problems, and have similar syntax, they are quite different.An example comparing C++ and Java exists in Wikibooks.In addition to running a compiled Java program, computers running Java applications generally must also run the Java virtual machine (JVM), while compiled C++ programs can be run without external applications. Early versions of Java were significantly outperformed by statically compiled languages such as C++. This is because the program statements of these two closely related languages may compile to a few machine instructions with C++, while compiling into several byte codes involving several machine instructions each when interpreted by a JVM. For example:Since performance optimizing is a very complex issue, it is very difficult to quantify the performance difference between C++ and Java in general terms, and most benchmarks are unreliable and biased. Given the very different natures of the languages, definitive qualitative differences are also difficult to draw. In a nutshell, there are inherent inefficiencies and hard limits on optimizing in Java, given that it heavily relies on flexible high-level abstractions, however, the use of a powerful JIT compiler (as in modern JVM implementations) can mitigate some issues. In any case, if the inefficiencies of Java are too great, compiled C or C++ code can be called from Java via the JNI.Some inefficiencies that are inherent to the Java language include, mainly:However, there are a number of benefits to Java's design, some realized, some only theorized:Also, some performance problems occur in C++:The C++ language is defined by ISO/IEC 14882, an ISO standard, which is published by the ISO/IEC JTC1/SC22/WG21 committee. The latest, post-standardization draft of C++11 is available as well.The C++ language evolves via an open steering committee called the C++ Standards Committee. The committee is composed of the creator of C++ Bjarne Stroustrup, the convener Herb Sutter, and other prominent figures, including many representatives of industries and user-groups (i.e., the stake-holders). Being an open committee, anyone is free to join, participate, and contribute proposals for upcoming releases of the standard and technical specifications. The committee now aims to release a new standard every few years, although in the past strict review processes and discussions have meant longer delays between publication of new standards (1998, 2003, and 2011).The Java language is defined by the Java Language Specification, a book which is published by Oracle.The Java language continuously evolves via a process called the Java Community Process, and the world's programming community is represented by a group of people and organizations - the Java Community members—which is actively engaged into the enhancement of the language, by sending public requests - the Java Specification Requests - which must pass formal and public reviews before they get integrated into the language.The lack of a firm standard for Java and the somewhat more volatile nature of its specifications have been a constant source of criticism by stake-holders wanting more stability and conservatism in the addition of new language and library features. In contrast, the C++ committee also receives constant criticism, for the opposite reason, i.e., being too strict and conservative, and taking too long to release new versions.C++ is not a trademark of any company or organization and is not owned by any individual. Java is a trademark of Oracle Corporation."
"63"	"In computer programming, tracing garbage collection is a form of automatic memory management that consists of determining which objects should be deallocated (garbage collected) by tracing which objects are reachable by a chain of references from certain root objects, and considering the rest as garbage and collecting them. Tracing garbage collection is the most common type of garbage collection – so much so that garbage collection often refers to tracing garbage collection, rather than other methods such as reference counting – and there are a large number of algorithms used in implementation.Informally, an object is reachable if it is referenced by at least one variable in the program, either directly or through references from other reachable objects. More precisely, objects can be reachable in only two ways:The reachability definition of garbage is not optimal, insofar as the last time a program uses an object could be long before that object falls out of the environment scope. A distinction is sometimes drawn between syntactic garbage, those objects the program cannot possibly reach, and semantic garbage, those objects the program will in fact never again use. For example:The problem of precisely identifying semantic garbage can easily be shown to be partially decidable: a program that allocates an object X, runs an arbitrary input program P, and uses X if and only if P finishes would require a semantic garbage collector to solve the halting problem. Although conservative heuristic methods for semantic garbage detection remain an active research area, essentially all practical garbage collectors focus on syntactic garbage.[citation needed]Another complication with this approach is that, in languages with both reference types and unboxed value types, the garbage collector needs to somehow be able to distinguish which variables on the stack or fields in an object are regular values and which are references: in memory, an integer and a reference might look alike. The garbage collector then needs to know whether to treat the element as a reference and follow it, or whether it is a primitive value. One common solution is the use of tagged pointers.The garbage collector can reclaim only objects that have no references pointing to them either directly or indirectly from the root set. However, some programs require weak references, which should be usable for as long as the object exists but should not prolong its lifetime. In discussions about weak references, ordinary references are sometimes called strong references. An object is eligible for garbage collection if there are no strong (i.e. ordinary) references to it, even though there still might be some weak references to it.A weak reference is not merely just any pointer to the object that a garbage collector does not care about. The term is usually reserved for a properly managed category of special reference objects which are safe to use even after the object disappears because they lapse to a safe value. An unsafe reference that is not known to the garbage collector will simply remain dangling by continuing to refer to the address where the object previously resided. This is not a weak reference.In some implementations, weak references are divided into subcategories. For example, the Java Virtual Machine provides three forms of weak references, namely soft references,phantom references, and regular weak references. A softly referenced object is only eligible for reclamation, if the garbage collector decides that the program is low on memory. Unlike a soft reference or a regular weak reference, a phantom reference does not provide access to the object that it references. Instead, a phantom reference is a mechanism that allows the garbage collector to notify the program when the referenced object has become phantom reachable. An object is phantom reachable, if it still resides in memory and it is referenced by a phantom reference, but its finalizer has already executed. Similarly, Microsoft.NET provides two subcategories of weak references, namely long weak references (tracks resurrection) and short weak references.Data structures can also be devised which have weak tracking features. For instance, weak hash tables are useful. Like a regular hash table, a weak hash table maintains an association between pairs of objects, where each pair is understood to be a key and value. However, the hash table does not actually maintain a strong reference on these objects. A special behavior takes place when either the key or value or both become garbage: the hash table entry is spontaneously deleted. There exist further refinements such as hash tables which have only weak keys (value references are ordinary, strong references) or only weak values (key references are strong).Weak hash tables are important for maintaining associations between objects, such that the objects engaged in the association can still become garbage if nothing in the program refers to them any longer (other than the associating hash table).The use of a regular hash table for such a purpose could lead to a logical memory leak: the accumulation of reachable data which the program does not need and will not use.Tracing collectors are so called because they trace through the working set of memory. These garbage collectors perform collection in cycles. It is common for cycles to be triggered when there is not enough free memory for the memory manager to satisfy an allocation request. But cycles can often be requested by the mutator directly or run on a time schedule. The original method involves a naïve mark-and-sweep in which the entire memory set is touched several times.In the naive mark-and-sweep method, each object in memory has a flag (typically a single bit) reserved for garbage collection use only. This flag is always cleared, except during the collection cycle. The first stage is the mark stage which does a tree traversal of the entire 'root set' and marks each object that is pointed to by a root as being 'in-use'. All objects that those objects point to, and so on, are marked as well, so that every object that is reachable via the root set is marked.In the second stage, the sweep stage, all memory is scanned from start to finish, examining all free or used blocks; those not marked as being 'in-use' are not reachable by any roots, and their memory is freed. For objects which were marked in-use, the in-use flag is cleared, preparing for the next cycle.This method has several disadvantages, the most notable being that the entire system must be suspended during collection; no mutation of the working set can be allowed. This can cause programs to 'freeze' periodically (and generally unpredictably), making some real-time and time-critical applications impossible. In addition, the entire working memory must be examined, much of it twice, potentially causing problems in paged memory systems.Because of these performance problems, most modern tracing garbage collectors implement some variant of the tri-color marking abstraction, but simple collectors (such as the mark-and-sweep collector) often do not make this abstraction explicit.  Tri-color marking works as described below.Three sets are created –  white, black and gray:In many algorithms, initially the black set starts as empty, the gray set is the set of objects which are directly referenced from roots and the white set includes all other objects. Every object in memory is at all times in exactly one of the three sets. The algorithm proceeds as following:When the gray set is empty, the scan is complete; the black objects are reachable from the roots, while the white objects are not and can be garbage-collected.Since all objects not immediately reachable from the roots are added to the white set, and objects can only move from white to gray and from gray to black, the algorithm preserves an important invariant –  no black objects reference white objects. This ensures that the white objects can be freed once the gray set is empty. This is called the tri-color invariant. Some variations on the algorithm do not preserve this invariant but use a modified form for which all the important properties hold.The tri-color method has an important advantage –  it can be performed on-the-fly, without halting the system for significant periods of time. This is accomplished by marking objects as they are allocated and during mutation, maintaining the various sets. By monitoring the size of the sets, the system can perform garbage collection periodically, rather than as needed. Also, the need to touch the entire working set on each cycle is avoided.Once the unreachable set has been determined, the garbage collector may simply release the unreachable objects and leave everything else as it is, or it may copy some or all of the reachable objects into a new area of memory, updating all references to those objects as needed. These are called non-moving and moving (or, alternatively, non-compacting and compacting) garbage collectors, respectively.At first, a moving algorithm may seem inefficient compared to a non-moving one, since much more work would appear to be required on each cycle. But the moving algorithm leads to several performance advantages, both during the garbage collection cycle itself and during program execution:One disadvantage of a moving garbage collector is that it only allows access through references that are managed by the garbage collected environment, and does not allow pointer arithmetic. This is because any pointers to objects will be invalidated if the garbage collector moves those objects (they become dangling pointers). For interoperability with native code, the garbage collector must copy the object contents to a location outside of the garbage collected region of memory. An alternative approach is to pin the object in memory, preventing the garbage collector from moving it and allowing the memory to be directly shared with native pointers (and possibly allowing pointer arithmetic).Not only do collectors differ in whether they are moving or non-moving, they can also be categorized by how they treat the white, gray and black object sets during a collection cycle.The most straightforward approach is the semi-space collector, which dates to 1969. In this moving collector, memory is partitioned into an equally sized from space and to space. Initially, objects are allocated in to space until it becomes full and a collection cycle is triggered. At the start of the cycle, the to space becomes the from space, and vice versa. The objects reachable from the root set are copied from the from space to the to space. These objects are scanned in turn, and all objects that they point to are copied into to space, until all reachable objects have been copied into to space. Once the program continues execution, new objects are once again allocated in the to space until it is once again full and the process is repeated. This approach is very simple, but since only one semi space is used for allocating objects, the memory usage is twice as high compared to other algorithms. The technique is also known as stop-and-copy. Cheney's algorithm is an improvement on the semi-space collector.A mark and sweep garbage collector keeps a bit or two with each object to record if it is white or black. The grey set is kept as a separate list or using another bit. As the reference tree is traversed during a collection cycle (the mark phase), these bits are manipulated by the collector. A final sweep of the memory areas then frees white objects. The mark and sweep strategy has the advantage that, once the condemned set is determined, either a moving or non-moving collection strategy can be pursued. This choice of strategy can be made at runtime, as available memory permits. It has the disadvantage of bloating objects by a small amount.A mark and don't sweep garbage collector, like the mark-and-sweep, keeps a bit with each object to record if it is white or black; the gray set is kept as a separate list or using another bit. There are two key differences here. First, black and white mean different things than they do in the mark and sweep collector. In a mark and don't sweep collector, all reachable objects are always black. An object is marked black at the time it is allocated, and it will stay black even if it becomes unreachable. A white object is unused memory and may be allocated. Second, the interpretation of the black/white bit can change. Initially, the black/white bit may have the sense of (0=white, 1=black). If an allocation operation ever fails to find any available (white) memory, that means all objects are marked used (black). The sense of the black/white bit is then inverted (for example, 0=black, 1=white). Everything becomes white. This momentarily breaks the invariant that reachable objects are black, but a full marking phase follows immediately, to mark them black again. Once this is done, all unreachable memory is white. No sweep phase is necessary.It has been empirically observed that in many programs, the most recently created objects are also those most likely to become unreachable quickly (known as infant mortality or the generational hypothesis).  A generational GC (also known as ephemeral GC) divides objects into generations and, on most cycles, will place only the objects of a subset of generations into the initial white (condemned) set. Furthermore, the runtime system maintains knowledge of when references cross generations by observing the creation and overwriting of references. When the garbage collector runs, it may be able to use this knowledge to prove that some objects in the initial white set are unreachable without having to traverse the entire reference tree. If the generational hypothesis holds, this results in much faster collection cycles while still reclaiming most unreachable objects.In order to implement this concept, many generational garbage collectors use separate memory regions for different ages of objects. When a region becomes full, the objects in it are traced, using the references from the older generation(s) as roots.  This usually results in most objects in the generation being collected (by the hypothesis), leaving it to be used to allocate new objects.  When a collection doesn't collect many objects (the hypothesis doesn't hold, for example because the program has computed a large collection of new objects it does want to retain), some or all of the surviving objects that are referenced from older memory regions are promoted to the next highest region, and the entire region can then be overwritten with fresh objects. This technique permits very fast incremental garbage collection, since the garbage collection of only one region at a time is all that is typically required.Ungar's classic generation scavenger has two generations. It divides the youngest generation, called new space, into a large eden in which new objects are created and two smaller survivor spaces, past survivor space and future survivor space. The objects in the older generation that may reference objects in new space are kept in a remembered set. On each scavenge, the objects in new space are traced from the roots in the remembered set and copied to future survivor space. If future survivor space fills up, the objects that do not fit are promoted to old space, a process called tenuring. At the end of the scavenge, some objects reside in future survivor space, and eden and past survivor space are empty. Then future survivor space and past survivor space are exchanged and the program continues, allocating objects in eden. In Ungar's original system, eden is 5 times larger than each survivor space.Generational garbage collection is a heuristic approach, and some unreachable objects may not be reclaimed on each cycle. It may therefore occasionally be necessary to perform a full mark and sweep or copying garbage collection to reclaim all available space. In fact, runtime systems for modern programming languages (such as Java and the .NET Framework) usually use some hybrid of the various strategies that have been described thus far; for example, most collection cycles might look only at a few generations, while occasionally a mark-and-sweep is performed, and even more rarely a full copying is performed to combat fragmentation. The terms minor cycle and major cycle are sometimes used to describe these different levels of collector aggression.Simple stop-the-world garbage collectors completely halt execution of the program to run a collection cycle, thus guaranteeing that new objects are not allocated and objects do not suddenly become unreachable while the collector is running.This has the obvious disadvantage that the program can perform no useful work while a collection cycle is running (sometimes called the embarrassing pause). Stop-the-world garbage collection is therefore mainly suitable for non-interactive programs. Its advantage is that it is both simpler to implement and faster than incremental garbage collection.Incremental and concurrent garbage collectors are designed to reduce this disruption by interleaving their work with activity from the main program. Incremental garbage collectors perform the garbage collection cycle in discrete phases, with program execution permitted between each phase (and sometimes during some phases). Concurrent garbage collectors do not stop program execution at all, except perhaps briefly when the program's execution stack is scanned. However, the sum of the incremental phases takes longer to complete than one batch garbage collection pass, so these garbage collectors may yield lower total throughput.Careful design is necessary with these techniques to ensure that the main program does not interfere with the garbage collector and vice versa; for example, when the program needs to allocate a new object, the runtime system may either need to suspend it until the collection cycle is complete, or somehow notify the garbage collector that there exists a new, reachable object.Some collectors can correctly identify all pointers (references) in an object; these are called precise (also exact or accurate) collectors, the opposite being a conservative or partly conservative collector. Conservative collectors assume that any bit pattern in memory could be a pointer if, interpreted as a pointer, it would point into an allocated object. Conservative collectors may produce false positives, where unused memory is not released because of improper pointer identification. This is not always a problem in practice unless the program handles a lot of data that could easily be misidentified as a pointer. False positives are generally less problematic on 64-bit systems than on 32-bit systems because the range of valid memory addresses tends to be a tiny fraction of the range of 64-bit values. Thus, an arbitrary 64-bit pattern is unlikely to mimic a valid pointer. A false negative can also happen if pointers are hidden, for example using an XOR linked list. Whether a precise collector is practical usually depends on the type safety properties of the programming language in question. An example for which a conservative garbage collector would be needed is the C language, which allows typed (non-void) pointers to be type cast into untyped (void) pointers, and vice versa.A related issue concerns internal pointers, or pointers to fields within an object. If the semantics of a language allow internal pointers, then there may be many different addresses that can refer to parts of the same object, which complicates determining whether an object is garbage or not. An example for this is the C++ language, in which multiple inheritance can cause pointers to base objects to have different addresses. In a tightly optimized program, the corresponding pointer to the object itself may have been overwritten in its register, so such internal pointers need to be scanned.Performance of tracing garbage collectors – both latency and throughput – depends significantly on the implementation, workload, and environment. Naive implementations or use in very memory-constrained environments, notably embedded systems, can result in very poor performance compared with other methods, while sophisticated implementations and use in environments with ample memory can result in excellent performance.In terms of throughput, tracing by its nature requires some implicit runtime overhead, though in some cases the amortized cost can be extremely low, in some cases even lower than one instruction per allocation or collection, outperforming stack allocation. Manual memory management requires overhead due to explicit freeing of memory, and reference counting has overhead from incrementing and decrementing reference counts, and checking if the count has overflowed or dropped to zero.In terms of latency, simple stop-the-world garbage collectors pause program execution for garbage collection, which can happen at arbitrary times and take arbitrarily long, making them unusable for real-time computing, notably embedded systems, and a poor fit for interactive use, or any other situation where low latency is a priority. However, incremental garbage collectors can provide hard real-time guarantees, and on systems with frequent idle time and sufficient free memory, such as personal computers, garbage collection can be scheduled for idle times and have minimal impact on interactive performance. Manual memory management (as in C++) and reference counting have a similar issue of arbitrarily long pauses in case of deallocating a large data structure and all its children, though these only occur at fixed times, not depending on garbage collection.It is difficult to compare the two cases directly, as their behavior depends on the situation. For example, in the best case for a garbage collecting system, allocation just increments a pointer, but in the best case for manual heap allocation, the allocator maintains freelists of specific sizes and allocation only requires following a pointer. However, this size segregation usually cause a large degree of external fragmentation, which can have an adverse impact on cache behaviour. Memory allocation in a garbage collected language may be implemented using heap allocation behind the scenes (rather than simply incrementing a pointer), so the performance advantages listed above don't necessarily apply in this case. In some situations, most notably embedded systems, it is possible to avoid both garbage collection and heap management overhead by preallocating pools of memory and using a custom, lightweight scheme for allocation/deallocation.The overhead of write barriers is more likely to be noticeable in an imperative-style program which frequently writes pointers into existing data structures than in a functional-style program which constructs data only once and never changes them.Some advances in garbage collection can be understood as reactions to performance issues. Early collectors were stop-the-world collectors, but the performance of this approach was distracting in interactive applications. Incremental collection avoided this disruption, but at the cost of decreased efficiency due to the need for barriers. Generational collection techniques are used with both stop-the-world and incremental collectors to increase performance; the trade-off is that some garbage is not detected as such for longer than normal.While garbage collection is generally nondeterministic, it is possible to use it in hard real-time systems. A real-time garbage collector should guarantee that even in the worst case it will dedicate a certain number of computational resources to mutator threads. Constraints imposed on a real-time garbage collector are usually either work based or time based. A time based constraint would look like: within each time window of duration T, mutator threads should be allowed to run at least for Tm time. For work based analysis, MMU (minimal mutator utilization) is usually used as a real-time constraint for the garbage collection algorithm.One of the first implementations of hard real-time garbage collection for the JVM was based on the Metronome algorithm, whose commercial implementation is available as part of the IBM WebSphere Real Time. Another hard real-time garbage collection algorithm is Staccato, available in the IBM's J9 JVM, which also provides scalability to large multiprocessor architectures, while bringing various advantages over Metronome and other algorithms which, on the contrary, require specialized hardware."
"64"	"In computer science, the Boehm–Demers–Weiser garbage collector, often simply known as Boehm GC, is a conservative garbage collector for C and C++.Boehm GC is free software distributed under a permissive free software licence similar to the X11 license.The developer describes the operation of the collector as follows:Boehm GC can also run in leak detection mode in which memory management is still done manually, but the Boehm GC can check if it is done properly. In this way a programmer can find memory leaks and double deallocations.Boehm GC is also distributed with a C string handling library called cords. This is similar to ropes in C++ (strings are trees of small arrays, and they never change), but instead of using reference counting for proper deallocation, it relies on garbage collection to free objects. Cords are good at handling very large texts, modifications to them in the middle, slicing, concatenating, and keeping history of changes (undo/redo functionality).The garbage collector works with most unmodified C programs, simply by replacing malloc() with GC_MALLOC() calls, replacing realloc() with GC_REALLOC() calls, and removing free() calls. The code piece below shows how one can use Boehm instead of traditional malloc and free in C.The Boehm GC is used by many projects that are implemented in C or C++ like Inkscape, as well as by runtime environments for a number of other languages, including the GNU Compiler for Java runtime environment, the Portable.NET project, Embeddable Common Lisp, GNU Guile,  the Mono implementation of the Microsoft .NET platform (also using precise compacting GC since version 2.8), and libgc-d (a binding to libgc for the D programming language, used primarily in the MCI). It supports numerous operating systems, including many Unix variants (such as Mac OS X) and Microsoft Windows, and provides a number of advanced features including incremental collection, parallel collection and a variety of finalizer semantics."
"65"	"In computer science, manual memory management refers to the usage of manual instructions by the programmer to identify and deallocate unused objects, or garbage. Up until the mid-1990s, the majority of programming languages used in industry supported manual memory management, though garbage collection has existed since 1959, when it was introduced with Lisp. Today, however, languages with garbage collection such as Java are increasingly popular and the languages Objective-C and Swift provide similar functionality through Automatic Reference Counting. The main manually managed languages still in widespread use today are C and C++ – see C dynamic memory allocation.All programming languages use manual techniques to determine when to allocate a new object from the free store. C uses the malloc function; C++ and Java use the new operator; and many other languages (such as Python) allocate all objects from the free store. Determination of when an object ought to be created (object creation) is generally trivial and unproblematic, though techniques such as object pools mean an object may be created before immediate use. The fundamental issue is object destruction – determination of when an object is no longer needed (i.e. is garbage), and arranging for its underlying storage to be returned to the free store so that it may be re-used to satisfy future memory requests. In manual memory allocation, this is also specified manually by the programmer; via functions such as free() in C, or the delete operator in C++ – this contrasts with automatic destruction of objects held in automatic variables, notably (non-static) local variables of functions, which are destroyed at the end of their scope in C and C++.Manual memory management is known to enable several major classes of bugs into a program when used incorrectly, notably violations of memory safety or memory leaks. These are a significant source of security bugs.Languages which exclusively use garbage collection are known to avoid the last two classes of defects.  Memory leaks can still occur (and bounded leaks frequently occur with generational or conservative garbage collection), but are generally less severe than memory leaks in manual systems.Manual memory management has one correctness advantage, which is that it allows automatic resource management via the Resource Acquisition Is Initialization (RAII) paradigm.This arises when objects own scarce system resources (like graphics resources, file handles, or database connections) which must be relinquished when an object is destroyed – when the lifetime of the resource ownership should be tied to the lifetime of the object. Languages with manual management can arrange this by acquiring the resource during object initialization (in the constructor), and releasing during object destruction (in the destructor), which occurs at a precise time. This is known as Resource Acquisition Is Initialization.This can also be used with deterministic reference counting. In C++, this ability is put to further use to automate memory deallocation within an otherwise-manual framework, use of the shared_ptr template in the language's standard library to perform memory management is a common paradigm. shared_ptr is not suitable for all object usage patterns, however.This approach is not usable in most garbage collected languages – notably tracing garbage collectors or more advanced reference counting – due to finalization being non-deterministic, and sometimes not occurring at all. That is, it is difficult to define (or determine) when or if a finalizer method might be called; this is commonly known as the finalizer problem. Java and other GC'd languages frequently use manual management for scarce system resources besides memory via the dispose pattern: any object which manages resources is expected to implement the dispose() method, which releases any such resources and marks the object as inactive.  Programmers are expected to invoke dispose() manually as appropriate to prevent leaking of scarce graphics resources.  Depending on the finalize() method (how Java implements finalizers) to release graphics resources is widely viewed as poor programming practice among Java programmers, and similarly the analogous __del__() method in Python cannot be relied on for releasing resources. For stack resources (resources acquired and released within a single block of code), this can be automated by various language constructs, such as Python's with, C#'s using or Java's try-with-resources.Many advocates of manual memory management argue that it affords superior performance when compared to automatic techniques such as garbage collection. Traditionally latency was the biggest advantage, but this is no longer the case. Manual allocation frequently has superior locality of reference.[citation needed]Manual allocation is also known to be more appropriate for systems where memory is a scarce resource, due to faster reclamation. Memory systems can and do frequently thrash as the size of a program's working set approaches the size of available memory; unused objects in a garbage-collected system remain in an unreclaimed state for longer than in manually managed systems, because they are not immediately reclaimed, increasing the effective working set size.Manual management has a number of documented performance disadvantages:Latency is a debated point that has changed over time, with early garbage collectors and simple implementations performing very poorly compared to manual memory management, but sophisticated modern garbage collectors often performing as well or better than manual memory management.Manual allocation does not suffer from the long pause times that occur in simple stop-the-world garbage collection, although modern garbage collectors have collection cycles which are often not noticeable.Manual memory management and garbage collection both suffer from potentially unbounded deallocation times – manual memory management because deallocating a single object may require deallocating its members, and recursively its members' members, etc., while garbage collection may have long collection cycles. This is especially an issue in real time systems, where unbounded collection cycles are generally unacceptable; real-time garbage collection is possible by pausing the garbage collector, while real-time manual memory management requires avoiding large deallocations, or manually pausing deallocation."
"66"	"In computer science, a smart pointer is an abstract data type that simulates a pointer while providing added features, such as automatic memory management or bounds checking. Such features are intended to reduce bugs caused by the misuse of pointers, while retaining efficiency. Smart pointers typically keep track of the memory they point to, and may also be used to manage other resources, such as network connections and file handles. Smart pointers originated in the programming language C++.Pointer misuse can be a major source of bugs. Smart pointers prevent most situations of memory leaks by making the memory deallocation automatic. More generally, they make object destruction automatic: an object controlled by a smart pointer is automatically destroyed (finalized and then deallocated) when the last (or only) owner of an object is destroyed, for example because the owner is a local variable, and execution leaves the variable's scope. Smart pointers also eliminate dangling pointers by postponing destruction until an object is no longer in use.Several types of smart pointers exist. Some work with reference counting, others by assigning ownership of an object to one pointer. If a language supports automatic garbage collection (for example, Java or C#), then smart pointers are unneeded for the reclaiming and safety aspects of memory management, yet are useful for other purposes, such as cache data structure residence management and resource management of objects such as file handles or network sockets.In C++, a smart pointer is implemented as a template class that mimics, by means of operator overloading, the behaviors of a traditional (raw) pointer, (e.g. dereferencing, assignment) while providing additional memory management features.Smart pointers can facilitate intentional programming by expressing, in the type, how the memory of the referent of the pointer will be managed. For example, if a C++ function returns a pointer, there is no way to know whether the caller should delete the memory of the referent when the caller is finished with the information.Traditionally, naming conventions have been used to resolve the ambiguity, which is an error-prone, labor-intensive approach. C++11 introduced a way to ensure correct memory management in this case by declaring the function to return a unique_ptr,The declaration of the function return type as a unique_ptr makes explicit the fact that the caller takes ownership of the result, and the C++ runtime ensures that the memory for *some_type will be reclaimed automatically. Before C++11, unique_ptr can be replaced with auto_ptr.To ease the allocation of a C++11 introduced:and similarly Since C++14 one can use:It is preferred, in almost all circumstances, to use these facilities over the new keyword:C++11 introduces std::unique_ptr, defined in the header <memory>.A unique_ptr is a container for a raw pointer, which the unique_ptr is said to own. A unique_ptr explicitly prevents copying of its contained pointer (as would happen with normal assignment), but the std::move function can be used to transfer ownership of the contained pointer to another unique_ptr. A unique_ptr cannot be copied because its copy constructor and assignment operators are explicitly deleted.std::auto_ptr is deprecated under C++11 and completely removed from C++17. The copy constructor and assignment operators of auto_ptr do not actually copy the stored pointer. Instead, they transfer it, leaving the prior auto_ptr object empty. This was one way to implement strict ownership, so that only one auto_ptr object can own the pointer at any given time. This means that auto_ptr should not be used where copy semantics are needed.[citation needed] Since auto_ptr already existed with its copy semantics, it could not be upgraded to be a move-only pointer without breaking backward compatibility with existing code.C++11 introduces std::shared_ptr and std::weak_ptr, defined in the header <memory>.A shared_ptr is a container for a raw pointer. It maintains reference counting ownership of its contained pointer in cooperation with all copies of the shared_ptr. An object referenced by the contained raw pointer will be destroyed when and only when all copies of the shared_ptr have been destroyed.A weak_ptr is a container for a raw pointer. It is created as a copy of a shared_ptr. The existence or destruction of weak_ptr copies of a shared_ptr have no effect on the shared_ptr or its other copies. After all copies of a shared_ptr have been destroyed, all weak_ptr copies become empty.Because the implementation of shared_ptr uses reference counting, circular references are potentially a problem. A circular shared_ptr chain can be broken by changing the code so that one of the references is a weak_ptr.Multiple threads can safely simultaneously access different shared_ptr and weak_ptr objects that point to the same object.The referenced object must be protected separately to ensure thread safety.shared_ptr and weak_ptr are based on versions used by the Boost libraries.[citation needed]C++ Technical Report 1 (TR1) first introduced them to the standard, as general utilities, but C++11 adds more functions, in line with the Boost version."
"67"	"In computer science, unreachable memory is a block of memory allocated dynamically where the program that allocated the memory no longer has any reachable pointer that refers to it. Similarly, an unreachable object is a dynamically allocated object that has no reachable  reference to it. Informally, unreachable memory is dynamic memory that the program can not reach directly, nor get to by starting at an object it can reach directly, and then following a chain of pointer references.In dynamic memory allocation implementations that employ a garbage collector, objects are reclaimed after they become unreachable. The garbage collector is able to determine if an object is reachable; any object that is determined to no longer be reachable can be deallocated. Many programming languages (for example, Java, C#, D,  Dylan) use automatic garbage collection.In contrast, when memory becomes unreachable in dynamic memory allocation implementations that require explicit deallocation, the memory can no longer be explicitly deallocated. Unreachable memory in systems that use manual memory management results in a memory leak.Some garbage collectors implement weak references. If an object is reachable only through either weak references or chains of references that include a weak reference, then the object is said to be weakly reachable. The garbage collector can treat a weakly reachable object graph as unreachable and deallocate it. (Conversely, references that prevent an object from being garbage collected are called strong references; a weakly reachable object is unreachable by any chain consisting only of strong references.) Some garbage-collected object-oriented languages, such as Java and Python, feature weak references.  The Java package java.lang.ref supports soft, weak and phantom references, resulting in the additional object reachability states softly reachable and phantom reachable.Unreachable memory is often associated with software aging."
"68"	" (Learn how and when to remove this template message)In object-oriented programming, a metaclass is a class whose instances are classes. Just as an ordinary class defines the behavior of certain objects, a metaclass defines the behavior of certain classes and their instances. Not all object-oriented programming languages support metaclasses. Among those that do, the extent to which metaclasses can override any given aspect of class behavior varies. Metaclasses can be implemented by having classes be first-class citizen, in which case a metaclass is simply an object that constructs classes. Each language has its own metaobject protocol, a set of rules that govern how objects, classes, and metaclasses interact.In Python, the builtin class type is a metaclass. Consider this simple Python class:At run time, Car itself is an instance of type. The source code of the Car class, shown above, does not include such details as the size in bytes of Car objects, their binary layout in memory, how they are allocated, that the __init__ method is automatically called each time a Car is created, and so on. These details come into play not only when a new Car object is created, but also each time any attribute of a Car is accessed. In languages without metaclasses, these details are defined by the language specification and can't be overridden. In Python, the metaclass - type - controls these details of Car's behavior. They can be overridden by using a different metaclass instead of type.The above example contains some redundant code to do with the four attributes make, model, year, and color. It is possible to eliminate some of this redundancy using a metaclass. In Python, a metaclass is most easily defined as a subclass of type.This metaclass only overrides object creation.  All other aspects of class and object behavior are still handled by type.Now the class Car can be rewritten to use this metaclass.  This is done in Python 2 by assigning to __metaclass__ within the class definition:In Python 3 you provide a named argument, metaclass=M to the class definition instead:Car objects can then be instantiated like this:In Smalltalk, everything is an object. Additionally, Smalltalk is a class based system, which means that every object has a class that defines the structure of that object (i.e. the instance variables the object has) and the messages an object understands. Together this implies that a class in Smalltalk is an object and that therefore a class needs to be an instance of a class (called metaclass).As an example, a car object c is an instance of the class Car. In turn, the class Car is again an object and as such an instance of the metaclass of Car called Car class. Note the blank in the name of the metaclass. The name of the metaclass is the Smalltalk expression that, when evaluated, results in the metaclass object. Thus evaluating Car class results in the metaclass object for Car whose name is Car class (one can confirm this by evaluating Car class name which returns the name of the metaclass of Car.)Class methods actually belong to the metaclass, just as instance methods actually belong to the class. When a message is sent to the object 2, the search for the method starts in Integer. If it is not found it proceeds up the superclass chain, stopping at Object whether it is found or not.When a message is sent to Integer the search for the method starts in Integer class and proceeds up the superclass chain to Object class. Note that, so far, the metaclass inheritance chain exactly follows that of the class inheritance chain. But the metaclass chain extends further because Object class is the subclass of Class. All metaclasses are subclasses of Class.In early Smalltalks, there was only one metaclass called Class. This implied that the methods all classes have were the same, in particular the method to create new objects, i.e., new. To allow classes to have their own methods and their own instance variables (called class instance variables and should not be confused with class variables), Smalltalk-80 introduced for each class C their own metaclass C class. This means that each metaclass is effectively a singleton class.Since there is no requirement that metaclasses behave differently from each other, all metaclasses are instances of only one class called Metaclass. The metaclass of Metaclass is called Metaclass class which again is an instance of class Metaclass.In Smalltalk-80, every class (except Object) has a superclass. The abstract superclass of all metaclasses is Class, which describes the general nature of classes.The superclass hierarchy for metaclasses parallels that for classes, except for class Object. ALL metaclasses are subclasses of Class, therefore: Like conjoined twins, classes and metaclasses are born together. Metaclass has an instance variable thisClass, which points to its conjoined class. Note that the usual Smalltalk class browser does not show metaclasses as separate classes. Instead the class browser allows to edit the class together with its metaclass at the same time.The names of classes in the metaclass hierarchy are easily confused with the concepts of the same name. For instance:Four classes provide the facilities to describe new classes. Their inheritance hierarchy (from Object), and the main facilities they provide are:Ruby purifies the Smalltalk-80 concept of metaclasses by introducing eigenclasses, removing the Metaclass class, and (un)redefining the class-of map.  The change can be schematized as follows:Note in particular the correspondence between Smalltalk's implicit metaclasses and Ruby's eigenclasses of classes. The Ruby eigenclass model makes the concept of implicit metaclasses fully uniform: every object x has its own meta-object, called the eigenclass of x, which is one meta-level higher than x. The higher order eigenclasses usually exist purely conceptually – they do not contain any methods or store any (other) data in most Ruby programs.The following diagrams show a sample core structure of Smalltalk-80 and Ruby in comparison. In both languages, the structure consists of a built-in part which contains the circular objects (i.e. objects that appear in a cycle formed by a combination of blue or green links) and a user-part which has four explicit objects: classes A and B and terminal objects u and v. Green links show the child<U+2192>parent relation of inheritance (with the implicit upward direction), blue links show the complementary member<U+2192>container relation of instantiation (a blue link from x points to the least actual container of x that is the start point for the method lookup when a method is invoked on x). Gray nodes display the eigenclasses (resp. implicit metaclasses in the case of Smalltalk-80).The diagram on the right also provides a picture of lazy evaluation of eigenclasses in Ruby. The v object can have its eigenclass evaluated (allocated) as a consequence of adding singleton methods to v.According to the Ruby's introspection method named class, the class of every class (and of every eigenclass) is constantly the Class class (denoted by c in the diagram). Class, and Struct are the only classes that have classes as instances.[disputed  – discuss] Subclassing of Class is disallowed.  Following the standard definition of metaclasses we can conclude that Class and Struct are the only metaclasses in Ruby. This seems to contradict the correspondence between Ruby and Smalltalk, since in Smalltalk-80, every class has its own metaclass. The discrepancy is based on the disagreement between the class introspection method in Ruby and Smalltalk. While the map x <U+21A6> x.class coincides on terminal objects, it differs in the restriction to classes. As already mentioned above, for a class x, the Ruby expression x.class evaluates constantly to Class. In Smalltalk-80, if x is a class then the expression x class corresponds to the Ruby's x.singleton_class – which evaluates to the eigenclass of x.Metaclasses in Objective-C are almost the same as those in Smalltalk-80—not surprising since Objective-C borrows a lot from Smalltalk. Like Smalltalk, in Objective-C, the instance variables and methods are defined by an object's class. A class is an object, hence it is an instance of a metaclass.Like Smalltalk, in Objective-C, class methods are simply methods called on the class object, hence a class's class methods must be defined as instance methods in its metaclass. Because different classes can have different sets of class methods, each class must have its own separate metaclass. Classes and metaclasses are always created as a pair: the runtime has functions objc_allocateClassPair() and objc_registerClassPair() to create and register class-metaclass pairs, respectively.There are no names for the metaclasses; however, a pointer to any class object can be referred to with the generic type Class (similar to the type id being used for a pointer to any object).Because class methods are inherited through inheritance, like Smalltalk, metaclasses must follow an inheritance scheme paralleling that of classes (e.g. if class A's parent class is class B, then A's metaclass's parent class is B's metaclass), except that of the root class.Unlike Smalltalk, the metaclass of the root class inherits from the root class (usually NSObject using the Cocoa framework) itself. This ensures that all class objects are ultimately instances of the root class, so that you can use the instance methods of the root class, usually useful utility methods for objects, on class objects themselves.Since metaclass objects do not behave differently (you cannot add class methods for a metaclass, so metaclass objects all have the same methods), they are all instances of the same class—the metaclass of the root class (unlike Smalltalk). Thus, the metaclass of the root class is an instance of itself. The reason for this is that all metaclasses inherit from root class; hence, they must inherit the class methods of the root class.The following are some of the most prominent programming languages that support metaclasses.Some less widespread languages that support metaclasses include OpenJava, OpenC++, OpenAda, CorbaScript, ObjVLisp, Object-Z, MODEL-K, XOTcl, and MELDC. Several of these languages date from the early 1990s and are of academic interest.Logtalk, an object-oriented extension of Prolog, also supports metaclasses.Resource Description Framework (RDF) and Unified Modeling Language (UML) both support metaclasses."
"69"	"RubyCocoa is a Mac OS X framework that provides a bridge between the Ruby and the Objective-C programming languages, allowing the user to manipulate Objective-C objects from Ruby, and vice versa. It makes it possible to write a Cocoa application completely in Ruby as well as to write an application that mixes Ruby and Objective-C code. An Apple project called MacRuby was under development to replace RubyCocoa in 2008. A proprietary spin-off called RubyMotion was subsequently released in 2012, available for iOS, OS X and Android.Some useful applications of RubyCocoa are exploration of a Cocoa object's features with irb interactively, prototyping of a Cocoa application, writing a Cocoa application that combines the features of Ruby and Objective-C and wrapping Mac OS X's native GUI for a Ruby script.RubyCocoa is free software, released under both the Ruby License and the LGPL.RubyCocoa was started in 2001 by Hisakuni Fujimoto when he implemented a Ruby extension module to wrap NSObject and NSClassFromString function. Later it was integrated with Project Builder (which later became Xcode). In 2002 the project was registered on SourceForge and the development team began to grow.In 2006 the committers list was first joined by a developer from Apple, Laurent Sansonetti, and then a RubyCocoa presentation was made during WWDC. Apple stated that RubyCocoa will be included and supported in Mac OS X v10.5 “Leopard”.In August 2008, Sansonetti confirmed that MacRuby is supposed to replace RubyCocoa. in the future.RubyCocoa is sometimes interpreted as a set of bindings to the Cocoa frameworks, which is false. RubyCocoa is a real bridge between the Objective-C and Ruby programming languages.RubyCocoa will import the Objective-C classes into the Ruby world on demand. For example, when you access OSX::NSTableView for the very first time in your code, RubyCocoa will retrieve all the necessary information regarding this class from the Objective-C runtime and create a Ruby class of the same name that will act as a proxy. It will also import in the same way all the inherited classes.As stated earlier, RubyCocoa creates special proxy objects. Every time you send a Ruby message to a proxy object, RubyCocoa will try to forward it to the embedded Objective-C instance, by translating the message name to an Objective-C selector and asking the Objective-C runtime to forward it.If an exception is raised from the Objective-C world, RubyCocoa will convert it to a Ruby exception and forward it to you.RubyCocoa uses the libffi library to call the Objective-C methods implementations.RubyCocoa makes it easy to override an Objective-C method from Ruby, either in a subclass or directly to the class (as you would do in Objective-C using a category).Once your method is inserted, RubyCocoa will retrieve the signature of the existing Objective-C method and inject a new one to the Objective-C runtime, of the same signature, but which now points to your code.To accomplish this, RubyCocoa uses the libffi library to dynamically create a closure that will call the Ruby method, and just passes a pointer to that new closure to the Objective-C runtime.Due to the nature of the Objective-C language, you can freely use C from Objective-C code. In order to bridge the relevant C parts of an Objective-C framework, such as C structures, functions, enumerations, constants and more, RubyCocoa relies on the BridgeSupport project.RubyCocoa will interpret at runtime the BridgeSupport files (using the very fast libXML2's xmlTextReader) and accordingly handle their content. It will for instance construct the Ruby proxy classes for the C structures and also create the functions.Note that the costly operations, such as localizing the symbols, are done on demand, and obviously only once.RubyCocoa is able to detect APIs that use format strings, like NSLog or NSString.stringWithFormat, and appropriately convert the variable arguments to the types specified in the format string.RubyCocoa allows you to pass Ruby Proc objects as function pointer arguments. It will then use the libffi library to dynamically create a closure and pass it to the underlying function/method.When you install RubyCocoa, the corresponding Xcode templates are installed automatically. So when you start a new project, select Cocoa-Ruby Application  project type and all necessary files will be generated.To invoke an Objective-C method, you replace each colon in the method name except the last with an underscore. Thus, for example, the NSWindow instance method initWithContentRect:styleMask:backing:defer: becomes initWithContentRect_styleMask_backing_defer.All Cocoa classes and functions belong to OSX module, so for example, the Objective-C code:will become:As you can see, this decreases the code readability by rendering Objective-C parameter naming useless. So, there is another convenient way to write the method calls — the objc_send method, which accepts Ruby symbols as parameter names. For example, the previous code can also be written as:"
